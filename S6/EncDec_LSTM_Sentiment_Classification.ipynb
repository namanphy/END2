{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EncDec-LSTM-Sentiment-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T_uEfWJpL6Nq",
        "zOIbi5WzO5OU",
        "a5aeKuNCRGip"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOa/LTO2tDWWwNTSQRk41Tu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f263d0896d0a4b6199380cad43b52428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63ca32ea8fb44319920bea51328eb6bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26b04d7c58ca4adeafece4c5b5db31ca",
              "IPY_MODEL_8a198b9390c64ab5b1563e16ba328c28"
            ]
          }
        },
        "63ca32ea8fb44319920bea51328eb6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26b04d7c58ca4adeafece4c5b5db31ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_40a9d40ed0d74d289b8fdaafcd0162cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.88MB of 0.88MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d16b7f5aee5647b1846daaccfc7d7306"
          }
        },
        "8a198b9390c64ab5b1563e16ba328c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f72bc0dc9eee42048e2174fb87ddc31b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_442fe868c30d48fdb22130d8eef0a33e"
          }
        },
        "40a9d40ed0d74d289b8fdaafcd0162cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d16b7f5aee5647b1846daaccfc7d7306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f72bc0dc9eee42048e2174fb87ddc31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "442fe868c30d48fdb22130d8eef0a33e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namanphy/END2/blob/main/S6/EncDec_LSTM_Sentiment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yBoAQtCfJAg"
      },
      "source": [
        "## Initialising my wandb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVb6XmSWfHyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49ffe69-81c2-403e-c522-158952b346bc"
      },
      "source": [
        "! pip install --upgrade wandb --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 18.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 18.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA6AJMfXhg1W"
      },
      "source": [
        "! pip install OmegaConf --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ukExsfhcxk"
      },
      "source": [
        "from omegaconf import OmegaConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V54Yb9Y7ce5w",
        "outputId": "617c5c1a-7f50-4a83-9ad9-ec47100bdff6"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamanphy\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS_kEHpIhl46"
      },
      "source": [
        "wand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset Preview\n",
        "\n",
        "Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. \n",
        "\n",
        "We will be using previous session tweet dataset. Let's just preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "bdf892a4-ea24-4f0f-a538-f84a6cc57ae0"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee178158-b617-4cc5-c9a1-24daaff172fd"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4495f9e3-4ae3-4966-92d0-c6145e35fc52"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa5aa4f-f9c1-4cf2-b67b-d3e8205c5c9f"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ffa8bd49130>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "#twitterDataset = data.TabularDataset(path=\"tweets.csv\", format=\"CSV\", fields=fields, skip_header=True)\n",
        "\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training, testing, and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmKkoIO8vEO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913e6678-1fbe-47d8-b112-8087b93330a5"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kix8P2IKSBaV"
      },
      "source": [
        "An example from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc4a647-4cbf-4e47-f436-e591771bdba2"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabu‐ lary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. \n",
        "\n",
        "Let’s limit the vocabulary to a maximum of 5000 words in our training set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyEeEjXTGhX"
      },
      "source": [
        "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcf45c7-1b90-44f0-eda1-56421ce77748"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwjD2-ebTeUX"
      },
      "source": [
        "**Lots of stopwords!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmrz2aoXjKY7",
        "outputId": "7093b7b8-8674-41df-be3b-fa6882405179"
      },
      "source": [
        "item = next(iter(train_iterator))\n",
        "print(item.tweets[0].shape)\n",
        "print(item.tweets[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 8])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SQBxxksipUq"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAfcQLpRisvt"
      },
      "source": [
        "hparams = OmegaConf.create({\n",
        "    'epochs':10,\n",
        "    'batch_size':32,\n",
        "    'learning_rate':0.0001,\n",
        "    'input_dim':len(Tweet.vocab),\n",
        "    'embedding_dim':300,\n",
        "    'enc_hidden_dim':150,\n",
        "    'dec_hidden_dim':150,\n",
        "    'output_dim':len(Label.vocab),\n",
        "    'dropout': 0.3,\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKMIQCyijKfF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "f263d0896d0a4b6199380cad43b52428",
            "63ca32ea8fb44319920bea51328eb6bc",
            "26b04d7c58ca4adeafece4c5b5db31ca",
            "8a198b9390c64ab5b1563e16ba328c28",
            "40a9d40ed0d74d289b8fdaafcd0162cc",
            "d16b7f5aee5647b1846daaccfc7d7306",
            "f72bc0dc9eee42048e2174fb87ddc31b",
            "442fe868c30d48fdb22130d8eef0a33e"
          ]
        },
        "outputId": "03ac88d6-3c73-4038-9f89-2760690f2569"
      },
      "source": [
        "wandb.init(project='Encoder-Decoder-lstm-classification')\n",
        "config = wandb.config\n",
        "config = hparams\n",
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:10ncw029) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 385<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f263d0896d0a4b6199380cad43b52428",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210607_175954-10ncw029/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210607_175954-10ncw029/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">apricot-star-1</strong>: <a href=\"https://wandb.ai/namanphy/Encoder-Decoder-lstm-classification/runs/10ncw029\" target=\"_blank\">https://wandb.ai/namanphy/Encoder-Decoder-lstm-classification/runs/10ncw029</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:10ncw029). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">snowy-puddle-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/namanphy/Encoder-Decoder-lstm-classification\" target=\"_blank\">https://wandb.ai/namanphy/Encoder-Decoder-lstm-classification</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/namanphy/Encoder-Decoder-lstm-classification/runs/2a8r8yv3\" target=\"_blank\">https://wandb.ai/namanphy/Encoder-Decoder-lstm-classification/runs/2a8r8yv3</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210607_182726-2a8r8yv3</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 10, 'batch_size': 32, 'learning_rate': 0.0001, 'input_dim': 4651, 'embedding_dim': 300, 'enc_hidden_dim': 150, 'dec_hidden_dim': 150, 'output_dim': 3, 'dropout': 0.3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot2jS4EZoYmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PED4HJWH4t"
      },
      "source": [
        "We use the Embedding and LSTM modules in PyTorch to build a simple model for classifying tweets.\n",
        "\n",
        "In this model we create three layers. \n",
        "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
        "2. That’s then fed into a 2 stacked-LSTMs with 100 hidden features (again, we’re compressing down from the 300-dimensional input like we did with images). We are using 2 LSTMs for using the dropout.\n",
        "3. Finally, the output of the LSTM (the final hidden state after processing the incoming tweet) is pushed through a standard fully connected layer with three outputs to correspond to our three possible classes (negative, positive, or neutral).printppp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ha-28FKiMVt"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jllpcmDwiKg2"
      },
      "source": [
        "class lstm_encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, n_layers, dropout):\n",
        "        super(lstm_encoder, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, input, input_lengths):\n",
        "        print('Shapes Insider Encoders :')\n",
        "        print('\\t Input Length : ', len(input), '\\n\\t\\t Data : ', input.data.shape)\n",
        "        print('\\t Input Lengths : ', input_lengths.shape)\n",
        "\n",
        "        embedded_input = self.embedding(input)\n",
        "        packed_embedded_input = nn.utils.rnn.pack_padded_sequence(embedded_input, input_lengths.cpu(), batch_first=True)\n",
        "\n",
        "        print('\\t Embeddings : ', embedded_input.shape, '\\n\\t\\t Packed Embedded inout : ', packed_embedded_input.data.shape)\n",
        "                \n",
        "        output, (hidden, cell) = self.lstm(packed_embedded_input)\n",
        "\n",
        "        return output, (hidden, cell)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxvTjIDkkUVr"
      },
      "source": [
        "class lstm_decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dropout=0):\n",
        "        super(lstm_decoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, dropout=dropout)\n",
        "\n",
        "    def forward(self, input, hidden_encoder, cell_encoder):\n",
        "        output, (hidden, cell) = self.lstm(input, (hidden_encoder, cell_encoder))\n",
        "\n",
        "        return output, (hidden, cell)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "class classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, batch_size, n_layers, dropout):        \n",
        "        super(classifier, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.encoder = lstm_encoder(vocab_size, embedding_dim, hidden_dim, n_layers, dropout)\n",
        "        self.decoder = lstm_decoder(embedding_dim, hidden_dim, dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        encoder_output, (encoder_hidden, encoder_cell) = self.encoder(text, text_lengths)\n",
        "\n",
        "        print('Shapes of Encoders :')\n",
        "        print('\\t Output Length : ', len(encoder_output), '\\n\\t\\t Data : ', encoder_output.data.shape, \n",
        "              '\\n\\t\\t Batch size : ', encoder_output.batch_sizes)\n",
        "        print('\\t Hidden : ', encoder_hidden.shape)\n",
        "        print('\\t Cell Length : ', len(encoder_cell), '\\n\\t\\t Data Shape : ', encoder_cell.data.shape, \n",
        "              '\\n\\t\\t Data : ', encoder_cell)\n",
        "\n",
        "        print(\"-------------------------------------------\")\n",
        "        \n",
        "        decoder_first_input = self.get_decoder_input(encoder_hidden.shape) # pass decoder hidden shape\n",
        "        decoder_output, (decoder_hidden, decoder_cell) = self.decoder(decoder_first_input, encoder_hidden, encoder_cell)\n",
        "        \n",
        "        print('Shapes of Decoders :')\n",
        "        print('\\t Output Length : ', len(decoder_output), '\\n\\t\\t Data : ', decoder_output.data.shape)\n",
        "        print('\\t Hidden : ', decoder_hidden.shape)\n",
        "        print('\\t Cell Length : ', len(decoder_cell), '\\n\\t\\t Data Shape : ', decoder_cell.data.shape, \n",
        "              '\\n\\t\\t Data : ', decoder_cell)\n",
        "        print(\"\\n\\n\")\n",
        "        final_outputs = self.fc(decoder_hidden)\n",
        "        return final_outputs\n",
        "\n",
        "    def get_decoder_input(self, hidden_shape, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
        "        return torch.zeros(1, hidden_shape[1], self.embedding_dim).to(device)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NColQ_R2s8_7",
        "outputId": "655a59d0-2516-4d59-b2a2-3fb0f58637bc"
      },
      "source": [
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 10, 'batch_size': 32, 'learning_rate': 0.0001, 'input_dim': 4651, 'embedding_dim': 300, 'enc_hidden_dim': 150, 'dec_hidden_dim': 150, 'output_dim': 3, 'dropout': 0.3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2cb19d-d818-46ba-fad8-725f4d3590ac"
      },
      "source": [
        "# # Define hyperparameters\n",
        "# size_of_vocab = len(Tweet.vocab)\n",
        "# embedding_dim = 300\n",
        "# num_hidden_nodes = 100\n",
        "# num_output_nodes = 3\n",
        "# num_layers = 1\n",
        "# dropout = 0.2\n",
        "\n",
        "# # Instantiate the model\n",
        "# model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, 32, num_layers, dropout = dropout)\n",
        "\n",
        "model = classifier(config.input_dim, config.embedding_dim, config.enc_hidden_dim, config.output_dim, config.batch_size,\n",
        "                   1, config.dropout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969c6377-ae6d-4c51-f8d2-aceccbcae3fd"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (encoder): lstm_encoder(\n",
            "    (embedding): Embedding(4651, 300)\n",
            "    (lstm): LSTM(300, 150, batch_first=True, dropout=0.3)\n",
            "  )\n",
            "  (decoder): lstm_decoder(\n",
            "    (lstm): LSTM(300, 150, dropout=0.3)\n",
            "  )\n",
            "  (fc): Linear(in_features=150, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,938,153 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VCJtNb3Zt8w"
      },
      "source": [
        "The main thing to be aware of in this new training loop is that we have to reference `batch.tweets` and `batch.labels` to get the particular fields we’re interested in; they don’t fall out quite as nicely from the enumerator as they do in torchvision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WjEPLKsAiS_"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZcHhkkvAsCt"
      },
      "source": [
        "**Evaluation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a357e7-98a3-4c34-ac83-7c0515b479c7"
      },
      "source": [
        "N_EPOCHS = config.epochs\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "wandb.watch(model, criterion, log='all', log_freq=10)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    wandb.log({\n",
        "        'train loss': train_loss,\n",
        "        'train acc': train_acc*100,\n",
        "        'val loss': valid_loss,\n",
        "        'val acc': valid_acc*100\n",
        "    })\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 28, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([884, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([884, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 20])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6561,  0.6684, -1.2487,  ...,  0.4775, -0.5191, -1.7716],\n",
            "         [-0.2995,  1.6167, -0.6769,  ..., -0.5065, -1.1548, -0.3950],\n",
            "         [-0.4268,  0.4422, -0.3564,  ..., -0.2738, -1.2414,  0.1167],\n",
            "         ...,\n",
            "         [-0.6158,  1.0526, -0.5168,  ..., -0.7725, -1.0073, -1.0402],\n",
            "         [-0.9183,  0.6789, -0.9880,  ..., -0.0736, -0.6529, -0.5154],\n",
            "         [-0.8821,  1.9856,  0.0292,  ..., -1.4550, -1.9144, -0.6516]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5832,  0.6174, -0.9316,  ...,  0.3219, -0.3371, -0.7843],\n",
            "         [-0.4491,  1.1136, -0.6120,  ..., -0.0977, -1.1451,  0.1298],\n",
            "         [-0.4667,  0.3553, -0.2776,  ..., -0.0256, -1.0303,  0.3597],\n",
            "         ...,\n",
            "         [-0.4656,  0.7316, -0.6126,  ..., -0.3450, -0.4447, -0.4735],\n",
            "         [-0.7289,  0.6658, -0.8368,  ...,  0.1225, -0.5096, -0.1732],\n",
            "         [-0.7193,  1.2615, -0.1647,  ..., -0.5465, -1.2958, -0.0866]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 16])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 16, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([482, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([482, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-2.3047e-01,  6.6611e-01, -1.9140e-01,  ...,  9.0658e-04,\n",
            "          -1.5566e+00, -8.3499e-01],\n",
            "         [ 4.0563e-02,  4.1181e-01, -3.2124e-01,  ..., -2.0310e-01,\n",
            "          -4.1014e-01,  1.6584e-02],\n",
            "         [-1.1271e+00,  9.2511e-01, -1.1611e+00,  ..., -3.0617e-01,\n",
            "          -8.7455e-01, -8.1991e-01],\n",
            "         ...,\n",
            "         [-1.3023e+00,  1.2117e+00, -1.3809e+00,  ..., -1.1542e+00,\n",
            "          -1.1178e+00, -8.4725e-01],\n",
            "         [-9.1983e-01,  8.8946e-01,  1.3889e-01,  ..., -4.0590e-01,\n",
            "          -5.6038e-01, -2.4105e-01],\n",
            "         [-9.3723e-01,  8.2793e-01, -7.3054e-01,  ..., -8.8375e-01,\n",
            "          -1.1352e+00, -8.2671e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3252,  0.6306, -0.3531,  ...,  0.1014, -0.9499, -0.2874],\n",
            "         [-0.1013,  0.3248, -0.2185,  ..., -0.0300, -0.4443,  0.2580],\n",
            "         [-0.8398,  0.8560, -1.0380,  ..., -0.0108, -0.7070, -0.3528],\n",
            "         ...,\n",
            "         [-0.9967,  1.0082, -1.1243,  ..., -0.5073, -0.6911, -0.1541],\n",
            "         [-0.6429,  0.6989, -0.0190,  ..., -0.2133, -0.4671, -0.0485],\n",
            "         [-0.9406,  0.7838, -0.6552,  ..., -0.3267, -0.9844, -0.1606]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 6])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 6, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([126, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([126, 150]) \n",
            "\t\t Batch size :  tensor([32, 28, 26, 23, 14,  3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8653,  0.9384, -0.6057,  ..., -1.2826, -0.9752, -0.2790],\n",
            "         [-1.0237,  1.3430, -0.5316,  ..., -1.0146, -1.0223, -0.9662],\n",
            "         [-0.1545,  1.2704, -1.1533,  ..., -1.1338, -0.8248, -1.1154],\n",
            "         ...,\n",
            "         [-0.2132,  0.3946, -0.0168,  ...,  0.1441,  0.1663, -0.0478],\n",
            "         [-0.3616,  0.2672, -0.3943,  ..., -0.0825,  0.0664, -0.6112],\n",
            "         [ 0.0642,  0.2493, -0.3329,  ...,  0.3812, -0.3355, -0.2924]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-6.3961e-01,  7.8817e-01, -5.1761e-01,  ..., -5.5370e-01,\n",
            "          -7.3981e-01, -4.0202e-02],\n",
            "         [-7.3313e-01,  1.1175e+00, -5.9794e-01,  ..., -4.3302e-01,\n",
            "          -6.5023e-01, -2.7433e-01],\n",
            "         [-3.1856e-01,  7.9312e-01, -9.6291e-01,  ..., -5.2079e-01,\n",
            "          -4.1328e-01, -4.9721e-01],\n",
            "         ...,\n",
            "         [-1.7656e-01,  3.5789e-01,  7.1238e-04,  ...,  6.3850e-02,\n",
            "          -2.6635e-02, -2.1866e-02],\n",
            "         [-2.7452e-01,  2.4135e-01, -2.3277e-01,  ...,  2.5245e-02,\n",
            "          -5.4787e-02, -3.3382e-01],\n",
            "         [-5.2681e-02,  1.7476e-01, -2.1385e-01,  ...,  2.6255e-01,\n",
            "          -1.7081e-01, -1.4595e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1186, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1186, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27,\n",
            "        20,  8,  6,  5])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3083,  1.3703, -1.1842,  ..., -1.1243, -1.1585, -1.8387],\n",
            "         [-1.3083,  1.3703, -1.1842,  ..., -1.1243, -1.1585, -1.8387],\n",
            "         [-1.3083,  1.3703, -1.1842,  ..., -1.1243, -1.1585, -1.8387],\n",
            "         ...,\n",
            "         [-0.6135,  0.7399, -0.9636,  ..., -1.0637, -1.1134, -0.6466],\n",
            "         [-1.3196,  1.2794, -0.2684,  ..., -2.2375, -0.7600, -0.7126],\n",
            "         [-0.5583,  1.6865, -0.6599,  ..., -0.6695, -0.7929, -0.4465]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0772,  1.2729, -1.1699,  ..., -0.4796, -0.9356, -0.9079],\n",
            "         [-1.0772,  1.2729, -1.1699,  ..., -0.4796, -0.9356, -0.9079],\n",
            "         [-1.0772,  1.2729, -1.1699,  ..., -0.4796, -0.9356, -0.9079],\n",
            "         ...,\n",
            "         [-0.4977,  0.6539, -0.7834,  ..., -0.4132, -0.6766, -0.2187],\n",
            "         [-0.9207,  0.9917, -0.3822,  ..., -1.0400, -0.5267, -0.3485],\n",
            "         [-0.6549,  1.0794, -0.6085,  ..., -0.2152, -0.7929,  0.0201]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 19])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 19, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([579, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([579, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "         3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6243,  0.9227, -0.4597,  ..., -1.5644, -0.4299, -0.2315],\n",
            "         [-0.3568,  1.0014, -0.8211,  ..., -0.9911, -0.7834, -1.2219],\n",
            "         [-1.0579,  1.4384, -1.4397,  ..., -1.0093, -0.7626, -1.4973],\n",
            "         ...,\n",
            "         [-0.5449,  0.8802, -0.7354,  ..., -0.7684, -0.9705, -0.1062],\n",
            "         [-0.7556,  1.1938, -0.2139,  ..., -1.3130, -0.2944, -1.0265],\n",
            "         [ 0.0423,  0.4924, -0.0851,  ..., -0.7500,  0.1244,  0.1476]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5980,  0.8059, -0.4389,  ..., -0.7197, -0.3433,  0.0920],\n",
            "         [-0.3870,  0.6964, -0.6326,  ..., -0.4004, -0.5613, -0.4851],\n",
            "         [-0.8470,  1.0202, -1.2978,  ..., -0.4875, -0.5247, -0.6703],\n",
            "         ...,\n",
            "         [-0.6221,  0.7461, -0.6251,  ..., -0.2911, -0.8844,  0.2433],\n",
            "         [-0.6170,  1.0623, -0.3271,  ..., -0.6319, -0.2915, -0.3186],\n",
            "         [-0.1937,  0.4245, -0.0646,  ..., -0.4290,  0.0458,  0.1114]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 10])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 10, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([320, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([320, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.5095,  1.2777, -0.5653,  ..., -1.2604, -1.9983, -0.9747],\n",
            "         [ 0.3903,  0.1336, -0.1805,  ..., -0.3013,  0.0087, -0.8244],\n",
            "         [-0.6652,  0.4818, -0.5792,  ...,  0.3489, -0.7899, -0.0334],\n",
            "         ...,\n",
            "         [-1.1004,  0.9223, -1.1610,  ..., -0.4691, -0.1315, -0.4571],\n",
            "         [-0.4858,  1.8595, -0.4339,  ..., -0.6095, -1.2222, -0.0617],\n",
            "         [-1.5095,  1.2777, -0.5653,  ..., -1.2604, -1.9983, -0.9747]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1169,  1.0205, -0.6997,  ..., -0.6072, -1.2275, -0.3823],\n",
            "         [ 0.0711,  0.1394, -0.0419,  ..., -0.1763, -0.0570, -0.3070],\n",
            "         [-0.5183,  0.5235, -0.5023,  ...,  0.2362, -0.3505,  0.0977],\n",
            "         ...,\n",
            "         [-0.8871,  0.7375, -0.9063,  ..., -0.1014, -0.2262, -0.1770],\n",
            "         [-0.5884,  1.1737, -0.4229,  ..., -0.1591, -1.0146,  0.2936],\n",
            "         [-1.1169,  1.0205, -0.6997,  ..., -0.6072, -1.2275, -0.3823]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 27])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 27, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([838, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([838, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32,  6])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0745,  1.1108, -0.6207,  ..., -1.4693, -0.1957, -1.0227],\n",
            "         [-0.8878,  1.0878, -0.8906,  ..., -1.7654, -1.9581, -0.5128],\n",
            "         [-0.1441,  0.2813, -0.0933,  ..., -0.2605,  0.0152,  0.0633],\n",
            "         ...,\n",
            "         [-0.6242,  0.3715,  0.0573,  ..., -0.2142, -0.5900,  0.1659],\n",
            "         [ 0.4561,  0.4038, -0.3808,  ..., -0.4070, -1.0460, -0.0528],\n",
            "         [-0.8028,  1.5473, -0.1972,  ..., -0.8863, -1.1827, -0.7538]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2164,  0.8498, -0.4773,  ..., -0.8565, -0.1417, -0.3768],\n",
            "         [-0.7187,  0.9596, -0.8784,  ..., -0.7829, -1.2880, -0.1023],\n",
            "         [-0.1612,  0.1940, -0.2067,  ..., -0.1206, -0.0452,  0.1340],\n",
            "         ...,\n",
            "         [-0.5477,  0.4235, -0.0877,  ..., -0.0156, -0.3270,  0.2080],\n",
            "         [ 0.1505,  0.3322, -0.2281,  ..., -0.2312, -0.4950, -0.0466],\n",
            "         [-0.5907,  1.1994, -0.3599,  ..., -0.3745, -0.7451, -0.1306]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 24])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 24, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([762, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([762, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 26])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.4581,  0.4024, -0.3797,  ..., -0.4057, -1.0437, -0.0513],\n",
            "         [ 0.1179,  0.8322, -0.6041,  ..., -1.5511, -0.6031,  0.1956],\n",
            "         [ 0.1033,  0.1131,  0.0770,  ..., -0.0921, -0.1559,  0.0238],\n",
            "         ...,\n",
            "         [-0.8602,  0.4966, -0.8578,  ..., -1.4871, -2.3930, -1.2635],\n",
            "         [-0.2456,  0.6474, -0.1343,  ..., -0.2077, -1.2589,  0.1298],\n",
            "         [-0.7426,  0.4253, -0.3968,  ..., -0.9391, -1.9762,  0.4445]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.1524,  0.3307, -0.2265,  ..., -0.2311, -0.4934, -0.0462],\n",
            "         [-0.2864,  0.6557, -0.6652,  ..., -0.7488, -0.4577,  0.2123],\n",
            "         [-0.0297,  0.2166, -0.0635,  ..., -0.0522, -0.1133,  0.0450],\n",
            "         ...,\n",
            "         [-0.6778,  0.6613, -0.8629,  ..., -0.6581, -1.5502, -0.3721],\n",
            "         [-0.3394,  0.6117, -0.2998,  ...,  0.0620, -0.7781,  0.1767],\n",
            "         [-0.7137,  0.5113, -0.4046,  ..., -0.3295, -1.1055,  0.3767]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 14])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 14, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([448, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([448, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2787,  0.6397,  0.1277,  ..., -0.6442, -0.6417, -0.6027],\n",
            "         [-0.0922,  0.4309,  0.4220,  ..., -0.0154, -0.1420,  0.3474],\n",
            "         [-0.0922,  0.4309,  0.4220,  ..., -0.0154, -0.1420,  0.3474],\n",
            "         ...,\n",
            "         [-0.1786,  0.8142, -0.5100,  ..., -0.8706, -0.9390, -0.9530],\n",
            "         [-0.6727,  1.2940, -0.6833,  ..., -1.3958, -0.6334, -1.3098],\n",
            "         [-1.2540,  0.9026, -0.2073,  ..., -0.8734, -0.7622, -1.0117]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3370,  0.5465, -0.1369,  ..., -0.2698, -0.4192, -0.1846],\n",
            "         [-0.2072,  0.3290,  0.1614,  ...,  0.1333, -0.1282,  0.2567],\n",
            "         [-0.2072,  0.3290,  0.1614,  ...,  0.1333, -0.1282,  0.2567],\n",
            "         ...,\n",
            "         [-0.2166,  0.5833, -0.5738,  ..., -0.4225, -0.3911, -0.4829],\n",
            "         [-0.5633,  0.8610, -0.6496,  ..., -0.7302, -0.4473, -0.4669],\n",
            "         [-1.0902,  0.9711, -0.4969,  ..., -0.3727, -0.6325, -0.4119]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 22])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 22, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([688, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([688, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 16])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2968,  0.9702, -0.2014,  ..., -0.2628, -0.6596, -0.2687],\n",
            "         [ 0.0303,  0.0888, -0.6355,  ..., -0.6839,  0.0851, -0.0794],\n",
            "         [ 0.1348, -0.3558, -0.3941,  ...,  0.2061, -0.3344, -0.3851],\n",
            "         ...,\n",
            "         [ 0.1418,  0.1971,  0.1406,  ...,  0.3963, -0.7057, -0.4113],\n",
            "         [ 0.1528,  0.9049, -0.6947,  ..., -0.0854, -0.6428, -0.3061],\n",
            "         [-0.0689, -0.6273, -0.2107,  ...,  0.1374, -0.1036, -0.3292]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2797,  0.6360, -0.3139,  ..., -0.1012, -0.4800, -0.0581],\n",
            "         [-0.0394,  0.1142, -0.3435,  ..., -0.3476,  0.0204,  0.0616],\n",
            "         [-0.1708, -0.0878, -0.3479,  ...,  0.1832, -0.1956, -0.1094],\n",
            "         ...,\n",
            "         [ 0.0057,  0.1920, -0.0049,  ...,  0.2814, -0.3391, -0.1232],\n",
            "         [-0.0919,  0.5341, -0.6566,  ...,  0.0516, -0.1350, -0.1646],\n",
            "         [-0.1043, -0.1906, -0.2299,  ...,  0.0203, -0.0773, -0.0892]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 13])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 13, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([387, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([387, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27,  8])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2428,  0.3514, -0.7071,  ..., -0.1624, -0.4039,  0.0795],\n",
            "         [-0.3715,  0.7124, -1.3896,  ...,  0.1968, -0.8447, -0.2350],\n",
            "         [-1.5857,  1.8803, -0.9545,  ..., -1.4729, -1.5731, -1.3846],\n",
            "         ...,\n",
            "         [-0.7992,  0.4674, -0.7487,  ..., -0.2076, -1.2386,  0.4082],\n",
            "         [-0.6230,  0.5020, -0.6227,  ...,  0.2553, -0.1540, -0.2935],\n",
            "         [-0.9432,  1.2173, -0.1576,  ..., -0.0790, -1.1509, -1.2600]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3232,  0.3532, -0.6089,  ...,  0.0077, -0.3435,  0.1609],\n",
            "         [-0.3183,  0.5757, -1.0079,  ...,  0.0556, -0.5735,  0.0661],\n",
            "         [-1.0837,  1.2449, -0.9282,  ..., -0.7180, -0.9853, -0.5923],\n",
            "         ...,\n",
            "         [-0.7261,  0.6050, -0.7203,  ...,  0.0021, -0.8153,  0.3203],\n",
            "         [-0.5070,  0.5227, -0.5149,  ...,  0.2376, -0.1712,  0.0591],\n",
            "         [-0.8915,  1.0692, -0.3382,  ...,  0.1026, -0.7811, -0.6394]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 33])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 33, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1009, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1009, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 15,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0735,  1.6592, -2.6438,  ..., -1.0638, -1.0506, -1.4079],\n",
            "         [-0.4066,  1.3760, -0.2272,  ..., -0.3280, -1.0409, -0.1020],\n",
            "         [-0.6760,  1.0084, -1.2168,  ..., -1.0309, -0.8422, -0.9055],\n",
            "         ...,\n",
            "         [-0.9319,  1.0039, -0.3936,  ..., -1.6723, -1.1589, -0.4593],\n",
            "         [-0.5056,  0.9934, -0.6748,  ..., -1.5739, -0.7600, -0.4549],\n",
            "         [-1.2978,  0.9006, -0.1795,  ..., -0.4029, -0.3054, -0.7374]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7887,  1.0190, -2.1602,  ..., -0.5062, -0.6218, -0.6301],\n",
            "         [-0.4140,  0.9063, -0.1991,  ..., -0.0024, -0.8680,  0.1322],\n",
            "         [-0.5647,  0.7727, -1.1443,  ..., -0.4827, -0.4586, -0.3575],\n",
            "         ...,\n",
            "         [-0.7348,  0.8827, -0.4489,  ..., -0.7619, -0.8437, -0.0663],\n",
            "         [-0.4815,  0.8213, -0.5490,  ..., -0.7416, -0.5964, -0.0959],\n",
            "         [-0.8292,  0.6808, -0.1609,  ..., -0.1109, -0.2901, -0.2423]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3430,  1.4219, -1.2344,  ..., -1.1542, -1.1851, -1.9283],\n",
            "         [-1.3430,  1.4219, -1.2344,  ..., -1.1542, -1.1851, -1.9283],\n",
            "         [-1.3430,  1.4219, -1.2344,  ..., -1.1542, -1.1851, -1.9283],\n",
            "         ...,\n",
            "         [-1.3430,  1.4219, -1.2344,  ..., -1.1542, -1.1851, -1.9283],\n",
            "         [-1.3430,  1.4219, -1.2344,  ..., -1.1542, -1.1851, -1.9283],\n",
            "         [-1.3430,  1.4219, -1.2344,  ..., -1.1542, -1.1851, -1.9283]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1095,  1.3194, -1.2191,  ..., -0.5060, -0.9611, -0.9656],\n",
            "         [-1.1095,  1.3194, -1.2191,  ..., -0.5060, -0.9611, -0.9656],\n",
            "         [-1.1095,  1.3194, -1.2191,  ..., -0.5060, -0.9611, -0.9656],\n",
            "         ...,\n",
            "         [-1.1095,  1.3194, -1.2191,  ..., -0.5060, -0.9611, -0.9656],\n",
            "         [-1.1095,  1.3194, -1.2191,  ..., -0.5060, -0.9611, -0.9656],\n",
            "         [-1.1095,  1.3194, -1.2191,  ..., -0.5060, -0.9611, -0.9656]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 30])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 30, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([959, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([959, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4469,  0.9104, -0.9148,  ..., -1.2184, -0.6554, -0.4606],\n",
            "         [-1.0258,  1.8804, -1.7091,  ..., -0.3766, -0.8103, -1.3003],\n",
            "         [-0.3439,  0.4470, -0.2510,  ..., -0.3435, -0.8544, -0.3037],\n",
            "         ...,\n",
            "         [-0.5254,  1.3939, -0.4616,  ..., -0.3431, -0.5612, -0.4827],\n",
            "         [-2.3454,  1.1012, -0.2695,  ..., -1.6341, -1.1585, -0.5617],\n",
            "         [-0.9785,  1.0480, -0.1730,  ..., -0.4751, -0.9329, -0.6681]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5812,  0.6595, -0.7245,  ..., -0.6327, -0.5043, -0.1061],\n",
            "         [-0.8225,  1.2065, -1.4764,  ..., -0.0971, -0.5669, -0.5867],\n",
            "         [-0.4391,  0.3712, -0.2094,  ..., -0.0465, -0.7171,  0.1253],\n",
            "         ...,\n",
            "         [-0.5325,  0.8044, -0.2941,  ..., -0.0240, -0.6900,  0.0171],\n",
            "         [-1.6153,  1.0031, -0.4739,  ..., -0.7318, -0.8070, -0.0490],\n",
            "         [-0.7652,  0.8669, -0.3015,  ..., -0.1232, -0.6680, -0.2257]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 15])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 15, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([476, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([476, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0645,  0.8860, -0.8245,  ..., -0.9755, -1.1972, -1.0170],\n",
            "         [-0.5330,  0.8577, -0.7299,  ..., -0.7694, -0.9511, -0.1048],\n",
            "         [-0.3495,  0.8003, -0.2571,  ..., -0.4304, -1.0827, -0.9192],\n",
            "         ...,\n",
            "         [-0.0921,  0.4287,  0.4244,  ..., -0.0057, -0.1513,  0.3537],\n",
            "         [-0.7272,  1.3874, -0.7500,  ..., -0.8814, -0.8650, -1.2637],\n",
            "         [-0.5276,  0.8300,  0.2379,  ..., -0.4666,  0.1587, -0.5202]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0298,  0.8568, -0.7620,  ..., -0.4008, -1.0334, -0.2927],\n",
            "         [-0.6175,  0.7401, -0.6184,  ..., -0.2934, -0.8731,  0.2422],\n",
            "         [-0.4286,  0.6112, -0.3468,  ..., -0.0760, -1.0672, -0.1168],\n",
            "         ...,\n",
            "         [-0.2072,  0.3266,  0.1626,  ...,  0.1405, -0.1351,  0.2642],\n",
            "         [-0.6252,  0.9659, -0.8579,  ..., -0.3669, -0.4963, -0.6184],\n",
            "         [-0.3822,  0.5417,  0.0944,  ..., -0.2272,  0.0314, -0.1770]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 23])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 23, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([705, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([705, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32,  1])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5502,  0.1887, -0.6210,  ..., -0.9713, -0.5166, -0.9551],\n",
            "         [-0.1798,  0.0852, -0.4405,  ...,  0.1591, -0.6526, -0.0735],\n",
            "         [-0.1963,  0.4195, -0.1515,  ..., -0.5583, -0.7777, -0.3327],\n",
            "         ...,\n",
            "         [-0.9651,  0.8932, -0.1549,  ..., -0.4680, -0.4316, -0.3614],\n",
            "         [-0.9245,  1.5175, -2.4941,  ..., -1.0234, -0.7550, -1.8561],\n",
            "         [-0.9364,  0.8626,  0.0140,  ..., -0.4448, -0.4173, -0.3180]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5010,  0.1302, -0.3519,  ..., -0.4407, -0.4438, -0.2977],\n",
            "         [-0.2223,  0.1530, -0.4463,  ...,  0.1434, -0.4133, -0.0414],\n",
            "         [-0.3794,  0.3329, -0.1566,  ..., -0.1480, -0.7301,  0.0097],\n",
            "         ...,\n",
            "         [-0.7575,  0.6844, -0.2440,  ..., -0.1489, -0.4376,  0.0467],\n",
            "         [-0.7845,  0.9690, -1.9747,  ..., -0.5083, -0.5343, -0.8833],\n",
            "         [-0.7378,  0.6570, -0.1513,  ..., -0.1412, -0.4258,  0.0498]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3439,  1.4222, -1.2412,  ..., -1.1571, -1.1906, -1.9362],\n",
            "         [-1.3439,  1.4222, -1.2412,  ..., -1.1571, -1.1906, -1.9362],\n",
            "         [-1.3439,  1.4222, -1.2412,  ..., -1.1571, -1.1906, -1.9362],\n",
            "         ...,\n",
            "         [-1.3439,  1.4222, -1.2412,  ..., -1.1571, -1.1906, -1.9362],\n",
            "         [-1.3439,  1.4222, -1.2412,  ..., -1.1571, -1.1906, -1.9362],\n",
            "         [-1.3439,  1.4222, -1.2412,  ..., -1.1571, -1.1906, -1.9362]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1133,  1.3239, -1.2254,  ..., -0.5113, -0.9662, -0.9751],\n",
            "         [-1.1133,  1.3239, -1.2254,  ..., -0.5113, -0.9662, -0.9751],\n",
            "         [-1.1133,  1.3239, -1.2254,  ..., -0.5113, -0.9662, -0.9751],\n",
            "         ...,\n",
            "         [-1.1133,  1.3239, -1.2254,  ..., -0.5113, -0.9662, -0.9751],\n",
            "         [-1.1133,  1.3239, -1.2254,  ..., -0.5113, -0.9662, -0.9751],\n",
            "         [-1.1133,  1.3239, -1.2254,  ..., -0.5113, -0.9662, -0.9751]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 35])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 35, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1078, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1078, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 18,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6608,  1.7562, -1.1724,  ..., -1.0624, -1.0316, -0.7839],\n",
            "         [-0.3229,  0.3821,  0.3482,  ...,  0.1104,  0.0399,  0.4157],\n",
            "         [-0.6608,  1.7562, -1.1724,  ..., -1.0624, -1.0316, -0.7839],\n",
            "         ...,\n",
            "         [-0.5502,  1.2366, -1.0687,  ..., -1.2266, -0.8205, -0.9875],\n",
            "         [-1.2522,  1.8314, -0.4337,  ..., -1.3462, -1.3187, -1.4521],\n",
            "         [-0.4222,  0.8458, -0.3943,  ..., -0.2542, -1.0119, -0.1120]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5255,  1.0392, -1.0969,  ..., -0.5111, -0.4867, -0.3807],\n",
            "         [-0.3067,  0.3771,  0.1027,  ...,  0.0727, -0.0371,  0.3436],\n",
            "         [-0.5255,  1.0392, -1.0969,  ..., -0.5111, -0.4867, -0.3807],\n",
            "         ...,\n",
            "         [-0.4163,  0.6517, -0.7841,  ..., -0.5880, -0.4026, -0.4092],\n",
            "         [-0.9067,  1.3934, -0.5592,  ..., -0.6401, -0.9361, -0.4576],\n",
            "         [-0.4507,  0.6063, -0.2911,  ..., -0.0023, -0.9269,  0.2346]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 23])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 23, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([736, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([736, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4926, -0.1017, -0.0986,  ..., -0.1389, -0.9312, -0.7724],\n",
            "         [-0.6755,  1.1954, -0.4419,  ..., -1.2834, -1.3382, -0.3091],\n",
            "         [ 0.0055,  0.0523, -0.2801,  ..., -0.4614, -0.2183, -0.6334],\n",
            "         ...,\n",
            "         [-1.4360,  0.4482, -0.8485,  ..., -1.1063, -1.6760, -0.4074],\n",
            "         [-0.7082,  1.5995, -0.7760,  ..., -0.7790, -1.1945, -1.0682],\n",
            "         [-1.3881,  1.0980, -1.0503,  ..., -0.4134, -0.7720, -1.4133]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3309,  0.1436, -0.1790,  ..., -0.0711, -0.5581, -0.2751],\n",
            "         [-0.6374,  0.9863, -0.4612,  ..., -0.6431, -0.7984,  0.0035],\n",
            "         [-0.0384,  0.1628, -0.1104,  ..., -0.2565, -0.0988, -0.2256],\n",
            "         ...,\n",
            "         [-0.8622,  0.4402, -0.6994,  ..., -0.4531, -0.9517, -0.1197],\n",
            "         [-0.7384,  1.2014, -0.6497,  ..., -0.2438, -1.0371, -0.2621],\n",
            "         [-1.1577,  1.0161, -1.0395,  ..., -0.1194, -0.5848, -0.7706]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 8])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 8, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([218, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([218, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 23,  3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3915,  0.8840, -0.3635,  ..., -0.5295, -1.1157, -0.6628],\n",
            "         [-0.8249, -0.3493, -0.6170,  ..., -0.5629, -0.2308, -0.7866],\n",
            "         [-0.4296,  0.6479,  0.3985,  ..., -0.5733, -0.5393, -0.1371],\n",
            "         ...,\n",
            "         [-0.1927,  0.2057, -0.1409,  ..., -0.3814,  0.0378,  0.3551],\n",
            "         [-0.7844,  0.7138, -0.0305,  ..., -0.5465,  0.3419, -0.5462],\n",
            "         [-0.0501,  0.8876, -1.1149,  ...,  0.6879,  0.5169, -0.3910]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5631,  0.7328, -0.4243,  ..., -0.1282, -0.9781, -0.1336],\n",
            "         [-0.5726,  0.0633, -0.6212,  ..., -0.2645, -0.2034, -0.1958],\n",
            "         [-0.5008,  0.6352,  0.1320,  ..., -0.2782, -0.4763,  0.0417],\n",
            "         ...,\n",
            "         [-0.2164,  0.2570, -0.2983,  ..., -0.1733, -0.0481,  0.2968],\n",
            "         [-0.5373,  0.6241, -0.1942,  ..., -0.2456,  0.0219, -0.1790],\n",
            "         [-0.1533,  0.6295, -0.6445,  ...,  0.5155,  0.2165, -0.0778]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([906, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([906, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 10])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3918,  0.8209, -0.3647,  ..., -0.2348, -0.9864, -0.0720],\n",
            "         [-0.6298,  0.8094, -1.5618,  ..., -0.6218, -0.4466, -1.4002],\n",
            "         [-0.1847,  1.0404, -0.6257,  ...,  0.0548, -0.4843, -0.3365],\n",
            "         ...,\n",
            "         [-0.6825,  0.3031, -0.5682,  ..., -0.7805, -0.6548, -0.3079],\n",
            "         [-0.7431,  2.7539, -2.6737,  ..., -1.6215, -0.8734, -1.6174],\n",
            "         [-0.1101,  0.0293, -0.0486,  ...,  0.2954,  0.0495, -0.7216]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4256,  0.5856, -0.2684,  ...,  0.0025, -0.8986,  0.2504],\n",
            "         [-0.5603,  0.4714, -0.9583,  ..., -0.2763, -0.4517, -0.6646],\n",
            "         [-0.3141,  0.5853, -0.4067,  ...,  0.1171, -0.3064, -0.1923],\n",
            "         ...,\n",
            "         [-0.6453,  0.5282, -0.5839,  ..., -0.3696, -0.4438, -0.0262],\n",
            "         [-0.5878,  1.2500, -2.1424,  ..., -0.8212, -0.3496, -0.8086],\n",
            "         [-0.0112,  0.1029, -0.1414,  ...,  0.1403,  0.0765, -0.4260]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 31])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 31, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([979, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([979, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 19])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4896,  0.7125, -0.3838,  ..., -0.4104, -1.2601, -0.3637],\n",
            "         [ 0.0056,  1.3606, -0.1653,  ..., -0.5282, -1.5227, -0.3202],\n",
            "         [ 0.0056,  1.3606, -0.1653,  ..., -0.5282, -1.5227, -0.3202],\n",
            "         ...,\n",
            "         [-2.6665,  0.8057, -0.8255,  ..., -0.8755, -1.6999, -0.8119],\n",
            "         [ 0.4344, -0.1859, -1.3189,  ..., -0.3441,  0.3944, -0.4588],\n",
            "         [-0.1411,  1.0639, -0.8387,  ..., -1.0091, -0.7544, -0.8552]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4423,  0.5222, -0.3403,  ..., -0.0564, -1.0927,  0.1308],\n",
            "         [-0.3745,  0.9213, -0.1952,  ..., -0.0151, -1.3398,  0.1209],\n",
            "         [-0.3745,  0.9213, -0.1952,  ..., -0.0151, -1.3398,  0.1209],\n",
            "         ...,\n",
            "         [-1.8901,  0.8426, -0.8443,  ..., -0.3431, -1.1119, -0.2428],\n",
            "         [ 0.0190,  0.0962, -0.6490,  ..., -0.1064,  0.1893, -0.1470],\n",
            "         [-0.2040,  0.5729, -0.7276,  ..., -0.5353, -0.2592, -0.4053]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 19])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 19, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([608, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([608, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.3488,  0.5162, -0.5144,  ...,  0.2137, -0.6177, -0.0683],\n",
            "         [-0.2216,  0.8721, -0.1249,  ..., -0.2536, -1.1294, -0.0809],\n",
            "         [-0.5177,  1.3859, -0.5003,  ..., -0.4946, -0.8355, -0.7171],\n",
            "         ...,\n",
            "         [-0.2682,  1.5165, -0.3664,  ..., -0.7274, -1.4922, -0.4215],\n",
            "         [-0.1380,  0.9756, -1.5198,  ...,  0.0762, -0.7179, -1.0930],\n",
            "         [ 0.1089,  1.4090, -0.8874,  ..., -1.1447, -0.0919, -0.6645]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.1045,  0.3832, -0.3698,  ...,  0.1567, -0.3879,  0.0546],\n",
            "         [-0.3011,  0.5802, -0.1827,  ...,  0.0434, -0.9947,  0.3593],\n",
            "         [-0.5619,  0.9922, -0.4493,  ..., -0.1628, -0.8166, -0.1254],\n",
            "         ...,\n",
            "         [-0.4668,  1.0473, -0.3601,  ..., -0.1754, -1.4244,  0.0831],\n",
            "         [-0.2241,  0.7697, -1.1131,  ...,  0.0373, -0.4276, -0.3840],\n",
            "         [-0.0994,  0.9629, -0.5888,  ..., -0.6723, -0.0327, -0.2293]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 21])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 21, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([665, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([665, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 25])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.9976,  0.9006, -0.2974,  ..., -0.8651, -1.2679, -0.9689],\n",
            "         [-0.7068,  0.4520, -0.3126,  ..., -0.2437, -1.5971, -0.6468],\n",
            "         [ 0.2448,  0.3452, -0.0713,  ...,  0.1182, -0.0767,  0.1888],\n",
            "         ...,\n",
            "         [-0.5028,  0.2818, -1.0731,  ..., -0.2048, -0.5537, -0.8236],\n",
            "         [-0.3404, -0.0209, -0.4339,  ..., -0.9702, -0.1714, -0.0550],\n",
            "         [-0.3371,  0.8093, -0.4548,  ..., -0.2115, -0.2625, -0.3999]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8471,  0.7824, -0.4172,  ..., -0.3202, -0.9479, -0.3288],\n",
            "         [-0.5347,  0.3808, -0.2763,  ...,  0.0039, -1.2997, -0.1028],\n",
            "         [ 0.0812,  0.3018, -0.0649,  ...,  0.0380, -0.1196,  0.1244],\n",
            "         ...,\n",
            "         [-0.4567,  0.4435, -0.8416,  ..., -0.0187, -0.4100, -0.2997],\n",
            "         [-0.2021,  0.1360, -0.2549,  ..., -0.5251, -0.0781,  0.2234],\n",
            "         [-0.3618,  0.6644, -0.4527,  ..., -0.0295, -0.1137, -0.0875]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([800, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([800, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4591,  0.9105, -0.5842,  ..., -0.3588, -0.7369, -0.4411],\n",
            "         [-0.1774,  1.2646, -0.4387,  ..., -0.2895, -0.6041, -0.6259],\n",
            "         [-0.4837,  0.0207, -0.6968,  ..., -0.0800, -0.8153, -0.2464],\n",
            "         ...,\n",
            "         [-0.6582,  1.1933, -0.5610,  ..., -0.6472, -1.1804, -0.7928],\n",
            "         [-0.5017, -0.2148, -0.1042,  ..., -0.1182, -0.4456, -0.0856],\n",
            "         [-0.2500,  0.2552, -0.5886,  ..., -1.1346, -0.3828, -0.4068]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5361,  0.6645, -0.4593,  ..., -0.0175, -0.7563, -0.0074],\n",
            "         [-0.4204,  0.8260, -0.3981,  ...,  0.0356, -0.6808, -0.1077],\n",
            "         [-0.4387,  0.2584, -0.6544,  ...,  0.1003, -0.5672, -0.0540],\n",
            "         ...,\n",
            "         [-0.7477,  0.9066, -0.5863,  ..., -0.1461, -1.1286, -0.1021],\n",
            "         [-0.4225, -0.0405, -0.1300,  ..., -0.0679, -0.2471,  0.1067],\n",
            "         [-0.3754,  0.3511, -0.5426,  ..., -0.5910, -0.3260,  0.0070]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 10])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 10, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 20,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2039,  0.2984, -0.4301,  ..., -0.1508, -0.5061, -0.8766],\n",
            "         [-1.1530,  1.5550, -0.4488,  ..., -0.9302, -1.4889, -1.0665],\n",
            "         [-1.4767,  1.2405, -0.5696,  ..., -1.2678, -1.9957, -0.9503],\n",
            "         ...,\n",
            "         [-0.9314,  0.8101, -0.3776,  ..., -0.5967, -1.0857, -1.2829],\n",
            "         [ 0.4640,  0.4291,  0.0642,  ...,  0.1250,  0.0238, -0.1769],\n",
            "         [ 0.0111,  0.4657, -0.3234,  ..., -0.6771, -0.7508, -0.4548]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-3.1800e-01,  3.9677e-01, -3.9544e-01,  ..., -4.9565e-02,\n",
            "          -3.4678e-01, -3.3842e-01],\n",
            "         [-8.6321e-01,  1.2687e+00, -5.4409e-01,  ..., -4.0328e-01,\n",
            "          -1.0199e+00, -2.9461e-01],\n",
            "         [-1.1085e+00,  1.0086e+00, -7.0972e-01,  ..., -6.2518e-01,\n",
            "          -1.2238e+00, -3.8037e-01],\n",
            "         ...,\n",
            "         [-6.3138e-01,  7.1940e-01, -4.3340e-01,  ..., -2.4778e-01,\n",
            "          -6.3949e-01, -4.3690e-01],\n",
            "         [ 1.2510e-01,  3.5264e-01, -1.3197e-01,  ...,  9.0189e-02,\n",
            "          -1.0886e-01,  8.9960e-04],\n",
            "         [-2.0914e-01,  3.8325e-01, -3.2412e-01,  ..., -3.3199e-01,\n",
            "          -5.2694e-01, -1.1774e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 26])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 26, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([832, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([832, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.5216, -0.0196,  0.0049,  ..., -0.2072, -0.3081, -0.2299],\n",
            "         [-0.2782,  0.6783, -0.3352,  ..., -0.8171,  0.0581, -0.2718],\n",
            "         [ 0.1423,  0.3683, -1.7872,  ..., -0.6867, -1.0390, -0.7567],\n",
            "         ...,\n",
            "         [-0.6427,  0.8112, -1.5739,  ..., -0.6319, -0.4488, -1.4148],\n",
            "         [-1.0322,  0.5122,  0.0316,  ..., -1.7048, -0.3453, -0.6945],\n",
            "         [ 0.0457,  0.1247, -0.0849,  ..., -0.2305,  0.0717,  0.2677]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.3061,  0.0446, -0.0312,  ..., -0.0767, -0.3055, -0.0967],\n",
            "         [-0.3815,  0.5824, -0.4160,  ..., -0.3362, -0.0909, -0.0029],\n",
            "         [-0.2590,  0.5732, -1.4001,  ..., -0.3214, -0.6613, -0.1992],\n",
            "         ...,\n",
            "         [-0.5704,  0.4761, -0.9715,  ..., -0.2833, -0.4550, -0.6774],\n",
            "         [-0.8207,  0.5180, -0.2378,  ..., -0.9662, -0.2280, -0.2657],\n",
            "         [-0.0078,  0.1546, -0.1531,  ..., -0.1176,  0.0346,  0.2576]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 17])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 17, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([522, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([522, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 10])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6542,  0.9479, -0.3118,  ..., -0.3303, -0.5141, -0.3007],\n",
            "         [ 0.2898,  0.6241,  0.3986,  ..., -0.2104,  0.3728, -1.1269],\n",
            "         [-1.1530,  2.0129, -1.0029,  ..., -0.5882, -1.3119, -0.9125],\n",
            "         ...,\n",
            "         [-1.5316,  1.4519, -0.2230,  ..., -1.0790, -0.1849, -1.3921],\n",
            "         [-0.6865,  0.3775, -0.2540,  ..., -0.7106, -0.5162, -0.4190],\n",
            "         [-0.2051, -0.3153, -0.9536,  ..., -1.0134, -0.4198, -1.1986]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6430,  0.7109, -0.3004,  ...,  0.0373, -0.5822,  0.1414],\n",
            "         [-0.0430,  0.4093,  0.2473,  ..., -0.1005,  0.0931, -0.4540],\n",
            "         [-1.0109,  1.4724, -0.9660,  ..., -0.1606, -1.2490, -0.3008],\n",
            "         ...,\n",
            "         [-1.0576,  1.1070, -0.4242,  ..., -0.5610, -0.2708, -0.4818],\n",
            "         [-0.4902,  0.3635, -0.1567,  ..., -0.3050, -0.3622, -0.2347],\n",
            "         [-0.2615,  0.1099, -0.6928,  ..., -0.6289, -0.1560, -0.4662]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 27])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 27, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([864, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([864, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.0419,  0.1197,  0.0213,  ..., -0.1299,  0.3540,  0.4528],\n",
            "         [-0.1302,  0.8625, -0.0037,  ..., -0.1109, -0.9882,  0.1687],\n",
            "         [-0.2532,  0.2127, -0.3227,  ..., -0.4261, -0.5333, -0.3901],\n",
            "         ...,\n",
            "         [-0.3813,  0.7789, -0.5795,  ..., -0.1003, -0.7547, -0.4303],\n",
            "         [-0.3454, -0.3889,  0.4312,  ..., -0.0627,  0.3884, -0.8667],\n",
            "         [-0.4217,  0.6077, -0.6663,  ..., -1.3163, -0.1967, -0.5042]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0727,  0.1043, -0.0865,  ..., -0.0695,  0.1599,  0.3997],\n",
            "         [-0.2745,  0.4922, -0.0392,  ...,  0.0484, -0.8337,  0.4015],\n",
            "         [-0.2039,  0.2964, -0.3658,  ..., -0.2498, -0.1839, -0.1289],\n",
            "         ...,\n",
            "         [-0.4203,  0.6389, -0.5533,  ...,  0.0291, -0.4560, -0.2178],\n",
            "         [-0.1718, -0.0138,  0.2140,  ..., -0.0255,  0.2032, -0.3809],\n",
            "         [-0.4090,  0.6089, -0.5284,  ..., -0.6749, -0.2309, -0.1505]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 11])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 11, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([247, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([247, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 30, 29, 27, 26, 22, 19, 15, 11,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5899,  0.3666,  0.0824,  ...,  0.0798, -0.5628, -0.5028],\n",
            "         [ 0.0866, -0.0818, -0.0354,  ...,  0.7485, -0.6345, -0.7047],\n",
            "         [ 0.0211,  0.3700,  0.0076,  ..., -0.0682, -0.3895, -0.5462],\n",
            "         ...,\n",
            "         [-0.7726,  0.2692, -0.1868,  ..., -0.6998,  0.0216, -0.8395],\n",
            "         [-0.0850,  0.4394, -0.1609,  ..., -0.0173, -0.1497, -0.3526],\n",
            "         [ 0.4305, -0.0309, -0.1232,  ...,  0.4410, -0.3945, -0.5028]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3576,  0.2815,  0.1266,  ...,  0.0635, -0.3726, -0.1611],\n",
            "         [-0.0436,  0.1399, -0.0915,  ...,  0.4538, -0.2770, -0.3274],\n",
            "         [-0.1567,  0.2756, -0.0859,  ...,  0.0750, -0.3261, -0.1665],\n",
            "         ...,\n",
            "         [-0.7180,  0.5397, -0.3656,  ..., -0.3252, -0.1953, -0.3653],\n",
            "         [-0.1772,  0.3718, -0.1835,  ...,  0.0852, -0.0798, -0.1092],\n",
            "         [ 0.1521,  0.0202,  0.0041,  ...,  0.2053, -0.2096, -0.2590]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 16])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 16, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([448, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([448, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 26, 21, 12,  9])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0303,  0.8247, -0.2904,  ..., -0.1466, -1.1390, -0.3330],\n",
            "         [ 0.1575, -0.3464, -0.0981,  ...,  0.2713, -0.3728, -1.0766],\n",
            "         [-0.2740,  0.3248, -0.3742,  ...,  0.0618, -0.6885, -0.5540],\n",
            "         ...,\n",
            "         [-0.2769,  0.1406, -0.5010,  ...,  0.2280, -0.6451, -0.7341],\n",
            "         [-0.9868,  0.6648, -0.5467,  ..., -0.0812, -0.5891, -1.2033],\n",
            "         [-0.4458,  0.0419, -0.6559,  ...,  0.1934, -0.2171, -1.0027]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3112,  0.5659, -0.2734,  ...,  0.1040, -1.0320,  0.0785],\n",
            "         [-0.1348, -0.0289, -0.0440,  ...,  0.1859, -0.2468, -0.5057],\n",
            "         [-0.3480,  0.3896, -0.2803,  ...,  0.1037, -0.4055, -0.2382],\n",
            "         ...,\n",
            "         [-0.4108,  0.3044, -0.4349,  ...,  0.1805, -0.4838, -0.3059],\n",
            "         [-0.7380,  0.6762, -0.3525,  ..., -0.0487, -0.4173, -0.4971],\n",
            "         [-0.4620,  0.2603, -0.4645,  ...,  0.1569, -0.2668, -0.5415]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 21])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 21, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([608, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([608, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 29, 26,\n",
            "        20, 13,  8])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2550,  0.0332, -0.8793,  ...,  0.4862, -0.7358, -1.2440],\n",
            "         [-0.0232, -0.3961, -0.0730,  ...,  0.6202, -0.5569, -0.6890],\n",
            "         [-0.6759,  1.0084, -0.5892,  ..., -0.6373, -1.0430, -0.6190],\n",
            "         ...,\n",
            "         [-0.3650,  0.5793, -0.3462,  ..., -0.3108, -1.1996, -0.6335],\n",
            "         [ 0.1490, -0.0849,  0.1883,  ...,  0.4318, -0.6531, -0.6941],\n",
            "         [-0.5656,  0.3628,  0.4263,  ...,  0.0461, -0.5092, -0.6419]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3651,  0.2453, -0.6452,  ...,  0.3584, -0.5051, -0.6567],\n",
            "         [-0.1605, -0.1051, -0.0450,  ...,  0.3415, -0.3388, -0.3676],\n",
            "         [-0.7017,  0.8313, -0.5710,  ..., -0.1492, -0.9966, -0.0470],\n",
            "         ...,\n",
            "         [-0.5234,  0.4635, -0.2466,  ...,  0.0512, -1.0771, -0.0259],\n",
            "         [-0.0579,  0.0794,  0.1139,  ...,  0.2517, -0.3271, -0.3850],\n",
            "         [-0.3627,  0.2700,  0.2821,  ...,  0.0472, -0.2776, -0.2128]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([749, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([749, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 31, 21, 18,  7])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4574,  0.9326, -0.9802,  ..., -0.8063, -1.3995, -0.4814],\n",
            "         [-0.7847,  1.3305, -0.4872,  ..., -0.4029, -1.2059, -0.6275],\n",
            "         [ 0.1638, -0.3726,  0.0227,  ...,  0.9122, -0.5062, -0.6174],\n",
            "         ...,\n",
            "         [-0.2882,  0.1492, -0.3531,  ...,  0.1488, -0.5253, -1.1958],\n",
            "         [-0.1777,  0.1045, -0.0437,  ..., -0.3275, -1.4231, -0.2920],\n",
            "         [-0.3050,  1.7860, -0.4258,  ..., -0.7466, -0.8209, -0.6542]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0489,  0.8188, -0.9083,  ..., -0.3578, -0.9109, -0.0875],\n",
            "         [-0.8183,  1.0178, -0.4123,  ...,  0.0043, -1.0742, -0.0577],\n",
            "         [ 0.0057, -0.0940, -0.0110,  ...,  0.5367, -0.2033, -0.3316],\n",
            "         ...,\n",
            "         [-0.3359,  0.3582, -0.4638,  ...,  0.1456, -0.2869, -0.5071],\n",
            "         [-0.3163,  0.1341, -0.0644,  ...,  0.0019, -1.1414,  0.1392],\n",
            "         [-0.4603,  1.2701, -0.4978,  ..., -0.2757, -0.8919, -0.0585]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([868, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([868, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 29, 21, 12,  6])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.9374,  0.8590, -0.4496,  ..., -0.1250, -0.8213, -0.3622],\n",
            "         [-1.0112,  0.4071, -0.0834,  ..., -0.3818, -0.7598,  0.1388],\n",
            "         [-0.2869, -0.0183, -0.1685,  ...,  0.2761, -0.4594, -0.6439],\n",
            "         ...,\n",
            "         [-0.5013, -0.2153, -0.1059,  ..., -0.1182, -0.4471, -0.0860],\n",
            "         [ 0.4613,  2.0457, -1.3536,  ..., -0.6882, -0.7475, -0.6491],\n",
            "         [-0.5165, -0.1190,  0.0748,  ..., -0.1086, -0.0453, -0.7648]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6105,  0.7151, -0.3340,  ...,  0.0666, -0.5968, -0.1359],\n",
            "         [-0.6981,  0.3691, -0.1632,  ..., -0.0967, -0.4916,  0.1364],\n",
            "         [-0.3658,  0.1750, -0.1701,  ...,  0.1999, -0.4004, -0.2919],\n",
            "         ...,\n",
            "         [-0.4244, -0.0401, -0.1308,  ..., -0.0664, -0.2492,  0.1093],\n",
            "         [ 0.0026,  1.1409, -0.9211,  ..., -0.3668, -0.5996, -0.2310],\n",
            "         [-0.2630,  0.0348,  0.1472,  ..., -0.0446, -0.0157, -0.3623]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1019, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1019, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 22, 13,  7,  4,  3,  3,\n",
            "         3,  3,  3,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         [-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         [-0.6911,  2.8883, -4.7126,  ..., -1.6752, -0.7891, -1.8185],\n",
            "         ...,\n",
            "         [-0.3157,  1.5688, -0.2683,  ..., -0.3349, -0.8225, -0.1920],\n",
            "         [-0.1971,  1.2457, -0.4071,  ..., -0.5527, -0.8827, -0.1983],\n",
            "         [ 0.0303,  0.1817,  0.1886,  ..., -0.1531,  0.0534, -0.0691]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1424e+00,  1.3643e+00, -1.2764e+00,  ..., -5.5996e-01,\n",
            "          -9.8892e-01, -1.0393e+00],\n",
            "         [-1.1424e+00,  1.3643e+00, -1.2764e+00,  ..., -5.5996e-01,\n",
            "          -9.8892e-01, -1.0393e+00],\n",
            "         [-5.3577e-01,  1.2626e+00, -3.5929e+00,  ..., -8.7881e-01,\n",
            "          -2.7705e-01, -9.6426e-01],\n",
            "         ...,\n",
            "         [-3.8137e-01,  1.0220e+00, -2.6413e-01,  ...,  1.2719e-02,\n",
            "          -7.3850e-01,  2.5558e-01],\n",
            "         [-3.5431e-01,  8.0885e-01, -3.5853e-01,  ..., -1.5639e-01,\n",
            "          -8.7486e-01,  1.4915e-01],\n",
            "         [-6.1653e-02,  2.1006e-01,  3.5488e-02,  ..., -6.3160e-02,\n",
            "          -8.5048e-03, -3.3174e-03]]], device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  13 \n",
            "\t\t Data :  torch.Size([13, 40])\n",
            "\t Input Lengths :  torch.Size([13])\n",
            "\t Embeddings :  torch.Size([13, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([520, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([520, 150]) \n",
            "\t\t Batch size :  tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13])\n",
            "\t Hidden :  torch.Size([1, 13, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 13, 150]) \n",
            "\t\t Data :  tensor([[[-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         [-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         [-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         ...,\n",
            "         [-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         [-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067],\n",
            "         [-1.3827,  1.4573, -1.2931,  ..., -1.2104, -1.2189, -2.0067]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 13, 150])\n",
            "\t Hidden :  torch.Size([1, 13, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 13, 150]) \n",
            "\t\t Data :  tensor([[[-1.1424,  1.3643, -1.2764,  ..., -0.5600, -0.9889, -1.0393],\n",
            "         [-1.1424,  1.3643, -1.2764,  ..., -0.5600, -0.9889, -1.0393],\n",
            "         [-1.1424,  1.3643, -1.2764,  ..., -0.5600, -0.9889, -1.0393],\n",
            "         ...,\n",
            "         [-1.1424,  1.3643, -1.2764,  ..., -0.5600, -0.9889, -1.0393],\n",
            "         [-1.1424,  1.3643, -1.2764,  ..., -0.5600, -0.9889, -1.0393],\n",
            "         [-1.1424,  1.3643, -1.2764,  ..., -0.5600, -0.9889, -1.0393]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "\tTrain Loss: 0.589 | Train Acc: 76.51%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 72.77% \n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 27])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 27, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([838, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([838, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32,  6])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3367,  1.1807,  0.3772,  ..., -1.4658, -1.4199, -0.6021],\n",
            "         [-0.1317,  0.8632,  0.0022,  ..., -0.1108, -0.9897,  0.1690],\n",
            "         [-0.3792,  1.4311, -0.7731,  ..., -0.8725, -0.6884, -1.2036],\n",
            "         ...,\n",
            "         [ 0.0457,  0.1216, -0.0838,  ..., -0.2252,  0.0698,  0.2754],\n",
            "         [-0.8166,  1.6832, -0.8331,  ..., -0.8435, -1.2582, -1.2219],\n",
            "         [-0.4086,  0.8778, -0.4862,  ..., -0.2527, -0.0278, -0.4299]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3165,  0.8066, -0.0675,  ..., -0.6857, -0.9011, -0.1777],\n",
            "         [-0.2758,  0.4924, -0.0355,  ...,  0.0495, -0.8347,  0.4034],\n",
            "         [-0.4978,  0.9246, -0.7926,  ..., -0.4007, -0.5109, -0.5431],\n",
            "         ...,\n",
            "         [-0.0085,  0.1533, -0.1519,  ..., -0.1144,  0.0338,  0.2638],\n",
            "         [-0.8176,  1.2886, -0.7206,  ..., -0.2933, -1.0860, -0.3599],\n",
            "         [-0.4140,  0.5491, -0.3907,  ..., -0.1065, -0.0962, -0.1503]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 23])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 23, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([705, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([705, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32,  1])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2383,  0.3330, -0.1758,  ...,  0.4807, -0.1298, -0.2950],\n",
            "         [-0.5550,  0.0885,  0.0113,  ...,  0.1392, -0.2282, -0.2911],\n",
            "         [-0.9060,  0.8197,  0.0589,  ..., -0.3832, -0.4112, -0.2711],\n",
            "         ...,\n",
            "         [-0.6721,  0.7579, -1.2564,  ...,  0.5140, -0.4712, -1.9161],\n",
            "         [-0.3922,  0.5583, -0.5001,  ..., -0.7103, -0.6342, -1.5985],\n",
            "         [-0.9032,  0.8261,  0.0280,  ..., -0.4191, -0.4049, -0.2509]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2379,  0.2628, -0.2140,  ...,  0.2143, -0.0461, -0.0398],\n",
            "         [-0.4148,  0.2022,  0.0123,  ...,  0.1330, -0.2233, -0.0416],\n",
            "         [-0.6990,  0.6305, -0.1230,  ..., -0.1176, -0.4289,  0.0809],\n",
            "         ...,\n",
            "         [-0.6174,  0.6748, -0.9573,  ...,  0.3455, -0.3306, -0.8875],\n",
            "         [-0.4618,  0.5317, -0.3840,  ..., -0.2940, -0.5037, -0.6878],\n",
            "         [-0.7155,  0.6320, -0.1369,  ..., -0.1274, -0.4166,  0.0850]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 14])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 14, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([448, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([448, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7083,  1.2997, -0.7155,  ..., -1.4393, -0.6581, -1.3308],\n",
            "         [-0.0976,  0.4336,  0.4204,  ..., -0.0084, -0.1771,  0.3636],\n",
            "         [-0.5742, -0.0894, -0.3365,  ..., -1.1162,  0.1597, -0.7292],\n",
            "         ...,\n",
            "         [-1.3420,  1.3295, -0.2964,  ..., -1.1987, -1.6315, -1.0766],\n",
            "         [-0.7954,  0.8490,  0.1069,  ..., -0.5400, -0.6098, -0.7581],\n",
            "         [-0.7083,  1.2997, -0.7155,  ..., -1.4393, -0.6581, -1.3308]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5949,  0.8861, -0.6820,  ..., -0.7691, -0.4757, -0.4954],\n",
            "         [-0.2144,  0.3314,  0.1600,  ...,  0.1448, -0.1536,  0.2787],\n",
            "         [-0.4577,  0.1789, -0.3179,  ..., -0.6760,  0.1000, -0.1461],\n",
            "         ...,\n",
            "         [-1.1961,  1.2257, -0.6208,  ..., -0.5723, -1.1187, -0.4095],\n",
            "         [-0.6819,  0.5510,  0.0449,  ..., -0.2216, -0.2736, -0.2901],\n",
            "         [-0.5949,  0.8861, -0.6820,  ..., -0.7691, -0.4757, -0.4954]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 33])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 33, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1009, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1009, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 15,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-2.4263,  1.0948, -0.3470,  ..., -1.7057, -1.1793, -0.5666],\n",
            "         [-0.5274,  1.1972, -1.0428,  ..., -1.2099, -0.8097, -0.9399],\n",
            "         [-0.0379,  0.8638, -0.8266,  ..., -0.0541, -0.5911, -0.6748],\n",
            "         ...,\n",
            "         [-0.5087,  0.7216, -0.3420,  ..., -0.4099, -1.2924, -0.3601],\n",
            "         [-0.0898,  0.4944, -0.6560,  ..., -0.4808, -0.3585,  0.2507],\n",
            "         [-0.0036,  1.3535, -0.1006,  ..., -0.5271, -1.5309, -0.3116]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.6884e+00,  1.0153e+00, -5.2682e-01,  ..., -7.7303e-01,\n",
            "          -8.2598e-01, -5.1962e-02],\n",
            "         [-3.9280e-01,  6.2509e-01, -7.5117e-01,  ..., -5.7782e-01,\n",
            "          -3.8604e-01, -3.8933e-01],\n",
            "         [-1.9578e-01,  6.3550e-01, -5.3758e-01,  ...,  1.5046e-01,\n",
            "          -4.6754e-01, -2.3075e-01],\n",
            "         ...,\n",
            "         [-4.6077e-01,  5.2653e-01, -3.1230e-01,  ..., -4.2616e-02,\n",
            "          -1.1241e+00,  1.5229e-01],\n",
            "         [-1.6012e-01,  4.9212e-01, -5.4957e-01,  ..., -2.2205e-01,\n",
            "          -1.8129e-01,  2.1413e-01],\n",
            "         [-3.8727e-01,  9.1582e-01, -1.4838e-01,  ...,  6.4374e-04,\n",
            "          -1.3516e+00,  1.4673e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4128,  1.4920, -1.3305,  ..., -1.2330, -1.2425, -2.0607],\n",
            "         [-1.4128,  1.4920, -1.3305,  ..., -1.2330, -1.2425, -2.0607],\n",
            "         [-1.4128,  1.4920, -1.3305,  ..., -1.2330, -1.2425, -2.0607],\n",
            "         ...,\n",
            "         [-1.4128,  1.4920, -1.3305,  ..., -1.2330, -1.2425, -2.0607],\n",
            "         [-1.4128,  1.4920, -1.3305,  ..., -1.2330, -1.2425, -2.0607],\n",
            "         [-1.4128,  1.4920, -1.3305,  ..., -1.2330, -1.2425, -2.0607]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1725,  1.3976, -1.3083,  ..., -0.5749, -1.0127, -1.0677],\n",
            "         [-1.1725,  1.3976, -1.3083,  ..., -0.5749, -1.0127, -1.0677],\n",
            "         [-1.1725,  1.3976, -1.3083,  ..., -0.5749, -1.0127, -1.0677],\n",
            "         ...,\n",
            "         [-1.1725,  1.3976, -1.3083,  ..., -0.5749, -1.0127, -1.0677],\n",
            "         [-1.1725,  1.3976, -1.3083,  ..., -0.5749, -1.0127, -1.0677],\n",
            "         [-1.1725,  1.3976, -1.3083,  ..., -0.5749, -1.0127, -1.0677]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 6])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 6, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([126, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([126, 150]) \n",
            "\t\t Batch size :  tensor([32, 28, 26, 23, 14,  3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2281,  1.2982, -1.2053,  ..., -1.1713, -0.8501, -1.1426],\n",
            "         [-0.9800, -0.4536, -0.4998,  ..., -0.6112, -0.6352,  0.5112],\n",
            "         [-0.7911,  0.7077, -0.0413,  ..., -0.5492,  0.3477, -0.5432],\n",
            "         ...,\n",
            "         [ 0.1487,  0.3797, -0.1571,  ...,  0.0698, -0.5581,  0.2827],\n",
            "         [-0.3705,  0.2755, -0.3974,  ..., -0.0872,  0.0645, -0.6198],\n",
            "         [-0.2134,  0.3896, -0.0108,  ...,  0.1451,  0.1674, -0.0405]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3587,  0.8187, -1.0182,  ..., -0.5468, -0.4434, -0.5169],\n",
            "         [-0.8851,  0.0439, -0.4086,  ..., -0.3148, -0.5489,  0.4065],\n",
            "         [-0.5434,  0.6281, -0.2018,  ..., -0.2460,  0.0185, -0.1768],\n",
            "         ...,\n",
            "         [ 0.0325,  0.3316, -0.0954,  ...,  0.0454, -0.3584,  0.1366],\n",
            "         [-0.2816,  0.2480, -0.2365,  ...,  0.0245, -0.0583, -0.3390],\n",
            "         [-0.1777,  0.3563,  0.0031,  ...,  0.0646, -0.0263, -0.0164]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4334,  1.5185, -1.3579,  ..., -1.2519, -1.2579, -2.1034],\n",
            "         [-1.4334,  1.5185, -1.3579,  ..., -1.2519, -1.2579, -2.1034],\n",
            "         [-1.4334,  1.5185, -1.3579,  ..., -1.2519, -1.2579, -2.1034],\n",
            "         ...,\n",
            "         [-1.4334,  1.5185, -1.3579,  ..., -1.2519, -1.2579, -2.1034],\n",
            "         [-1.4334,  1.5185, -1.3579,  ..., -1.2519, -1.2579, -2.1034],\n",
            "         [-1.4334,  1.5185, -1.3579,  ..., -1.2519, -1.2579, -2.1034]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1914,  1.4215, -1.3318,  ..., -0.5880, -1.0273, -1.0921],\n",
            "         [-1.1914,  1.4215, -1.3318,  ..., -0.5880, -1.0273, -1.0921],\n",
            "         [-1.1914,  1.4215, -1.3318,  ..., -0.5880, -1.0273, -1.0921],\n",
            "         ...,\n",
            "         [-1.1914,  1.4215, -1.3318,  ..., -0.5880, -1.0273, -1.0921],\n",
            "         [-1.1914,  1.4215, -1.3318,  ..., -0.5880, -1.0273, -1.0921],\n",
            "         [-1.1914,  1.4215, -1.3318,  ..., -0.5880, -1.0273, -1.0921]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 24])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 24, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([762, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([762, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 26])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.1355,  1.0536, -0.1261,  ..., -0.2561, -1.0074,  0.1948],\n",
            "         [-0.7008,  1.2135, -0.2552,  ..., -0.6163, -0.1615, -0.2144],\n",
            "         [ 0.2880,  0.0621, -0.0624,  ..., -0.9494,  0.0397, -0.2695],\n",
            "         ...,\n",
            "         [-0.6847,  1.0598,  0.0323,  ..., -1.0681, -1.5788, -0.7393],\n",
            "         [-0.3145,  0.6461, -0.1434,  ..., -0.2271, -1.3411,  0.1402],\n",
            "         [-0.2512,  1.2081, -0.0143,  ..., -0.4487, -1.4905, -0.3412]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3523,  0.6962, -0.1686,  ...,  0.1192, -0.9030,  0.4385],\n",
            "         [-0.5853,  0.9296, -0.3203,  ..., -0.3655, -0.2596, -0.0608],\n",
            "         [ 0.1806,  0.0877, -0.0272,  ..., -0.4501, -0.0409, -0.0911],\n",
            "         ...,\n",
            "         [-0.5384,  0.8974, -0.1838,  ..., -0.4622, -1.1191, -0.1787],\n",
            "         [-0.3972,  0.6327, -0.3166,  ...,  0.0582, -0.8427,  0.2017],\n",
            "         [-0.4565,  0.7762, -0.0984,  ..., -0.0756, -1.2555,  0.1227]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 35])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 35, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1078, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1078, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 18,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7441,  1.7891, -1.2389,  ..., -1.1499, -1.0501, -0.7869],\n",
            "         [-0.7888,  1.3252,  0.4244,  ..., -1.4992, -2.3214, -0.1321],\n",
            "         [-0.9902,  1.5406, -0.5905,  ..., -0.7587, -1.1107, -0.5812],\n",
            "         ...,\n",
            "         [ 0.1029,  1.2622, -0.2029,  ..., -0.3308, -0.6012, -0.2751],\n",
            "         [-0.5398,  1.2054, -1.0507,  ..., -1.2333, -0.8155, -0.9444],\n",
            "         [-0.8881,  0.9617, -0.3880,  ..., -1.6495, -1.1423, -0.3875]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5742,  1.0684, -1.1634,  ..., -0.5679, -0.5083, -0.3797],\n",
            "         [-0.6571,  0.9855,  0.1101,  ..., -0.6333, -1.4494,  0.1003],\n",
            "         [-0.8260,  1.1774, -0.5896,  ..., -0.2466, -0.8688, -0.1141],\n",
            "         ...,\n",
            "         [-0.1917,  0.7040, -0.1927,  ...,  0.0208, -0.6009,  0.1319],\n",
            "         [-0.4035,  0.6321, -0.7578,  ..., -0.5891, -0.3948, -0.3887],\n",
            "         [-0.7272,  0.8664, -0.4362,  ..., -0.7395, -0.8352, -0.0255]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 8])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 8, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([218, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([218, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 23,  3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4069,  1.0028, -0.2326,  ..., -0.6341, -0.9042, -0.4218],\n",
            "         [-0.2595,  1.2727, -1.2492,  ..., -0.1739,  0.2378, -0.9091],\n",
            "         [-0.9279,  1.1307, -0.3975,  ..., -0.9909, -1.2395, -0.6581],\n",
            "         ...,\n",
            "         [-0.1833,  0.1753, -0.1322,  ..., -0.3719,  0.0532,  0.4133],\n",
            "         [ 0.1646,  0.3957, -1.0119,  ..., -0.0759, -0.4438,  0.0890],\n",
            "         [-1.1530,  0.7496, -0.1384,  ..., -0.8777, -1.6647, -1.0904]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3057,  0.8452, -0.3488,  ..., -0.2683, -0.5617, -0.0521],\n",
            "         [-0.3078,  0.7081, -0.8521,  ...,  0.0210,  0.0571, -0.4029],\n",
            "         [-0.6827,  1.0132, -0.5501,  ..., -0.4391, -0.7710, -0.1399],\n",
            "         ...,\n",
            "         [-0.2029,  0.2380, -0.2897,  ..., -0.1744, -0.0368,  0.3308],\n",
            "         [-0.0809,  0.4003, -0.7284,  ..., -0.0332, -0.2109,  0.0867],\n",
            "         [-1.0527,  0.9116, -0.4749,  ..., -0.4069, -1.1342, -0.3916]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  7 \n",
            "\t\t Data :  torch.Size([7, 43])\n",
            "\t Input Lengths :  torch.Size([7])\n",
            "\t Embeddings :  torch.Size([7, 43, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([285, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([285, 150]) \n",
            "\t\t Batch size :  tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 1])\n",
            "\t Hidden :  torch.Size([1, 7, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 7, 150]) \n",
            "\t\t Data :  tensor([[[-0.1827,  1.0809, -0.2211,  ..., -0.4884, -0.9667, -0.2204],\n",
            "         [-0.3434, -1.0433,  0.5921,  ...,  0.1548,  0.5524, -0.2929],\n",
            "         [-1.4531,  1.5348, -1.3841,  ..., -1.2731, -1.2695, -2.1383],\n",
            "         ...,\n",
            "         [-1.4531,  1.5348, -1.3841,  ..., -1.2731, -1.2695, -2.1383],\n",
            "         [-1.4531,  1.5348, -1.3841,  ..., -1.2731, -1.2695, -2.1383],\n",
            "         [-1.4531,  1.5348, -1.3841,  ..., -1.2731, -1.2695, -2.1383]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 7, 150])\n",
            "\t Hidden :  torch.Size([1, 7, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 7, 150]) \n",
            "\t\t Data :  tensor([[[-0.3652,  0.7130, -0.2081,  ..., -0.1132, -0.8816,  0.1318],\n",
            "         [-0.2845, -0.4391,  0.2408,  ...,  0.0137,  0.2990,  0.1649],\n",
            "         [-1.2095,  1.4419, -1.3574,  ..., -0.6063, -1.0392, -1.1196],\n",
            "         ...,\n",
            "         [-1.2095,  1.4419, -1.3574,  ..., -0.6063, -1.0392, -1.1196],\n",
            "         [-1.2095,  1.4419, -1.3574,  ..., -0.6063, -1.0392, -1.1196],\n",
            "         [-1.2095,  1.4419, -1.3574,  ..., -0.6063, -1.0392, -1.1196]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 20])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 20, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([633, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([633, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 25])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5820,  0.4337, -0.9687,  ..., -0.5811, -0.3149, -2.4480],\n",
            "         [-0.6830,  0.9378, -0.2550,  ..., -0.3300, -0.5260, -0.2984],\n",
            "         [-1.5321,  2.4590,  0.1818,  ..., -1.5028, -1.0437, -0.9420],\n",
            "         ...,\n",
            "         [ 0.0560,  0.3404,  0.0268,  ..., -0.3121, -0.4031, -0.0330],\n",
            "         [-0.2431,  0.8657, -0.0337,  ..., -0.2393, -1.1376, -0.0689],\n",
            "         [-0.9447,  0.1491, -0.1645,  ..., -0.2899, -0.1581, -1.4755]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4473,  0.3824, -0.7395,  ..., -0.3157, -0.2583, -1.0844],\n",
            "         [-0.6680,  0.7062, -0.2588,  ...,  0.0516, -0.5916,  0.1596],\n",
            "         [-1.2541,  1.6482, -0.1074,  ..., -0.8659, -0.7340, -0.2246],\n",
            "         ...,\n",
            "         [-0.1925,  0.2380,  0.0250,  ..., -0.0343, -0.4263,  0.2265],\n",
            "         [-0.3231,  0.5773, -0.1215,  ...,  0.0701, -1.0048,  0.3966],\n",
            "         [-0.7033,  0.3771, -0.2402,  ..., -0.1114, -0.2398, -0.6939]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 10])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 10, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([320, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([320, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0730,  1.2559, -0.3131,  ..., -0.1323, -1.1830, -1.4205],\n",
            "         [-0.5576,  0.8556, -0.3647,  ..., -0.5475, -1.2408, -0.4606],\n",
            "         [ 0.4006,  0.1275, -0.1605,  ..., -0.2925,  0.0214, -0.8238],\n",
            "         ...,\n",
            "         [-0.6747,  0.4074, -1.0693,  ..., -0.8471, -0.5272, -0.9227],\n",
            "         [-0.8622,  0.9154, -1.0353,  ..., -0.3501, -0.8770, -0.9187],\n",
            "         [-1.0730,  1.2559, -0.3131,  ..., -0.1323, -1.1830, -1.4205]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0058,  1.1367, -0.4664,  ...,  0.0720, -0.8255, -0.7479],\n",
            "         [-0.6744,  0.6842, -0.3920,  ..., -0.0908, -1.1181,  0.0680],\n",
            "         [ 0.0832,  0.1361, -0.0254,  ..., -0.1737, -0.0517, -0.3106],\n",
            "         ...,\n",
            "         [-0.5780,  0.3668, -0.8278,  ..., -0.4484, -0.3340, -0.4148],\n",
            "         [-0.6128,  0.5475, -0.7599,  ..., -0.0900, -0.7243, -0.3420],\n",
            "         [-1.0058,  1.1367, -0.4664,  ...,  0.0720, -0.8255, -0.7479]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 16])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 16, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([482, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([482, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6094,  0.1754, -0.4603,  ..., -0.1651, -0.0645, -1.0102],\n",
            "         [-0.8721,  1.1124, -0.2919,  ..., -0.6672, -1.0746, -1.1560],\n",
            "         [-1.2700,  0.9324, -0.9251,  ..., -1.1154, -1.2947, -1.2362],\n",
            "         ...,\n",
            "         [-1.2700,  0.9324, -0.9251,  ..., -1.1154, -1.2947, -1.2362],\n",
            "         [-1.4635,  1.2458, -1.5336,  ..., -1.2880, -1.1816, -0.9133],\n",
            "         [-1.1180,  0.9954,  0.0666,  ..., -0.6624, -0.6444, -0.3383]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4325,  0.1654, -0.2419,  ...,  0.0072, -0.0654, -0.3536],\n",
            "         [-0.7410,  0.9390, -0.3497,  ..., -0.1830, -0.9234, -0.3306],\n",
            "         [-1.1722,  0.9371, -0.8891,  ..., -0.5153, -1.1093, -0.4611],\n",
            "         ...,\n",
            "         [-1.1722,  0.9371, -0.8891,  ..., -0.5153, -1.1093, -0.4611],\n",
            "         [-1.1321,  1.0721, -1.2747,  ..., -0.6003, -0.7600, -0.2058],\n",
            "         [-0.8413,  0.8192, -0.0943,  ..., -0.3539, -0.5687, -0.0607]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 31])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 31, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([979, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([979, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 19])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0125,  1.3377, -0.0338,  ..., -0.5192, -1.5288, -0.3002],\n",
            "         [-0.2433,  0.8034, -0.4277,  ..., -0.3919, -0.5479, -0.3715],\n",
            "         [-0.6134,  1.8600, -0.3028,  ..., -0.9350, -2.0569, -0.0227],\n",
            "         ...,\n",
            "         [-0.6644,  0.1588, -0.9758,  ..., -0.6027, -0.3665, -0.7304],\n",
            "         [-0.1668,  0.7235, -0.4182,  ..., -0.7339, -0.8598, -0.8044],\n",
            "         [-0.2764,  1.2433, -0.1442,  ..., -0.4425,  0.1497, -1.2342]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-3.9549e-01,  9.0337e-01, -9.8486e-02,  ...,  1.9625e-02,\n",
            "          -1.3525e+00,  1.7370e-01],\n",
            "         [-4.1263e-01,  5.6991e-01, -2.5994e-01,  ...,  6.3493e-04,\n",
            "          -6.5273e-01,  4.4740e-02],\n",
            "         [-5.8486e-01,  1.3204e+00, -3.9296e-01,  ..., -3.3450e-01,\n",
            "          -1.3523e+00,  1.7444e-01],\n",
            "         ...,\n",
            "         [-5.5768e-01,  2.4672e-01, -6.7750e-01,  ..., -1.3505e-01,\n",
            "          -2.1290e-01, -2.4953e-01],\n",
            "         [-1.6280e-01,  4.8942e-01, -4.5152e-01,  ..., -3.4187e-01,\n",
            "          -2.6463e-01, -4.3323e-01],\n",
            "         [-3.6759e-01,  8.0353e-01, -2.6876e-01,  ..., -1.0777e-01,\n",
            "           4.7985e-02, -4.7300e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 15])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 15, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([476, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([476, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7097,  2.1306, -0.5753,  ..., -0.6587, -1.8602, -0.4709],\n",
            "         [ 0.0459,  1.1111,  0.0647,  ..., -0.3960, -1.1773, -0.0335],\n",
            "         [-1.2575,  0.9204, -0.9045,  ..., -1.1114, -1.2839, -1.2154],\n",
            "         ...,\n",
            "         [ 0.0845, -0.5212, -0.5778,  ..., -0.1388, -0.3241, -0.5481],\n",
            "         [-1.4129,  1.9459, -1.6795,  ..., -0.6512, -0.8375, -1.1354],\n",
            "         [-0.1118,  0.0358, -0.8950,  ..., -0.5675, -0.3914, -0.9592]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7270,  1.5791, -0.5777,  ..., -0.1777, -1.6568,  0.0238],\n",
            "         [-0.2379,  0.6882, -0.0059,  ..., -0.0830, -1.0213,  0.3027],\n",
            "         [-1.1629,  0.9272, -0.8708,  ..., -0.5142, -1.0978, -0.4523],\n",
            "         ...,\n",
            "         [-0.0425, -0.1372, -0.4599,  ..., -0.0782, -0.2706, -0.1775],\n",
            "         [-0.9462,  1.1598, -1.3999,  ..., -0.3170, -0.5120, -0.5927],\n",
            "         [-0.3297,  0.2912, -0.6402,  ..., -0.2334, -0.2697, -0.3275]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 30])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 30, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([959, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([959, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-2.8872,  0.8483, -0.9773,  ..., -1.0321, -1.7845, -0.8930],\n",
            "         [-2.8872,  0.8483, -0.9773,  ..., -1.0321, -1.7845, -0.8930],\n",
            "         [-0.9533,  1.6077, -0.4675,  ..., -0.8997, -0.4305, -0.3949],\n",
            "         ...,\n",
            "         [ 0.0402, -0.1035,  0.2757,  ..., -0.1352,  0.1774,  0.4405],\n",
            "         [ 0.0451,  0.0760,  0.0902,  ..., -0.1118,  0.3545,  0.4945],\n",
            "         [-0.3876,  0.7647, -0.2354,  ..., -0.2085, -0.9566, -0.0316]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-2.0761,  0.9078, -0.9801,  ..., -0.4456, -1.1878, -0.3060],\n",
            "         [-2.0761,  0.9078, -0.9801,  ..., -0.4456, -1.1878, -0.3060],\n",
            "         [-0.7699,  1.1110, -0.4504,  ..., -0.4580, -0.4043, -0.1565],\n",
            "         ...,\n",
            "         [-0.0072, -0.0921,  0.0765,  ..., -0.0996,  0.0749,  0.3251],\n",
            "         [-0.0705,  0.0724, -0.0350,  ..., -0.0601,  0.1677,  0.4345],\n",
            "         [-0.4197,  0.5406, -0.1745,  ...,  0.0283, -0.8655,  0.2987]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([770, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([770, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.1853, -0.4541,  0.1218,  ..., -0.3342,  0.1836, -0.3492],\n",
            "         [ 0.1426,  0.4971, -0.4940,  ...,  0.1003, -0.7661, -1.2125],\n",
            "         [-1.0147,  1.7452, -0.7244,  ..., -0.7289, -0.3364, -1.4462],\n",
            "         ...,\n",
            "         [ 0.1491,  0.0330,  0.0907,  ..., -0.0853, -0.0900,  0.1105],\n",
            "         [-0.0309,  1.2210,  0.0362,  ..., -0.3031, -0.4515, -0.1842],\n",
            "         [-2.0930,  1.1807, -1.4303,  ..., -1.7501, -0.5684, -0.8075]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.1412, -0.1304, -0.0485,  ..., -0.2094,  0.0604, -0.1620],\n",
            "         [-0.1744,  0.3548, -0.4583,  ...,  0.1479, -0.4565, -0.5487],\n",
            "         [-0.9751,  1.3034, -0.7674,  ..., -0.2521, -0.5439, -0.6052],\n",
            "         ...,\n",
            "         [ 0.0137,  0.1564, -0.0331,  ..., -0.0580, -0.0688,  0.0728],\n",
            "         [-0.2432,  0.8626, -0.0638,  ...,  0.0019, -0.3949,  0.1545],\n",
            "         [-1.3782,  0.8767, -1.1200,  ..., -0.9648, -0.4579, -0.2221]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 28])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 28, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([884, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([884, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 20])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4320,  0.3658, -0.1815,  ..., -0.2335, -1.2400,  0.1533],\n",
            "         [-0.4320,  0.3658, -0.1815,  ..., -0.2335, -1.2400,  0.1533],\n",
            "         [-1.4292,  0.8148, -1.0124,  ..., -0.7450, -2.0779, -0.6530],\n",
            "         ...,\n",
            "         [-0.3561,  0.6778, -0.5076,  ..., -0.3390, -0.4479, -0.1895],\n",
            "         [-1.7697,  0.6238, -0.5872,  ..., -1.0829, -1.2720, -1.3800],\n",
            "         [-0.1006,  0.8309, -0.7330,  ..., -0.6155, -0.5988, -1.1589]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4724,  0.3093, -0.1520,  ...,  0.0174, -1.0204,  0.4266],\n",
            "         [-0.4724,  0.3093, -0.1520,  ...,  0.0174, -1.0204,  0.4266],\n",
            "         [-1.0502,  0.6804, -0.7877,  ..., -0.2931, -1.2386, -0.2923],\n",
            "         ...,\n",
            "         [-0.4204,  0.5788, -0.5412,  ...,  0.0352, -0.4503,  0.0270],\n",
            "         [-1.3096,  0.6976, -0.6860,  ..., -0.5299, -1.1932, -0.5231],\n",
            "         [-0.1968,  0.5707, -0.6049,  ..., -0.2602, -0.2409, -0.6625]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1186, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1186, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27,\n",
            "        20,  8,  6,  5])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3865,  1.4101, -1.2922,  ..., -1.2160, -1.2201, -1.9611],\n",
            "         [-1.3865,  1.4101, -1.2922,  ..., -1.2160, -1.2201, -1.9611],\n",
            "         [-1.3865,  1.4101, -1.2922,  ..., -1.2160, -1.2201, -1.9611],\n",
            "         ...,\n",
            "         [-1.0521,  1.0634, -0.2226,  ..., -2.1667, -0.6936, -0.5772],\n",
            "         [-0.6420,  1.6560, -1.1494,  ..., -1.0777, -1.0101, -0.7201],\n",
            "         [-0.3370,  0.3891,  0.3498,  ...,  0.0851,  0.0166,  0.4151]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1606,  1.3617, -1.2936,  ..., -0.5805, -0.9977, -1.0498],\n",
            "         [-1.1606,  1.3617, -1.2936,  ..., -0.5805, -0.9977, -1.0498],\n",
            "         [-1.1606,  1.3617, -1.2936,  ..., -0.5805, -0.9977, -1.0498],\n",
            "         ...,\n",
            "         [-0.7770,  0.8440, -0.3210,  ..., -0.9943, -0.4778, -0.2886],\n",
            "         [-0.5026,  0.9902, -1.0821,  ..., -0.5261, -0.4641, -0.3670],\n",
            "         [-0.3290,  0.3963,  0.1011,  ...,  0.0642, -0.0528,  0.3515]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([800, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([800, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 1.7925e-01,  1.1479e+00, -5.3350e-01,  ..., -1.4347e+00,\n",
            "          -2.8624e-01, -6.1953e-01],\n",
            "         [-4.1756e-01,  1.6013e+00, -5.2970e-01,  ..., -1.0631e+00,\n",
            "          -1.3703e-01, -9.5643e-01],\n",
            "         [-1.0098e+00,  9.3439e-01, -6.2598e-01,  ..., -1.8849e+00,\n",
            "          -1.1306e+00, -5.4530e-01],\n",
            "         ...,\n",
            "         [-3.9854e-01,  3.7453e-01, -5.6696e-01,  ..., -3.6535e-01,\n",
            "          -8.0671e-01,  2.2246e-01],\n",
            "         [-4.8976e-01,  2.7552e-05, -6.8439e-01,  ..., -8.6885e-02,\n",
            "          -8.2096e-01, -2.2767e-01],\n",
            "         [-3.9854e-01,  3.7453e-01, -5.6696e-01,  ..., -3.6535e-01,\n",
            "          -8.0671e-01,  2.2246e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0539,  0.8522, -0.4082,  ..., -0.8590, -0.1300, -0.2029],\n",
            "         [-0.5958,  1.1323, -0.4470,  ..., -0.5425, -0.3147, -0.3629],\n",
            "         [-0.9415,  0.8204, -0.6041,  ..., -0.9601, -0.8803, -0.0976],\n",
            "         ...,\n",
            "         [-0.4235,  0.4088, -0.4656,  ..., -0.1786, -0.6699,  0.2608],\n",
            "         [-0.4504,  0.2605, -0.6498,  ...,  0.0976, -0.5761, -0.0431],\n",
            "         [-0.4235,  0.4088, -0.4656,  ..., -0.1786, -0.6699,  0.2608]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 21])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 21, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([665, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([665, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 25])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0455, -0.6620, -0.1936,  ...,  0.1584, -0.0808, -0.3077],\n",
            "         [-1.9843,  1.2824, -0.9644,  ..., -0.5751, -1.6127, -0.4438],\n",
            "         [-1.7476,  1.1990, -1.3526,  ..., -0.9363, -0.6421, -0.5702],\n",
            "         ...,\n",
            "         [-0.3830,  0.2631,  0.3777,  ..., -0.8460,  0.1882, -1.6941],\n",
            "         [ 0.2588,  0.0699,  0.3038,  ..., -0.1878, -0.5145, -1.1147],\n",
            "         [-0.6531,  0.4504, -0.7456,  ..., -0.7685, -0.4627, -2.1856]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0909, -0.2077, -0.2130,  ...,  0.0324, -0.0630, -0.0830],\n",
            "         [-1.3922,  1.1276, -0.7842,  ..., -0.2359, -1.1187, -0.0968],\n",
            "         [-1.2938,  1.0070, -0.9902,  ..., -0.3511, -0.5180, -0.0427],\n",
            "         ...,\n",
            "         [-0.4649,  0.4373, -0.0476,  ..., -0.4511, -0.0283, -0.9004],\n",
            "         [ 0.1823,  0.0966,  0.1218,  ...,  0.0241, -0.2265, -0.4868],\n",
            "         [-0.5908,  0.5223, -0.7130,  ..., -0.2737, -0.4037, -0.9909]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 26])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 26, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([802, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([802, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-7.8957e-01,  8.4500e-01, -1.2983e+00,  ...,  3.0426e-01,\n",
            "          -5.0879e-01, -2.0354e+00],\n",
            "         [-8.3841e-01,  1.5055e+00, -1.4200e-01,  ..., -1.0066e+00,\n",
            "          -1.1844e+00, -7.4376e-01],\n",
            "         [-1.9491e-01,  3.0354e-01, -6.3176e-01,  ..., -3.7428e-01,\n",
            "          -6.5292e-01, -1.3576e+00],\n",
            "         ...,\n",
            "         [-8.4397e-01,  1.4911e+00, -7.2058e-01,  ..., -8.4556e-01,\n",
            "          -1.1945e+00, -1.0469e+00],\n",
            "         [-3.5357e-01,  1.1751e+00, -6.2267e-01,  ..., -1.2230e+00,\n",
            "          -8.2264e-01, -4.0639e-01],\n",
            "         [-2.6318e-01,  1.2958e+00, -5.4563e-01,  ..., -1.0152e+00,\n",
            "          -1.9666e-03, -6.5301e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7182,  0.7452, -1.0136,  ...,  0.2239, -0.3724, -0.9675],\n",
            "         [-0.6152,  1.1938, -0.3394,  ..., -0.4572, -0.7335, -0.1448],\n",
            "         [-0.2099,  0.3311, -0.4498,  ..., -0.1767, -0.4150, -0.5433],\n",
            "         ...,\n",
            "         [-0.8559,  1.2338, -0.7892,  ..., -0.3232, -1.0645, -0.3655],\n",
            "         [-0.4508,  1.0276, -0.6420,  ..., -0.5688, -0.6115, -0.0186],\n",
            "         [-0.3085,  0.9499, -0.5197,  ..., -0.5671, -0.2033, -0.2003]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([906, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([906, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 10])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3019,  1.5253, -0.1611,  ..., -0.3179, -0.7909, -0.1816],\n",
            "         [-0.3245,  1.5253, -0.3334,  ..., -0.3238, -0.9442, -0.2495],\n",
            "         [-0.3019,  1.5253, -0.1611,  ..., -0.3179, -0.7909, -0.1816],\n",
            "         ...,\n",
            "         [-0.4213,  0.3512, -0.1657,  ..., -0.2299, -1.2260,  0.1596],\n",
            "         [-0.8839,  1.2529, -1.1276,  ..., -2.0529, -0.9219, -0.8896],\n",
            "         [-0.6182,  0.9367, -1.2051,  ..., -0.9604, -0.8096, -0.8117]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3743,  0.9818, -0.1842,  ...,  0.0393, -0.7089,  0.2893],\n",
            "         [-0.3932,  0.9827, -0.2754,  ..., -0.0379, -0.8592,  0.1844],\n",
            "         [-0.3743,  0.9818, -0.1842,  ...,  0.0393, -0.7089,  0.2893],\n",
            "         ...,\n",
            "         [-0.4649,  0.2993, -0.1389,  ...,  0.0194, -1.0066,  0.4338],\n",
            "         [-0.7071,  1.0246, -0.8983,  ..., -1.0259, -0.7363, -0.3061],\n",
            "         [-0.5096,  0.7362, -1.1157,  ..., -0.4425, -0.4025, -0.3449]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 10])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 10, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 20,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.4142,  0.0331, -0.3923,  ...,  0.6876, -0.5396, -0.2205],\n",
            "         [-1.4549,  1.1637, -0.5619,  ..., -1.2746, -1.9889, -0.9000],\n",
            "         [-0.5216,  1.7762, -0.3007,  ..., -0.6399, -1.2079, -0.0455],\n",
            "         ...,\n",
            "         [-0.8254, -0.3908, -0.6014,  ..., -0.5749, -0.2216, -0.7173],\n",
            "         [-0.4273,  0.8389, -0.2513,  ..., -0.5568, -1.0966, -0.6837],\n",
            "         [-0.0184,  0.4744, -0.3304,  ..., -0.6888, -0.7686, -0.4785]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.2269,  0.0911, -0.2687,  ...,  0.4131, -0.2478, -0.1103],\n",
            "         [-1.1040,  0.9824, -0.7154,  ..., -0.6506, -1.2163, -0.3719],\n",
            "         [-0.6145,  1.1351, -0.3162,  ..., -0.1691, -0.9908,  0.3199],\n",
            "         ...,\n",
            "         [-0.5796,  0.0504, -0.6192,  ..., -0.2739, -0.1981, -0.1739],\n",
            "         [-0.5763,  0.7119, -0.3476,  ..., -0.1576, -0.9492, -0.1568],\n",
            "         [-0.2381,  0.4020, -0.3347,  ..., -0.3358, -0.5428, -0.1274]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 14])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 14, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([423, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([423, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  7])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4937,  0.2612,  0.3909,  ..., -1.1105, -0.2471, -0.9958],\n",
            "         [-0.5411,  1.0926, -0.8415,  ..., -0.2250, -0.6510, -0.2747],\n",
            "         [-0.6995,  0.8729,  0.1625,  ..., -0.5005,  0.1564, -0.5826],\n",
            "         ...,\n",
            "         [-0.9338,  0.7982, -0.3387,  ..., -0.4544, -0.4647, -0.8438],\n",
            "         [-0.2601,  1.0194, -0.0194,  ..., -0.4869, -1.2434, -0.1419],\n",
            "         [ 0.4973,  0.8443, -0.0696,  ...,  0.0432, -0.6124,  0.4555]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4289,  0.4540,  0.0801,  ..., -0.6274, -0.1652, -0.2878],\n",
            "         [-0.4832,  0.8143, -0.7353,  ..., -0.0651, -0.4418, -0.0760],\n",
            "         [-0.5063,  0.6007,  0.0422,  ..., -0.2429,  0.0280, -0.2003],\n",
            "         ...,\n",
            "         [-0.7894,  0.7503, -0.5062,  ..., -0.1823, -0.4736, -0.4080],\n",
            "         [-0.4750,  0.7350, -0.1116,  ..., -0.0627, -1.0381,  0.2209],\n",
            "         [-0.0560,  0.6220, -0.1624,  ...,  0.0866, -0.4129,  0.4338]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 23])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 23, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([736, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([736, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8008,  1.3169, -1.1341,  ..., -2.0527, -0.8697, -0.2966],\n",
            "         [ 0.1591,  0.6597, -1.0184,  ...,  0.2308,  0.0416, -1.0833],\n",
            "         [-1.0216,  1.9697, -0.3979,  ..., -0.6048, -0.7593, -0.7444],\n",
            "         ...,\n",
            "         [-0.6607,  0.2730, -0.3302,  ..., -0.8257, -1.8911,  0.5184],\n",
            "         [ 0.3751,  0.8642, -0.2110,  ..., -0.8264,  0.0666, -0.0247],\n",
            "         [-1.6589,  1.0821, -1.0555,  ..., -0.1709, -0.0932, -0.9153]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7892,  1.0766, -1.0398,  ..., -1.0476, -0.6159, -0.0055],\n",
            "         [-0.0799,  0.5305, -0.6376,  ...,  0.3020, -0.0444, -0.3838],\n",
            "         [-0.8429,  1.4487, -0.3775,  ..., -0.1520, -0.8276, -0.2014],\n",
            "         ...,\n",
            "         [-0.6650,  0.4148, -0.3229,  ..., -0.2806, -1.0292,  0.4199],\n",
            "         [ 0.0860,  0.6421, -0.1846,  ..., -0.4831, -0.0115,  0.0637],\n",
            "         [-1.1666,  0.8205, -0.7555,  ..., -0.0118, -0.2107, -0.4037]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 22])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 22, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([688, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([688, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 16])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4948,  1.3052, -0.1879,  ..., -0.4283, -1.3370, -0.2885],\n",
            "         [ 0.1623,  0.4390, -0.0378,  ..., -0.1232, -0.3927, -0.0850],\n",
            "         [-1.1451,  1.9326, -0.8195,  ..., -0.6454, -2.0372, -0.1546],\n",
            "         ...,\n",
            "         [-0.4429,  1.4216, -0.8825,  ..., -0.8434, -1.0664, -0.5495],\n",
            "         [-0.3475,  0.7870, -0.2653,  ..., -0.4375, -1.4602,  0.0956],\n",
            "         [-1.1234,  1.2956, -0.4423,  ..., -0.9478,  0.1261, -2.0692]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6636,  0.9381, -0.1914,  ..., -0.0443, -1.0802,  0.1378],\n",
            "         [-0.0817,  0.2434, -0.0592,  ..., -0.0668, -0.3940, -0.0442],\n",
            "         [-0.9685,  1.1631, -0.7424,  ..., -0.3279, -1.4222,  0.1563],\n",
            "         ...,\n",
            "         [-0.4855,  1.1365, -0.7953,  ..., -0.4107, -0.7881, -0.0968],\n",
            "         [-0.4562,  0.6602, -0.2515,  ..., -0.0559, -1.2866,  0.2910],\n",
            "         [-0.7808,  1.0726, -0.5951,  ..., -0.5137, -0.1101, -1.0494]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 13])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 13, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([387, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([387, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27,  8])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6745,  0.8954, -0.5244,  ..., -0.7221, -0.8981, -0.6962],\n",
            "         [-0.2364,  0.3190, -0.6789,  ..., -0.1407, -0.3926,  0.1212],\n",
            "         [-0.2281, -0.1614, -0.0040,  ..., -0.1999,  0.0655, -0.7882],\n",
            "         ...,\n",
            "         [-0.1623,  0.9990, -0.2047,  ..., -1.0965, -0.8027, -0.5721],\n",
            "         [-0.5780, -0.2986, -0.2893,  ..., -0.3130,  0.5510, -0.2051],\n",
            "         [ 0.0290,  0.3600,  0.0243,  ..., -0.0559, -0.3899, -0.4963]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6296,  0.6767, -0.3885,  ..., -0.3121, -0.6627, -0.0848],\n",
            "         [-0.3263,  0.3404, -0.5855,  ...,  0.0248, -0.3428,  0.1973],\n",
            "         [-0.2317,  0.1545, -0.2345,  ..., -0.1119,  0.0249, -0.2515],\n",
            "         ...,\n",
            "         [-0.2743,  0.7321, -0.2211,  ..., -0.5385, -0.5640, -0.1012],\n",
            "         [-0.4714,  0.0067, -0.2554,  ..., -0.0556,  0.1798,  0.0181],\n",
            "         [-0.1538,  0.2723, -0.0714,  ...,  0.0814, -0.3256, -0.1450]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 26])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 26, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([832, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([832, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6471,  1.4127, -0.2093,  ..., -0.5167, -1.6291, -0.4323],\n",
            "         [-1.1318,  0.5334, -0.0066,  ..., -1.8132, -0.3757, -0.7509],\n",
            "         [-0.1763,  1.3474, -0.1298,  ..., -0.1790, -0.6477, -0.0667],\n",
            "         ...,\n",
            "         [-0.3033,  1.5159, -0.1522,  ..., -0.3135, -0.7923, -0.1797],\n",
            "         [ 0.0052, -0.2042, -0.0855,  ..., -0.6637, -0.3548,  0.3652],\n",
            "         [-0.7932, -0.0303, -0.4019,  ...,  0.0886, -0.5230, -0.4592]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7459,  0.9851, -0.2015,  ..., -0.0568, -1.5024, -0.0017],\n",
            "         [-0.8956,  0.5543, -0.2772,  ..., -1.0647, -0.2489, -0.3128],\n",
            "         [-0.3201,  0.7727, -0.1142,  ...,  0.0719, -0.6545,  0.2442],\n",
            "         ...,\n",
            "         [-0.3807,  0.9779, -0.1772,  ...,  0.0492, -0.7140,  0.3006],\n",
            "         [-0.2340, -0.0361, -0.0280,  ..., -0.3427, -0.3047,  0.2343],\n",
            "         [-0.4995,  0.1456, -0.2504,  ...,  0.0669, -0.3539, -0.1488]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 27])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 27, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([864, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([864, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8991,  0.9346, -0.9830,  ..., -1.8796, -1.9302, -0.3335],\n",
            "         [-0.9156,  1.3798,  0.1018,  ..., -0.2356,  0.0594, -1.0453],\n",
            "         [-0.2463,  0.1688, -0.2953,  ..., -0.4155, -0.5043, -0.3567],\n",
            "         ...,\n",
            "         [ 0.0488,  1.0106, -0.6801,  ..., -1.5895, -0.0240, -0.9975],\n",
            "         [-0.1888,  0.2590, -0.1360,  ..., -0.3001,  0.0264,  0.0250],\n",
            "         [-0.7555,  1.0667, -0.5629,  ..., -0.8993, -1.0235, -1.0766]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7447,  0.9055, -0.9563,  ..., -0.8598, -1.2699, -0.0131],\n",
            "         [-0.6957,  0.9587, -0.1860,  ..., -0.0993, -0.1273, -0.5080],\n",
            "         [-0.2005,  0.2701, -0.3452,  ..., -0.2530, -0.1604, -0.1209],\n",
            "         ...,\n",
            "         [-0.1143,  0.7818, -0.4923,  ..., -0.9713, -0.0242, -0.4135],\n",
            "         [-0.1868,  0.1988, -0.2344,  ..., -0.1425, -0.0426,  0.1140],\n",
            "         [-0.5224,  0.7557, -0.6655,  ..., -0.4491, -0.4473, -0.5294]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 19])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 19, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([579, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([579, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "         3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3031,  1.0103, -1.7043,  ..., -0.0257, -0.7306, -1.2426],\n",
            "         [-0.2440,  0.8428,  0.0192,  ..., -0.2284, -1.1165, -0.0581],\n",
            "         [-1.4455,  0.3819, -1.7239,  ..., -1.1778, -0.9679, -1.0883],\n",
            "         ...,\n",
            "         [-1.3066,  1.4071, -2.7769,  ..., -2.0514, -1.1335, -0.8806],\n",
            "         [-0.6002,  1.9463, -0.3615,  ..., -0.7369, -1.6085, -0.7741],\n",
            "         [-1.2956,  0.9080, -0.9237,  ..., -1.1539, -1.2751, -1.2601]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3427,  0.8292, -1.2737,  ..., -0.0150, -0.4659, -0.4715],\n",
            "         [-0.3328,  0.5640, -0.0813,  ...,  0.0935, -0.9956,  0.4273],\n",
            "         [-1.0782,  0.4251, -1.2665,  ..., -0.4828, -0.7263, -0.4504],\n",
            "         ...,\n",
            "         [-1.0471,  1.0765, -2.2952,  ..., -1.0827, -0.6965, -0.4096],\n",
            "         [-0.6408,  1.4173, -0.4140,  ..., -0.2938, -1.4768, -0.1118],\n",
            "         [-1.1774,  0.9222, -0.9007,  ..., -0.5683, -1.0768, -0.5211]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 19])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 19, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([608, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([608, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2447,  0.8425,  0.0193,  ..., -0.2284, -1.1171, -0.0579],\n",
            "         [-0.2447,  0.8425,  0.0193,  ..., -0.2284, -1.1171, -0.0579],\n",
            "         [-0.6369,  0.6718, -0.2743,  ..., -0.3012, -1.1343, -0.0537],\n",
            "         ...,\n",
            "         [-1.7823,  1.3025, -0.3376,  ..., -1.1146, -1.4323, -0.6524],\n",
            "         [-0.2447,  0.8425,  0.0193,  ..., -0.2284, -1.1171, -0.0579],\n",
            "         [-0.8830,  2.0496, -0.5453,  ..., -0.6585, -0.8188, -0.2838]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3342,  0.5647, -0.0812,  ...,  0.0947, -0.9969,  0.4285],\n",
            "         [-0.3342,  0.5647, -0.0812,  ...,  0.0947, -0.9969,  0.4285],\n",
            "         [-0.5096,  0.4901, -0.2025,  ..., -0.0133, -0.9990,  0.3268],\n",
            "         ...,\n",
            "         [-1.1254,  0.9925, -0.4213,  ..., -0.5416, -0.8796, -0.2001],\n",
            "         [-0.3342,  0.5647, -0.0812,  ...,  0.0947, -0.9969,  0.4285],\n",
            "         [-0.8924,  1.5032, -0.5205,  ..., -0.1042, -0.8351,  0.1412]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([928, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([928, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8660,  1.2426, -0.4517,  ..., -0.6622, -1.2087, -0.4107],\n",
            "         [ 0.3401,  0.5635, -0.3997,  ..., -0.3215, -0.5464, -0.9474],\n",
            "         [-0.6917,  0.7956, -1.5875,  ..., -0.6480, -0.4520, -1.4679],\n",
            "         ...,\n",
            "         [-0.3166,  1.5276, -0.1564,  ..., -0.3196, -0.8072, -0.1837],\n",
            "         [-1.0248,  1.0151, -0.1797,  ..., -0.5138, -0.9634, -0.6529],\n",
            "         [-0.6522,  0.9503, -1.2225,  ..., -0.9866, -0.8190, -0.8317]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6624,  0.8691, -0.3588,  ..., -0.2636, -1.0316,  0.1112],\n",
            "         [ 0.0734,  0.3610, -0.3087,  ..., -0.1146, -0.1800, -0.4586],\n",
            "         [-0.6147,  0.4859, -0.9958,  ..., -0.2964, -0.4667, -0.7228],\n",
            "         ...,\n",
            "         [-0.3951,  0.9930, -0.1825,  ...,  0.0512, -0.7298,  0.3040],\n",
            "         [-0.7985,  0.8620, -0.3119,  ..., -0.1483, -0.6907, -0.2274],\n",
            "         [-0.5291,  0.7456, -1.1396,  ..., -0.4654, -0.4142, -0.3587]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 11])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 11, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([344, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([344, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 24])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8526,  0.3493, -0.1489,  ..., -0.6215, -0.2348, -0.7846],\n",
            "         [-1.0820,  0.5515, -1.1149,  ..., -0.9048, -1.0957, -0.5476],\n",
            "         [-0.3892,  0.8063, -0.6355,  ..., -0.2297, -0.0604, -0.9427],\n",
            "         ...,\n",
            "         [-0.3285,  0.0984, -0.7654,  ..., -0.3009, -0.4399, -0.9392],\n",
            "         [-1.3237,  0.9834, -1.3515,  ..., -0.6848, -0.2468, -0.6059],\n",
            "         [-0.3242,  1.6003, -2.1492,  ..., -0.6051, -0.8119, -1.1726]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7579,  0.5408, -0.3547,  ..., -0.2363, -0.3921, -0.3537],\n",
            "         [-0.8945,  0.6791, -0.9376,  ..., -0.4263, -0.8646, -0.2060],\n",
            "         [-0.5139,  0.6124, -0.5496,  ..., -0.0348, -0.0971, -0.3778],\n",
            "         ...,\n",
            "         [-0.4701,  0.2976, -0.6243,  ..., -0.0738, -0.4383, -0.4380],\n",
            "         [-1.0685,  0.8372, -1.0813,  ..., -0.2265, -0.3156, -0.2550],\n",
            "         [-0.3692,  0.9069, -1.6244,  ..., -0.1418, -0.2647, -0.6055]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 17])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 17, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([522, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([522, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 10])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6504,  0.4911,  0.2802,  ..., -0.7889, -1.5943, -0.6436],\n",
            "         [-0.6181,  0.8549, -0.1546,  ..., -0.2817, -0.4690, -0.2431],\n",
            "         [-1.5030,  1.3345,  0.0111,  ..., -0.8685, -2.4069, -0.4953],\n",
            "         ...,\n",
            "         [ 0.0625,  0.3327, -0.1470,  ..., -0.1764, -0.2949,  0.0301],\n",
            "         [-0.2721, -0.3559, -1.0183,  ..., -1.0708, -0.4565, -1.2251],\n",
            "         [-0.0493,  0.0067, -0.3565,  ...,  0.1388, -1.2705, -0.5493]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6152,  0.6157, -0.0596,  ..., -0.4150, -0.9976, -0.1563],\n",
            "         [-0.6270,  0.6326, -0.1688,  ...,  0.0853, -0.5406,  0.2035],\n",
            "         [-1.1233,  0.9359, -0.1883,  ..., -0.3079, -1.6544,  0.0024],\n",
            "         ...,\n",
            "         [-0.0785,  0.2626, -0.0843,  ..., -0.0145, -0.3621,  0.2912],\n",
            "         [-0.3087,  0.1154, -0.7689,  ..., -0.6843, -0.1795, -0.5148],\n",
            "         [-0.2983,  0.2216, -0.3942,  ...,  0.2277, -0.9606, -0.0625]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 18])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 18, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([561, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([561, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 17])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8595,  1.1317, -0.3013,  ..., -1.4765, -0.3216, -1.0417],\n",
            "         [-1.3479,  0.9221, -0.9778,  ..., -1.1781, -1.3052, -1.3022],\n",
            "         [-1.2068,  1.5273, -0.1600,  ..., -1.2955, -1.9692, -0.9330],\n",
            "         ...,\n",
            "         [-0.5963,  0.9884, -0.8270,  ..., -0.5246,  0.0160, -0.6815],\n",
            "         [-0.8496, -0.0172, -0.2985,  ..., -0.3971, -0.7512, -0.5258],\n",
            "         [-0.7400,  0.9840, -1.0369,  ..., -0.8740, -0.9648, -0.5821]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7199,  1.0756, -0.4216,  ..., -0.7595, -0.3274, -0.3576],\n",
            "         [-1.2177,  0.9495, -0.9589,  ..., -0.5884, -1.1068, -0.5553],\n",
            "         [-0.8878,  1.2616, -0.3925,  ..., -0.6416, -1.3178, -0.2323],\n",
            "         ...,\n",
            "         [-0.5893,  0.8821, -0.7185,  ..., -0.2001, -0.0604, -0.2687],\n",
            "         [-0.6622,  0.2810, -0.3818,  ..., -0.0982, -0.6450, -0.1424],\n",
            "         [-0.5775,  0.7806, -0.8132,  ..., -0.3840, -0.6346, -0.1745]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 11])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 11, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([247, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([247, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 30, 29, 27, 26, 22, 19, 15, 11,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5914,  0.3687,  0.0838,  ...,  0.0640, -0.5720, -0.5018],\n",
            "         [ 0.1072, -0.1300,  0.0297,  ...,  0.7747, -0.6222, -0.6695],\n",
            "         [ 0.0030,  0.3704,  0.0158,  ..., -0.0758, -0.4110, -0.5263],\n",
            "         ...,\n",
            "         [-0.7788,  0.2125, -0.1721,  ..., -0.6474,  0.0243, -0.8253],\n",
            "         [-0.0918,  0.4331, -0.1648,  ..., -0.0175, -0.1686, -0.3607],\n",
            "         [ 0.4326, -0.0423, -0.1148,  ...,  0.4358, -0.3963, -0.4904]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3636,  0.2903,  0.1266,  ...,  0.0558, -0.3793, -0.1649],\n",
            "         [-0.0281,  0.1035, -0.0482,  ...,  0.4709, -0.2755, -0.3121],\n",
            "         [-0.1784,  0.2930, -0.0814,  ...,  0.0800, -0.3442, -0.1544],\n",
            "         ...,\n",
            "         [-0.7287,  0.5159, -0.3530,  ..., -0.2974, -0.2042, -0.3592],\n",
            "         [-0.1862,  0.3766, -0.1894,  ...,  0.0895, -0.0933, -0.1102],\n",
            "         [ 0.1513,  0.0141,  0.0128,  ...,  0.2056, -0.2108, -0.2468]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 16])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 16, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([448, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([448, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 26, 21, 12,  9])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0493,  0.7763, -0.1968,  ..., -0.1493, -1.1252, -0.3356],\n",
            "         [ 0.1349, -0.3622, -0.0911,  ...,  0.2697, -0.3834, -1.0714],\n",
            "         [-0.2236,  0.2613, -0.3382,  ...,  0.0680, -0.6783, -0.5133],\n",
            "         ...,\n",
            "         [-0.4614,  0.1438, -0.6020,  ...,  0.1918, -0.6740, -0.7997],\n",
            "         [-1.0050,  0.6512, -0.5497,  ..., -0.1000, -0.5764, -1.1606],\n",
            "         [-0.4295, -0.0344, -0.6239,  ...,  0.2178, -0.2178, -0.9698]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3339,  0.5423, -0.2025,  ...,  0.1235, -1.0319,  0.1097],\n",
            "         [-0.1565, -0.0290, -0.0388,  ...,  0.1924, -0.2563, -0.5004],\n",
            "         [-0.3165,  0.3448, -0.2445,  ...,  0.1059, -0.3897, -0.2177],\n",
            "         ...,\n",
            "         [-0.5470,  0.3483, -0.5235,  ...,  0.1806, -0.5278, -0.3328],\n",
            "         [-0.7593,  0.6846, -0.3554,  ..., -0.0620, -0.4184, -0.4871],\n",
            "         [-0.4578,  0.2161, -0.4342,  ...,  0.1707, -0.2637, -0.5220]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 21])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 21, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([608, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([608, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 29, 26,\n",
            "        20, 13,  8])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3167,  0.0037, -0.8976,  ...,  0.4876, -0.7380, -1.2446],\n",
            "         [-0.0043, -0.4243, -0.0318,  ...,  0.6142, -0.5554, -0.6689],\n",
            "         [-0.7058,  0.9507, -0.5286,  ..., -0.6258, -1.0445, -0.6101],\n",
            "         ...,\n",
            "         [-0.3916,  0.5079, -0.2508,  ..., -0.3167, -1.1934, -0.6155],\n",
            "         [ 0.2103, -0.1369,  0.2389,  ...,  0.4385, -0.6358, -0.6367],\n",
            "         [-0.5474,  0.3185,  0.4458,  ...,  0.0625, -0.4739, -0.5999]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4017,  0.2414, -0.6584,  ...,  0.3670, -0.5099, -0.6641],\n",
            "         [-0.1535, -0.1234, -0.0106,  ...,  0.3422, -0.3363, -0.3541],\n",
            "         [-0.7376,  0.8159, -0.5257,  ..., -0.1248, -1.0114, -0.0227],\n",
            "         ...,\n",
            "         [-0.5514,  0.4223, -0.1713,  ...,  0.0690, -1.0784,  0.0129],\n",
            "         [-0.0207,  0.0367,  0.1593,  ...,  0.2533, -0.3069, -0.3543],\n",
            "         [-0.3514,  0.2480,  0.3051,  ...,  0.0545, -0.2556, -0.1988]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([749, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([749, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 31, 21, 18,  7])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.6875,  0.9212, -1.0811,  ..., -0.8659, -1.3847, -0.5573],\n",
            "         [-0.8627,  1.2989, -0.4274,  ..., -0.4145, -1.2163, -0.6333],\n",
            "         [ 0.2181, -0.4180,  0.1171,  ...,  0.9410, -0.4698, -0.5329],\n",
            "         ...,\n",
            "         [-0.2712,  0.0807, -0.2809,  ...,  0.1994, -0.5188, -1.1585],\n",
            "         [-0.2082,  0.0526,  0.0545,  ..., -0.3393, -1.4204, -0.2960],\n",
            "         [-0.4213,  1.8394, -0.4099,  ..., -0.8409, -0.8648, -0.7695]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1951,  0.8404, -1.0073,  ..., -0.4174, -0.9062, -0.1340],\n",
            "         [-0.8852,  1.0218, -0.3626,  ...,  0.0129, -1.0922, -0.0475],\n",
            "         [ 0.0460, -0.1376,  0.0546,  ...,  0.5459, -0.1827, -0.2919],\n",
            "         ...,\n",
            "         [-0.3258,  0.3212, -0.4229,  ...,  0.1798, -0.2926, -0.4983],\n",
            "         [-0.3425,  0.1005,  0.0057,  ...,  0.0143, -1.1437,  0.1661],\n",
            "         [-0.5523,  1.3771, -0.5170,  ..., -0.3323, -0.9363, -0.1247]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([868, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([868, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 29, 21, 12,  6])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-9.1678e-01,  7.7864e-01, -4.3105e-01,  ..., -1.1082e-01,\n",
            "          -8.0541e-01, -3.3732e-01],\n",
            "         [-1.0489e+00,  4.0108e-01, -9.0667e-02,  ..., -3.8013e-01,\n",
            "          -7.7148e-01,  1.4482e-01],\n",
            "         [-2.7606e-01, -9.7966e-02, -1.6547e-01,  ...,  2.7458e-01,\n",
            "          -4.5134e-01, -6.0015e-01],\n",
            "         ...,\n",
            "         [-5.0171e-01, -2.1671e-01, -1.1169e-01,  ..., -1.0355e-01,\n",
            "          -4.5933e-01, -8.4565e-02],\n",
            "         [ 4.1109e-01,  1.9603e+00, -1.3059e+00,  ..., -7.0562e-01,\n",
            "          -7.5866e-01, -6.5889e-01],\n",
            "         [-4.7801e-01, -1.8762e-01,  1.1811e-01,  ..., -7.5010e-02,\n",
            "          -1.6993e-03, -6.7385e-01]]], device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5903,  0.6693, -0.3189,  ...,  0.0733, -0.5778, -0.1321],\n",
            "         [-0.7340,  0.3769, -0.1715,  ..., -0.0917, -0.5077,  0.1449],\n",
            "         [-0.3627,  0.1349, -0.1557,  ...,  0.1994, -0.3944, -0.2705],\n",
            "         ...,\n",
            "         [-0.4391, -0.0369, -0.1326,  ..., -0.0461, -0.2649,  0.1350],\n",
            "         [-0.0386,  1.1113, -0.8980,  ..., -0.3778, -0.6201, -0.2318],\n",
            "         [-0.2368, -0.0103,  0.1788,  ..., -0.0289,  0.0160, -0.3269]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1019, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1019, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 22, 13,  7,  4,  3,  3,\n",
            "         3,  3,  3,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         [-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         [-0.6796,  2.6551, -4.5887,  ..., -1.6384, -0.7393, -1.7112],\n",
            "         ...,\n",
            "         [-0.3269,  1.5382, -0.1666,  ..., -0.3260, -0.8195, -0.1880],\n",
            "         [-0.2988,  1.2649, -0.3812,  ..., -0.6183, -0.8935, -0.2554],\n",
            "         [ 0.0323,  0.1280,  0.2091,  ..., -0.1413,  0.0701, -0.0278]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         [-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         [-0.4928,  1.1560, -3.5044,  ..., -0.8741, -0.2125, -0.9552],\n",
            "         ...,\n",
            "         [-0.4082,  1.0074, -0.1918,  ...,  0.0531, -0.7442,  0.3067],\n",
            "         [-0.4265,  0.8433, -0.3483,  ..., -0.1835, -0.9013,  0.1243],\n",
            "         [-0.0572,  0.1784,  0.0627,  ..., -0.0614,  0.0044,  0.0270]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  13 \n",
            "\t\t Data :  torch.Size([13, 40])\n",
            "\t Input Lengths :  torch.Size([13])\n",
            "\t Embeddings :  torch.Size([13, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([520, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([520, 150]) \n",
            "\t\t Batch size :  tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13])\n",
            "\t Hidden :  torch.Size([1, 13, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 13, 150]) \n",
            "\t\t Data :  tensor([[[-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         [-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         [-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         ...,\n",
            "         [-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         [-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450],\n",
            "         [-1.4360,  1.4260, -1.3532,  ..., -1.2498, -1.2535, -2.0450]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 13, 150])\n",
            "\t Hidden :  torch.Size([1, 13, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 13, 150]) \n",
            "\t\t Data :  tensor([[[-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         [-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         [-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         ...,\n",
            "         [-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         [-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282],\n",
            "         [-1.1959,  1.3870, -1.3538,  ..., -0.6247, -1.0206, -1.1282]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "\tTrain Loss: 0.551 | Train Acc: 77.10%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 72.32% \n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 23])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 23, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([705, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([705, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32,  1])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3966,  0.3363, -0.7984,  ..., -1.0882, -1.6461, -0.3126],\n",
            "         [-0.7400, -0.2598, -0.4541,  ...,  0.3085, -0.1502,  0.4572],\n",
            "         [-0.9004,  0.7886,  0.0663,  ..., -0.4104, -0.4371, -0.1642],\n",
            "         ...,\n",
            "         [-1.6091,  0.3600, -1.1687,  ..., -0.9189, -0.8322, -1.6736],\n",
            "         [-0.7964,  0.9077,  0.1440,  ..., -1.2291, -1.2493, -0.8915],\n",
            "         [-0.3557,  1.0552, -0.5678,  ..., -1.1111, -0.3377, -0.8229]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8484,  0.3849, -0.6535,  ..., -0.4435, -0.9242, -0.0837],\n",
            "         [-0.4039, -0.1017, -0.1317,  ...,  0.1782, -0.1007,  0.1624],\n",
            "         [-0.7100,  0.6150, -0.1117,  ..., -0.1156, -0.4308,  0.1450],\n",
            "         ...,\n",
            "         [-1.1363,  0.5242, -0.8851,  ..., -0.4250, -0.5589, -0.7140],\n",
            "         [-0.5809,  0.8259, -0.1297,  ..., -0.5983, -0.9054, -0.2705],\n",
            "         [-0.3051,  0.9083, -0.5470,  ..., -0.5941, -0.2207, -0.2451]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 33])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 33, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1009, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1009, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 15,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.0906,  1.2431, -0.1531,  ..., -0.3389, -0.6299, -0.2697],\n",
            "         [-1.3101,  0.0928, -0.0225,  ..., -1.5057, -2.1596, -0.0604],\n",
            "         [-0.3657,  0.4181,  0.3481,  ...,  0.0582, -0.0181,  0.3930],\n",
            "         ...,\n",
            "         [-0.5795,  1.1067, -0.3735,  ..., -0.5639, -0.6036, -0.4118],\n",
            "         [-0.9518,  1.2397,  0.2857,  ..., -1.9522, -0.4857,  0.0466],\n",
            "         [-1.5293,  1.0055, -0.3823,  ..., -0.5601, -0.3204, -0.9367]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2188,  0.7016, -0.1592,  ...,  0.0419, -0.6335,  0.1710],\n",
            "         [-0.9389,  0.4062, -0.2656,  ..., -0.8132, -1.1800,  0.1361],\n",
            "         [-0.3642,  0.4319,  0.0955,  ...,  0.0558, -0.0760,  0.3479],\n",
            "         ...,\n",
            "         [-0.5767,  0.7804, -0.4880,  ..., -0.2011, -0.5290, -0.0905],\n",
            "         [-0.6916,  1.0181, -0.0976,  ..., -0.9518, -0.4418,  0.2001],\n",
            "         [-1.0198,  0.8262, -0.3083,  ..., -0.2156, -0.3313, -0.3387]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 18])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 18, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([561, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([561, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 17])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2348,  1.5465, -0.1726,  ..., -1.3210, -1.9899, -0.9551],\n",
            "         [-0.2022, -0.2844, -0.5867,  ..., -0.2915, -0.1240, -2.6159],\n",
            "         [-0.8771,  1.1453, -0.3164,  ..., -1.4905, -0.3352, -1.0508],\n",
            "         ...,\n",
            "         [-0.6151,  1.0110, -0.8472,  ..., -0.5320,  0.0057, -0.6999],\n",
            "         [ 0.4411, -0.1964, -0.3044,  ...,  0.4430, -0.6558,  0.2468],\n",
            "         [-0.6605,  0.5029,  0.2761,  ..., -0.7991, -1.6160, -0.6477]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.9116,  1.2812, -0.4062,  ..., -0.6564, -1.3408, -0.2425],\n",
            "         [-0.3183,  0.0715, -0.4322,  ..., -0.1299, -0.0301, -1.1974],\n",
            "         [-0.7396,  1.0906, -0.4375,  ..., -0.7663, -0.3407, -0.3601],\n",
            "         ...,\n",
            "         [-0.6088,  0.9030, -0.7395,  ..., -0.2003, -0.0720, -0.2776],\n",
            "         [ 0.1736, -0.0569, -0.2493,  ...,  0.2662, -0.4428,  0.1637],\n",
            "         [-0.6293,  0.6288, -0.0659,  ..., -0.4186, -1.0178, -0.1548]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 28])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 28, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([884, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([884, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 20])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4850,  0.3711, -0.1987,  ..., -0.2510, -1.2725,  0.1491],\n",
            "         [-0.6972,  1.1115, -0.4774,  ..., -0.6333, -1.2062, -0.7471],\n",
            "         [-0.9729,  1.2783, -1.2172,  ..., -2.1686, -0.9402, -1.0207],\n",
            "         ...,\n",
            "         [ 0.0373,  0.0913,  0.0820,  ..., -0.1182,  0.3434,  0.4829],\n",
            "         [ 0.2713,  1.1096, -0.0361,  ..., -1.4299, -0.1685, -0.0215],\n",
            "         [-1.2354,  2.0696, -0.7504,  ..., -0.8735, -1.2217, -1.4598]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5262,  0.3294, -0.1654,  ...,  0.0294, -1.0676,  0.4508],\n",
            "         [-0.8110,  0.8931, -0.5255,  ..., -0.0988, -1.1753, -0.0325],\n",
            "         [-0.7716,  1.0593, -0.9819,  ..., -1.1043, -0.7634, -0.3775],\n",
            "         ...,\n",
            "         [-0.0890,  0.0813, -0.0329,  ..., -0.0550,  0.1585,  0.4468],\n",
            "         [ 0.0180,  0.8073, -0.1322,  ..., -0.8288, -0.1191,  0.0699],\n",
            "         [-1.1165,  1.6044, -0.8551,  ..., -0.3359, -1.1074, -0.6166]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 23])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 23, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([736, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([736, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8097,  0.3755, -0.7413,  ..., -1.4942, -2.4065, -1.0572],\n",
            "         [-0.9291,  0.6733, -0.3158,  ...,  0.2116,  0.0901, -1.0920],\n",
            "         [-0.8350,  1.3287, -1.1706,  ..., -2.0944, -0.9154, -0.2998],\n",
            "         ...,\n",
            "         [-1.3077,  1.3784, -0.7115,  ..., -1.5378, -1.4175, -0.6265],\n",
            "         [-0.3472,  0.7097, -0.8591,  ..., -0.3287,  0.1065, -0.9997],\n",
            "         [-1.2413,  2.1420, -0.4781,  ..., -0.7594, -0.8909, -0.9205]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6721,  0.6247, -0.7952,  ..., -0.6635, -1.5692, -0.2957],\n",
            "         [-0.6736,  0.6018, -0.3153,  ...,  0.1833,  0.0387, -0.4656],\n",
            "         [-0.8281,  1.1040, -1.0851,  ..., -1.0721, -0.6572, -0.0023],\n",
            "         ...,\n",
            "         [-1.0800,  1.1761, -0.7195,  ..., -0.8372, -0.9075, -0.1717],\n",
            "         [-0.4249,  0.6673, -0.7366,  ..., -0.1100, -0.0317, -0.3637],\n",
            "         [-1.0180,  1.6346, -0.5054,  ..., -0.2638, -0.9332, -0.3275]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1186, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1186, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27,\n",
            "        20,  8,  6,  5])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.5049,  1.5035, -1.4495,  ..., -1.3014, -1.3008, -2.2027],\n",
            "         [-1.5049,  1.5035, -1.4495,  ..., -1.3014, -1.3008, -2.2027],\n",
            "         [-1.5049,  1.5035, -1.4495,  ..., -1.3014, -1.3008, -2.2027],\n",
            "         ...,\n",
            "         [-0.7515,  0.7690, -1.0215,  ..., -1.1751, -1.2255, -0.6855],\n",
            "         [-0.1650, -0.2309, -0.1336,  ...,  0.3379, -0.2213, -0.0044],\n",
            "         [-0.8022,  1.7296, -1.2657,  ..., -1.2158, -1.0351, -0.7739]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2541,  1.4547, -1.4368,  ..., -0.6631, -1.0648, -1.2237],\n",
            "         [-1.2541,  1.4547, -1.4368,  ..., -0.6631, -1.0648, -1.2237],\n",
            "         [-1.2541,  1.4547, -1.4368,  ..., -0.6631, -1.0648, -1.2237],\n",
            "         ...,\n",
            "         [-0.6217,  0.7188, -0.8377,  ..., -0.4543, -0.7761, -0.2174],\n",
            "         [-0.1058, -0.0106, -0.1225,  ...,  0.1716, -0.1562, -0.1492],\n",
            "         [-0.5882,  1.0413, -1.2015,  ..., -0.6280, -0.4895, -0.3909]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([770, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([770, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3332,  1.5518, -0.5677,  ..., -0.8530, -1.4311, -0.6933],\n",
            "         [-0.9473,  1.5682, -0.8119,  ..., -0.8984, -1.2357, -1.1957],\n",
            "         [-0.3586,  0.1197, -1.0680,  ..., -1.3861, -0.8598, -1.6350],\n",
            "         ...,\n",
            "         [-0.3954,  0.4784,  0.0571,  ..., -0.2012, -0.3972, -0.2270],\n",
            "         [-0.7854, -0.2741,  0.4529,  ..., -0.7437, -0.9131, -0.1772],\n",
            "         [ 0.5647,  0.2051,  0.4330,  ..., -0.2984, -0.9535, -0.8898]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.9427,  1.1457, -0.5523,  ..., -0.2881, -1.2877, -0.0361],\n",
            "         [-0.9474,  1.3356, -0.9002,  ..., -0.3730, -1.1026, -0.4816],\n",
            "         [-0.4448,  0.4386, -0.9747,  ..., -0.7437, -0.6055, -0.6608],\n",
            "         ...,\n",
            "         [-0.2659,  0.3498,  0.0215,  ..., -0.0973, -0.2479, -0.0199],\n",
            "         [-0.5642,  0.1333,  0.1543,  ..., -0.4151, -0.5673,  0.0130],\n",
            "         [ 0.1445,  0.2583,  0.1768,  ..., -0.0581, -0.6532, -0.4270]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 11])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 11, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([344, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([344, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 24])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3864,  0.6577, -0.1572,  ..., -1.0050, -0.7812, -0.8157],\n",
            "         [-1.0238,  1.2135, -0.1690,  ..., -0.0867, -1.1896, -1.2059],\n",
            "         [-0.6263,  0.5016, -0.2092,  ..., -0.6852, -0.3770, -1.9970],\n",
            "         ...,\n",
            "         [-1.4627,  1.0623, -1.4701,  ..., -0.8054, -0.3339, -0.7332],\n",
            "         [-1.5215,  1.1959, -0.5836,  ..., -1.3006, -2.0578, -0.9080],\n",
            "         [ 0.4196,  0.0306, -0.3769,  ...,  0.6685, -0.5563, -0.2412]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.0329,  0.8647, -0.3555,  ..., -0.5250, -0.5583, -0.3085],\n",
            "         [-0.9841,  1.1276, -0.3684,  ...,  0.0944, -0.8238, -0.6574],\n",
            "         [-0.5748,  0.5765, -0.3776,  ..., -0.3061, -0.3608, -0.8832],\n",
            "         ...,\n",
            "         [-1.1827,  0.9188, -1.1945,  ..., -0.2963, -0.3884, -0.3122],\n",
            "         [-1.1805,  1.0239, -0.7491,  ..., -0.6706, -1.2860, -0.3738],\n",
            "         [ 0.2252,  0.0878, -0.2662,  ...,  0.4078, -0.2640, -0.1132]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 8])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 8, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([218, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([218, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 23,  3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.1013,  0.5295, -0.3633,  ..., -0.7255, -0.8301, -0.5599],\n",
            "         [-0.5265,  0.8726, -0.3078,  ..., -0.6317, -1.1499, -0.7983],\n",
            "         [-0.9002,  1.0471, -0.3481,  ..., -0.9151, -1.2335, -0.5808],\n",
            "         ...,\n",
            "         [-0.1466,  0.9667, -1.2452,  ...,  0.6398,  0.4771, -0.4916],\n",
            "         [-1.1689,  1.1731, -0.8020,  ..., -0.5339, -0.5498, -1.0487],\n",
            "         [-0.1797,  0.1672, -0.1463,  ..., -0.3697,  0.0701,  0.4310]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3172,  0.4677, -0.3778,  ..., -0.3461, -0.5972, -0.1594],\n",
            "         [-0.6531,  0.7910, -0.4288,  ..., -0.2185, -0.9924, -0.2252],\n",
            "         [-0.6647,  0.9722, -0.5244,  ..., -0.4043, -0.7490, -0.1196],\n",
            "         ...,\n",
            "         [-0.2506,  0.7126, -0.7569,  ...,  0.5123,  0.1733, -0.1387],\n",
            "         [-0.8098,  1.0395, -0.7730,  ..., -0.2094, -0.3703, -0.3395],\n",
            "         [-0.1948,  0.2339, -0.2959,  ..., -0.1785, -0.0248,  0.3443]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([800, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([800, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4116,  1.5149, -0.7292,  ..., -0.7675, -1.4222, -0.9491],\n",
            "         [-0.8717,  0.8338,  0.2421,  ...,  0.1089, -0.5304, -0.1707],\n",
            "         [-0.8032,  0.8182,  0.1175,  ..., -0.9250, -0.7726, -0.9350],\n",
            "         ...,\n",
            "         [-0.6083,  0.4725, -0.6539,  ..., -0.5549, -0.9606,  0.1433],\n",
            "         [ 0.1189,  1.1965, -0.6424,  ..., -1.6530, -0.2713, -0.7926],\n",
            "         [-0.4838,  0.6702, -1.4279,  ..., -0.8653, -1.4914, -0.4779]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2189,  1.3392, -0.7973,  ..., -0.2612, -1.1593, -0.3031],\n",
            "         [-0.7395,  0.6784, -0.0844,  ...,  0.0975, -0.3642,  0.0136],\n",
            "         [-0.7523,  0.7343, -0.2322,  ..., -0.4755, -0.5504, -0.3262],\n",
            "         ...,\n",
            "         [-0.6111,  0.5182, -0.5558,  ..., -0.2698, -0.8158,  0.2342],\n",
            "         [-0.0896,  0.8845, -0.4919,  ..., -1.0054, -0.1105, -0.2952],\n",
            "         [-0.6572,  0.7820, -1.3222,  ..., -0.3277, -1.1812, -0.2164]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 22])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 22, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([688, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([688, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 16])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3475,  0.9709, -0.0690,  ..., -0.5754, -1.4533, -0.1424],\n",
            "         [-0.9853,  0.2143, -0.2140,  ...,  0.1635, -0.2354, -1.0870],\n",
            "         [-0.4259,  0.7435, -0.2102,  ..., -0.2176, -0.9529, -0.0306],\n",
            "         ...,\n",
            "         [-1.3150,  0.9199,  0.0244,  ..., -0.0889, -1.3385,  0.3237],\n",
            "         [ 0.2101,  1.1554, -0.7741,  ..., -1.3876, -0.0027, -0.8634],\n",
            "         [-1.2769,  1.0809, -1.4139,  ..., -1.9425, -1.2063, -1.5491]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4267,  0.6482, -0.0937,  ..., -0.1110, -1.1409,  0.1628],\n",
            "         [-0.8343,  0.3970, -0.3334,  ...,  0.2268, -0.1373, -0.4683],\n",
            "         [-0.4580,  0.5413, -0.1551,  ...,  0.0442, -0.8747,  0.3241],\n",
            "         ...,\n",
            "         [-0.8908,  0.6404, -0.0382,  ...,  0.1169, -1.0791,  0.5200],\n",
            "         [-0.0199,  0.8570, -0.5545,  ..., -0.8526,  0.0126, -0.3453],\n",
            "         [-1.0705,  0.9395, -1.1514,  ..., -0.9147, -0.8574, -0.5778]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 26])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 26, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([832, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([832, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4973,  1.1154, -0.3483,  ..., -0.5388, -1.6035, -0.0884],\n",
            "         [-0.8790,  0.0024, -0.4410,  ...,  0.0310, -0.5684, -0.5100],\n",
            "         [ 0.5651,  0.3190, -0.3053,  ..., -0.3163, -0.9220,  0.0756],\n",
            "         ...,\n",
            "         [-0.1351,  0.2094,  0.1321,  ...,  0.3170,  0.1796, -0.0792],\n",
            "         [ 0.0262,  0.1191, -0.0966,  ..., -0.1910,  0.0440,  0.3198],\n",
            "         [-1.5790,  0.9013, -0.4225,  ..., -2.1296, -0.5877, -1.1986]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6664,  0.8727, -0.3824,  ..., -0.0225, -1.3670,  0.2791],\n",
            "         [-0.5839,  0.1899, -0.2956,  ...,  0.0438, -0.4042, -0.1631],\n",
            "         [ 0.2589,  0.2462, -0.1444,  ..., -0.2047, -0.4096,  0.0100],\n",
            "         ...,\n",
            "         [-0.1251,  0.1400,  0.1200,  ...,  0.1432,  0.1147, -0.0202],\n",
            "         [-0.0336,  0.1601, -0.1569,  ..., -0.0861,  0.0172,  0.3152],\n",
            "         [-1.2614,  0.8250, -0.6383,  ..., -1.3086, -0.4340, -0.5686]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 31])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 31, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([979, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([979, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 19])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6553,  0.8236, -0.3237,  ..., -0.4925, -1.4517, -0.4305],\n",
            "         [-0.1912,  1.4733, -0.0313,  ..., -0.6947, -1.6222, -0.4237],\n",
            "         [-0.1912,  1.4733, -0.0313,  ..., -0.6947, -1.6222, -0.4237],\n",
            "         ...,\n",
            "         [-0.1211,  0.2262,  0.0574,  ...,  0.6905, -1.0657, -0.8298],\n",
            "         [-1.0014,  1.6580, -0.5018,  ..., -0.9430, -0.4977, -0.4246],\n",
            "         [ 0.0383, -0.1020,  0.2871,  ..., -0.1422,  0.2096,  0.4172]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5967,  0.6344, -0.3244,  ..., -0.0338, -1.3026,  0.1715],\n",
            "         [-0.5469,  1.0594, -0.1150,  ..., -0.0298, -1.4894,  0.1535],\n",
            "         [-0.5469,  1.0594, -0.1150,  ..., -0.0298, -1.4894,  0.1535],\n",
            "         ...,\n",
            "         [-0.2279,  0.3074, -0.1227,  ...,  0.4873, -0.5896, -0.4236],\n",
            "         [-0.8228,  1.1695, -0.5009,  ..., -0.4991, -0.4537, -0.1811],\n",
            "         [-0.0062, -0.1054,  0.0948,  ..., -0.1043,  0.0950,  0.3180]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 21])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 21, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([665, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([665, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 25])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2895,  0.9075,  0.0513,  ..., -0.0836, -1.3309,  0.3360],\n",
            "         [-1.9918,  1.5436, -1.6329,  ..., -1.1931, -0.7823, -1.0330],\n",
            "         [ 0.2612,  0.3251, -0.1020,  ...,  0.1036, -0.0587,  0.1498],\n",
            "         ...,\n",
            "         [-0.2174,  0.5322,  0.0255,  ..., -1.0827, -0.4693, -0.8648],\n",
            "         [-0.7657,  0.5630, -1.0317,  ..., -1.0396, -0.5608, -2.7453],\n",
            "         [-0.8381,  0.3522, -0.4204,  ..., -0.5183, -0.2753, -1.2205]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8760,  0.6290, -0.0191,  ...,  0.1192, -1.0708,  0.5292],\n",
            "         [-1.5014,  1.2910, -1.2685,  ..., -0.5437, -0.6721, -0.3310],\n",
            "         [ 0.0985,  0.2960, -0.0856,  ...,  0.0227, -0.1089,  0.0972],\n",
            "         ...,\n",
            "         [-0.2386,  0.4591, -0.1176,  ..., -0.5410, -0.3814, -0.3748],\n",
            "         [-0.7413,  0.6701, -0.9776,  ..., -0.4645, -0.5396, -1.3609],\n",
            "         [-0.6893,  0.5112, -0.5037,  ..., -0.1988, -0.3487, -0.6007]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([928, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([928, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8171,  1.4842, -0.2014,  ..., -0.5896, -1.6853, -0.5383],\n",
            "         [-0.3456,  1.5561, -0.1354,  ..., -0.3339, -0.8369, -0.1899],\n",
            "         [-0.3456,  1.5561, -0.1354,  ..., -0.3339, -0.8369, -0.1899],\n",
            "         ...,\n",
            "         [-0.3456,  1.5561, -0.1354,  ..., -0.3339, -0.8369, -0.1899],\n",
            "         [-1.1129,  1.3829, -0.5394,  ..., -0.8203, -1.3018, -0.5979],\n",
            "         [-1.0483,  1.0606,  0.6565,  ..., -1.0850, -0.3590, -0.5625]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8742,  1.0891, -0.2247,  ..., -0.0816, -1.5774, -0.0517],\n",
            "         [-0.4310,  1.0299, -0.1769,  ...,  0.0644, -0.7582,  0.3191],\n",
            "         [-0.4310,  1.0299, -0.1769,  ...,  0.0644, -0.7582,  0.3191],\n",
            "         ...,\n",
            "         [-0.4310,  1.0299, -0.1769,  ...,  0.0644, -0.7582,  0.3191],\n",
            "         [-0.8217,  1.0127, -0.4813,  ..., -0.3801, -1.0856, -0.0135],\n",
            "         [-0.6795,  0.7861,  0.2081,  ..., -0.4698, -0.1817, -0.1790]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 10])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 10, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([320, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([320, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1865,  1.4760, -0.3710,  ..., -0.9579, -1.5214, -1.0141],\n",
            "         [-1.4998,  1.1737, -0.5711,  ..., -1.2889, -2.0651, -0.8986],\n",
            "         [-1.0012,  0.7982, -1.0084,  ..., -1.3733, -0.5910, -0.9867],\n",
            "         ...,\n",
            "         [-1.0806,  1.2064, -0.2528,  ..., -0.1048, -1.1891, -1.3225],\n",
            "         [-0.5704,  0.7902, -0.2960,  ..., -0.5336, -1.2386, -0.4539],\n",
            "         [-1.1204,  1.0289, -0.9307,  ..., -0.4022, -0.9437, -0.7200]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.9117,  1.2580, -0.5129,  ..., -0.4210, -1.0397, -0.3045],\n",
            "         [-1.1695,  1.0139, -0.7443,  ..., -0.6662, -1.2897, -0.3747],\n",
            "         [-0.8963,  0.8283, -0.9267,  ..., -0.5670, -0.4081, -0.3772],\n",
            "         ...,\n",
            "         [-1.0244,  1.1346, -0.4320,  ...,  0.0828, -0.8257, -0.7365],\n",
            "         [-0.7069,  0.6666, -0.3426,  ..., -0.0583, -1.1223,  0.0937],\n",
            "         [-0.9810,  1.0366, -1.0034,  ..., -0.0290, -0.8070, -0.2958]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.5047,  1.4758, -1.4339,  ..., -1.2908, -1.3090, -2.1919],\n",
            "         [-1.5047,  1.4758, -1.4339,  ..., -1.2908, -1.3090, -2.1919],\n",
            "         [-1.5047,  1.4758, -1.4339,  ..., -1.2908, -1.3090, -2.1919],\n",
            "         ...,\n",
            "         [-1.5047,  1.4758, -1.4339,  ..., -1.2908, -1.3090, -2.1919],\n",
            "         [-1.5047,  1.4758, -1.4339,  ..., -1.2908, -1.3090, -2.1919],\n",
            "         [-1.5047,  1.4758, -1.4339,  ..., -1.2908, -1.3090, -2.1919]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2586,  1.4498, -1.4372,  ..., -0.6651, -1.0705, -1.2414],\n",
            "         [-1.2586,  1.4498, -1.4372,  ..., -0.6651, -1.0705, -1.2414],\n",
            "         [-1.2586,  1.4498, -1.4372,  ..., -0.6651, -1.0705, -1.2414],\n",
            "         ...,\n",
            "         [-1.2586,  1.4498, -1.4372,  ..., -0.6651, -1.0705, -1.2414],\n",
            "         [-1.2586,  1.4498, -1.4372,  ..., -0.6651, -1.0705, -1.2414],\n",
            "         [-1.2586,  1.4498, -1.4372,  ..., -0.6651, -1.0705, -1.2414]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 17])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 17, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([522, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([522, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 10])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.8665,  0.1787, -0.7451,  ..., -1.5374, -0.4187, -0.7397],\n",
            "         [-1.2576,  1.9257, -0.9465,  ..., -0.6034, -1.3335, -0.9221],\n",
            "         [ 0.1038,  0.6511, -0.3231,  ...,  0.0554, -0.2471, -0.7746],\n",
            "         ...,\n",
            "         [-0.2680,  0.4408, -0.1788,  ...,  0.3390, -0.6702, -0.9385],\n",
            "         [-0.0519, -0.0068, -0.3160,  ...,  0.1684, -1.2966, -0.5247],\n",
            "         [-1.0968,  1.8159, -0.7373,  ..., -0.7423, -0.3617, -1.4537]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6310,  0.3168, -0.5124,  ..., -0.8674, -0.2201, -0.2783],\n",
            "         [-1.1250,  1.4888, -0.9677,  ..., -0.1609, -1.2740, -0.3305],\n",
            "         [-0.1267,  0.7228, -0.3445,  ...,  0.1808, -0.1835, -0.2992],\n",
            "         ...,\n",
            "         [-0.3373,  0.5420, -0.3511,  ...,  0.3061, -0.3518, -0.4124],\n",
            "         [-0.3194,  0.2200, -0.3710,  ...,  0.2575, -0.9939, -0.0370],\n",
            "         [-1.0470,  1.4237, -0.8220,  ..., -0.2752, -0.5502, -0.6685]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 35])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 35, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1078, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1078, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 18,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7760,  1.6721, -1.2270,  ..., -1.1992, -1.0388, -0.7443],\n",
            "         [-0.3827,  0.4356,  0.3475,  ...,  0.0397, -0.0435,  0.3793],\n",
            "         [-0.7046,  1.2073,  0.4516,  ..., -1.4429, -2.2915, -0.0659],\n",
            "         ...,\n",
            "         [-0.4458,  1.0537, -0.9315,  ..., -1.0890, -0.7657, -0.7951],\n",
            "         [-0.2840,  1.0759,  0.0765,  ..., -0.2158, -0.8436, -0.0074],\n",
            "         [ 0.0996,  1.2171, -0.0875,  ..., -0.3231, -0.6348, -0.2486]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5733,  1.0124, -1.1743,  ..., -0.6156, -0.4882, -0.3811],\n",
            "         [-0.3879,  0.4554,  0.0917,  ...,  0.0514, -0.0928,  0.3477],\n",
            "         [-0.6050,  0.9118,  0.1368,  ..., -0.5867, -1.4063,  0.1222],\n",
            "         ...,\n",
            "         [-0.3168,  0.5370, -0.6251,  ..., -0.5016, -0.3313, -0.3195],\n",
            "         [-0.3350,  0.6711,  0.0426,  ...,  0.1012, -0.6839,  0.2487],\n",
            "         [-0.2261,  0.6876, -0.1146,  ...,  0.0751, -0.6340,  0.2066]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 6])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 6, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([126, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([126, 150]) \n",
            "\t\t Batch size :  tensor([32, 28, 26, 23, 14,  3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2610,  1.4075, -0.9340,  ..., -0.9153, -1.1531, -0.9463],\n",
            "         [-0.9734,  1.1962, -0.4402,  ..., -0.9766, -1.0222, -0.8387],\n",
            "         [-0.7588,  0.6431, -0.0200,  ..., -0.5126,  0.3769, -0.5166],\n",
            "         ...,\n",
            "         [-0.2137,  0.3791,  0.0063,  ...,  0.1479,  0.1697, -0.0264],\n",
            "         [ 0.0749,  0.2304, -0.3325,  ...,  0.3844, -0.3190, -0.2774],\n",
            "         [ 0.1167,  0.3836, -0.1678,  ...,  0.0630, -0.5672,  0.2845]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.9244,  1.1135, -0.9043,  ..., -0.3994, -0.7983, -0.4519],\n",
            "         [-0.7064,  1.0565, -0.5581,  ..., -0.4325, -0.6184, -0.2639],\n",
            "         [-0.5256,  0.6038, -0.1881,  ..., -0.2196,  0.0245, -0.1673],\n",
            "         ...,\n",
            "         [-0.1788,  0.3511,  0.0106,  ...,  0.0662, -0.0240, -0.0062],\n",
            "         [-0.0439,  0.1660, -0.2120,  ...,  0.2644, -0.1587, -0.1379],\n",
            "         [ 0.0114,  0.3387, -0.1045,  ...,  0.0460, -0.3648,  0.1377]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 10])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 10, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 20,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.1887,  1.1772, -0.2934,  ..., -0.1376,  0.1475, -0.3595],\n",
            "         [-0.8572,  0.8371, -0.9833,  ..., -0.2681, -0.8651, -0.8365],\n",
            "         [-1.0391,  1.1456, -0.1984,  ..., -0.0820, -1.1723, -1.2470],\n",
            "         ...,\n",
            "         [-0.4710,  0.6732,  0.3930,  ..., -0.6540, -0.6253, -0.1572],\n",
            "         [ 0.0465,  0.7048, -0.0971,  ..., -0.2648, -0.8279, -0.6500],\n",
            "         [ 0.4620,  0.4072,  0.0901,  ...,  0.1456,  0.0254, -0.1621]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.1391,  0.7315, -0.3097,  ..., -0.0054,  0.1458, -0.0687],\n",
            "         [-0.6107,  0.4995, -0.7141,  ..., -0.0337, -0.7228, -0.3027],\n",
            "         [-0.9926,  1.0955, -0.3829,  ...,  0.0974, -0.8056, -0.6985],\n",
            "         ...,\n",
            "         [-0.5734,  0.6893,  0.1184,  ..., -0.3222, -0.5423,  0.0532],\n",
            "         [-0.2106,  0.4645, -0.0928,  ..., -0.0410, -0.7355,  0.0064],\n",
            "         [ 0.1156,  0.3544, -0.1168,  ...,  0.1130, -0.1111,  0.0123]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1280, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1280, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.3855,  1.2976, -1.2546,  ..., -1.1631, -1.2389, -1.8715],\n",
            "         [-1.3855,  1.2976, -1.2546,  ..., -1.1631, -1.2389, -1.8715],\n",
            "         [-1.3855,  1.2976, -1.2546,  ..., -1.1631, -1.2389, -1.8715],\n",
            "         ...,\n",
            "         [-1.3855,  1.2976, -1.2546,  ..., -1.1631, -1.2389, -1.8715],\n",
            "         [-1.3855,  1.2976, -1.2546,  ..., -1.1631, -1.2389, -1.8715],\n",
            "         [-1.3855,  1.2976, -1.2546,  ..., -1.1631, -1.2389, -1.8715]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1784,  1.3274, -1.2942,  ..., -0.5716, -1.0156, -1.0524],\n",
            "         [-1.1784,  1.3274, -1.2942,  ..., -0.5716, -1.0156, -1.0524],\n",
            "         [-1.1784,  1.3274, -1.2942,  ..., -0.5716, -1.0156, -1.0524],\n",
            "         ...,\n",
            "         [-1.1784,  1.3274, -1.2942,  ..., -0.5716, -1.0156, -1.0524],\n",
            "         [-1.1784,  1.3274, -1.2942,  ..., -0.5716, -1.0156, -1.0524],\n",
            "         [-1.1784,  1.3274, -1.2942,  ..., -0.5716, -1.0156, -1.0524]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 20])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 20, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([633, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([633, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 25])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6818,  0.3262, -1.2107,  ..., -0.3471, -0.6533, -0.9323],\n",
            "         [-0.5470,  0.3442, -0.7609,  ..., -0.5101, -0.2678, -2.2946],\n",
            "         [-0.7913,  1.6250, -0.9347,  ..., -0.5483, -1.3161, -0.6022],\n",
            "         ...,\n",
            "         [-0.6520,  0.2283, -0.5947,  ..., -0.0961, -1.0240, -0.0798],\n",
            "         [-0.2437,  0.8118,  0.1092,  ..., -0.1936, -1.0950, -0.0309],\n",
            "         [ 0.0902,  0.2901,  0.1583,  ..., -0.2891, -0.3390, -0.0106]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6111,  0.5298, -0.9907,  ..., -0.1072, -0.5009, -0.3771],\n",
            "         [-0.4247,  0.3269, -0.5775,  ..., -0.2792, -0.2176, -1.0393],\n",
            "         [-0.7266,  1.2376, -0.7526,  ..., -0.1592, -0.9519, -0.2068],\n",
            "         ...,\n",
            "         [-0.5851,  0.3558, -0.6062,  ...,  0.1839, -0.7881,  0.0582],\n",
            "         [-0.3477,  0.5506, -0.0206,  ...,  0.1440, -0.9815,  0.4731],\n",
            "         [-0.1818,  0.2073,  0.1182,  ...,  0.0034, -0.3721,  0.2657]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 19])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 19, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([608, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([608, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.3151,  0.5957, -0.5347,  ...,  0.1694, -0.6369, -0.0961],\n",
            "         [-0.2419,  0.8091,  0.1154,  ..., -0.1902, -1.0922, -0.0284],\n",
            "         [-0.0662, -0.2856,  0.0930,  ..., -0.2566, -0.3241, -0.2314],\n",
            "         ...,\n",
            "         [-0.2419,  0.8091,  0.1154,  ..., -0.1902, -1.0922, -0.0284],\n",
            "         [-1.3976,  0.2498, -1.5984,  ..., -1.0533, -0.9559, -0.9406],\n",
            "         [ 0.2318,  1.2159, -0.8282,  ..., -1.1902,  0.0720, -0.5449]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[ 0.0617,  0.4722, -0.4124,  ...,  0.1394, -0.4138,  0.0526],\n",
            "         [-0.3464,  0.5481, -0.0163,  ...,  0.1466, -0.9787,  0.4754],\n",
            "         [-0.2497, -0.0531, -0.0514,  ..., -0.1326, -0.2373, -0.0173],\n",
            "         ...,\n",
            "         [-0.3464,  0.5481, -0.0163,  ...,  0.1466, -0.9787,  0.4754],\n",
            "         [-1.0676,  0.3565, -1.1609,  ..., -0.3956, -0.7310, -0.3620],\n",
            "         [ 0.0058,  0.8479, -0.5454,  ..., -0.7285,  0.0807, -0.2113]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 27])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 27, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([838, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([838, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32,  6])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2940,  0.2844, -0.3026,  ..., -0.4255, -1.1084, -1.3396],\n",
            "         [-0.1848,  0.8407,  0.2256,  ..., -0.1074, -1.0028,  0.1902],\n",
            "         [-0.6640,  0.9827, -0.4866,  ..., -0.8115, -1.0122, -0.9773],\n",
            "         ...,\n",
            "         [-1.1773,  0.5306,  0.0214,  ..., -1.8486, -0.4048, -0.7601],\n",
            "         [ 0.1895,  1.1049, -0.1977,  ..., -0.4933, -0.4191,  0.2827],\n",
            "         [ 0.5225,  0.7354, -0.5610,  ..., -0.6972,  0.2103, -0.2558]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3173,  0.4429, -0.4494,  ..., -0.1457, -0.7632, -0.5687],\n",
            "         [-0.3299,  0.4801,  0.1150,  ...,  0.1039, -0.8387,  0.4901],\n",
            "         [-0.4715,  0.7027, -0.6072,  ..., -0.3854, -0.4269, -0.4864],\n",
            "         ...,\n",
            "         [-0.9517,  0.5755, -0.2696,  ..., -1.0931, -0.2729, -0.3233],\n",
            "         [-0.1033,  0.6533, -0.1917,  ..., -0.1817, -0.2927,  0.3334],\n",
            "         [ 0.1984,  0.5605, -0.3200,  ..., -0.4491,  0.0822, -0.0762]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 13])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 13, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([387, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([387, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 27,  8])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3675,  0.8944,  0.1559,  ..., -0.8246, -0.1590, -0.7056],\n",
            "         [-0.3675,  0.8944,  0.1559,  ..., -0.8246, -0.1590, -0.7056],\n",
            "         [-0.2321,  0.3476,  0.0359,  ...,  0.0818, -0.6348, -0.7358],\n",
            "         ...,\n",
            "         [ 0.0114,  0.3627,  0.0332,  ..., -0.0613, -0.4125, -0.5091],\n",
            "         [ 0.0114,  0.3627,  0.0332,  ..., -0.0613, -0.4125, -0.5091],\n",
            "         [-1.0364,  0.4655, -1.0143,  ..., -0.7787, -1.0965, -0.4325]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3151,  0.8478, -0.1114,  ..., -0.4153, -0.0865, -0.1711],\n",
            "         [-0.3151,  0.8478, -0.1114,  ..., -0.4153, -0.0865, -0.1711],\n",
            "         [-0.1680,  0.4004, -0.0026,  ..., -0.0080, -0.3249, -0.3642],\n",
            "         ...,\n",
            "         [-0.1777,  0.2929, -0.0686,  ...,  0.0928, -0.3451, -0.1467],\n",
            "         [-0.1777,  0.2929, -0.0686,  ...,  0.0928, -0.3451, -0.1467],\n",
            "         [-0.8739,  0.6359, -0.8599,  ..., -0.3450, -0.8731, -0.1363]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 30])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 30, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([959, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([959, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0250,  0.6298, -0.3387,  ..., -0.6000, -0.7980, -0.6886],\n",
            "         [-1.0578,  1.4203, -1.4989,  ..., -0.4093, -0.9188, -1.1622],\n",
            "         [-0.5994,  1.3280, -0.2278,  ..., -0.3546, -0.4858, -0.4611],\n",
            "         ...,\n",
            "         [ 0.0866,  0.8159, -0.2287,  ..., -0.2719,  0.5171, -1.1904],\n",
            "         [-0.7541,  0.6912, -0.2928,  ..., -2.0638, -0.7050, -0.1298],\n",
            "         [-0.6121,  1.0665,  0.5019,  ..., -1.1303, -1.9169, -0.7391]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0666,  0.4126, -0.3534,  ..., -0.2790, -0.2115, -0.3982],\n",
            "         [-0.8348,  1.0043, -1.3275,  ..., -0.0701, -0.5514, -0.5245],\n",
            "         [-0.5830,  0.7651, -0.1161,  ...,  0.0129, -0.6286,  0.0618],\n",
            "         ...,\n",
            "         [-0.2536,  0.6672, -0.2668,  ..., -0.1032,  0.1165, -0.4176],\n",
            "         [-0.6561,  0.7039, -0.3509,  ..., -0.9735, -0.4776,  0.1195],\n",
            "         [-0.6130,  0.9583,  0.0113,  ..., -0.4718, -1.1953, -0.1214]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 27])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 27, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([864, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([864, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3148,  0.6066, -0.4807,  ..., -0.0517, -0.7356, -0.2991],\n",
            "         [-1.2069,  0.8885, -0.2338,  ..., -0.1394, -0.9782, -1.0380],\n",
            "         [ 0.2494,  1.3316, -0.8342,  ..., -0.8084, -1.2172, -0.0332],\n",
            "         ...,\n",
            "         [-0.1827,  0.8329,  0.2314,  ..., -0.1039, -1.0001,  0.1908],\n",
            "         [-0.7334,  0.8589, -2.0889,  ..., -0.9540, -0.6681, -1.2135],\n",
            "         [-1.3104,  0.6145,  0.1877,  ..., -1.2161, -1.2481, -0.9198]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3554,  0.5321, -0.4785,  ...,  0.0483, -0.4261, -0.1573],\n",
            "         [-0.9480,  0.8201, -0.3402,  ..., -0.0164, -0.7348, -0.4240],\n",
            "         [-0.0331,  0.9558, -0.7325,  ..., -0.2902, -0.6676,  0.1222],\n",
            "         ...,\n",
            "         [-0.3299,  0.4768,  0.1187,  ...,  0.1080, -0.8375,  0.4931],\n",
            "         [-0.5616,  0.7187, -1.6973,  ..., -0.5308, -0.4527, -0.5497],\n",
            "         [-0.8457,  0.6797, -0.0877,  ..., -0.5519, -0.8776, -0.2785]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 14])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 14, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([448, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([448, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5954,  1.0656, -1.3008,  ..., -0.8626, -0.8362, -1.2909],\n",
            "         [-0.8489,  0.1891, -0.3359,  ..., -1.2458, -1.5990, -0.2537],\n",
            "         [-1.2656,  1.0366, -0.2115,  ..., -1.0894, -1.6444, -0.9774],\n",
            "         ...,\n",
            "         [-0.3303,  0.6535, -0.0439,  ..., -0.1322, -0.8511,  0.0625],\n",
            "         [-0.8489,  0.1891, -0.3359,  ..., -1.2458, -1.5990, -0.2537],\n",
            "         [-0.1044,  0.4142,  0.4169,  ...,  0.0097, -0.2369,  0.3785]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4643,  0.7333, -1.0897,  ..., -0.4518, -0.4706, -0.7158],\n",
            "         [-0.8348,  0.3432, -0.4333,  ..., -0.7169, -1.0772,  0.0961],\n",
            "         [-1.1810,  1.0809, -0.5681,  ..., -0.5127, -1.1431, -0.3669],\n",
            "         ...,\n",
            "         [-0.3864,  0.4643, -0.0433,  ...,  0.0887, -0.7686,  0.3787],\n",
            "         [-0.8348,  0.3432, -0.4333,  ..., -0.7169, -1.0772,  0.0961],\n",
            "         [-0.2335,  0.3296,  0.1622,  ...,  0.1762, -0.2012,  0.3197]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([906, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([906, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 10])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4211,  1.0078, -0.1533,  ..., -0.4493, -1.5231, -0.0209],\n",
            "         [-0.6594, -0.1183, -0.5408,  ..., -0.2357, -0.7325, -0.0122],\n",
            "         [-0.4342,  1.2270, -0.0156,  ..., -0.3578, -1.5589, -0.2148],\n",
            "         ...,\n",
            "         [-1.1201,  1.5194, -0.6199,  ..., -1.3192, -1.2605, -1.0863],\n",
            "         [-0.7078,  0.5707, -1.1360,  ...,  0.5458, -0.5051, -1.7475],\n",
            "         [-0.4852,  0.7915, -0.7906,  ..., -0.7196, -0.6631, -0.5473]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6090,  0.7732, -0.2175,  ...,  0.0578, -1.2879,  0.3332],\n",
            "         [-0.3404, -0.0196, -0.3013,  ..., -0.0764, -0.4567,  0.1014],\n",
            "         [-0.6487,  0.8471, -0.0316,  ...,  0.0941, -1.4097,  0.1663],\n",
            "         ...,\n",
            "         [-0.8989,  1.2075, -0.7420,  ..., -0.5939, -0.9016, -0.4059],\n",
            "         [-0.6324,  0.5761, -0.8903,  ...,  0.3699, -0.3568, -0.8260],\n",
            "         [-0.4664,  0.6533, -0.8025,  ..., -0.2952, -0.3191, -0.2265]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 16])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 16, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([482, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([482, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2601, -0.3948, -0.9381,  ..., -1.0557, -0.4366, -1.1596],\n",
            "         [-0.8872,  0.6097, -0.8482,  ..., -0.0032, -0.7048, -0.3326],\n",
            "         [-1.3363,  0.8520, -0.8403,  ..., -1.1804, -1.2963, -1.2192],\n",
            "         ...,\n",
            "         [-1.3363,  0.8520, -0.8403,  ..., -1.1804, -1.2963, -1.2192],\n",
            "         [-1.3363,  0.8520, -0.8403,  ..., -1.1804, -1.2963, -1.2192],\n",
            "         [-0.2384,  0.7508,  0.0614,  ...,  0.0418, -0.6441, -0.3392]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3038,  0.1160, -0.7226,  ..., -0.6783, -0.1653, -0.4988],\n",
            "         [-0.8324,  0.6495, -0.8365,  ...,  0.1472, -0.5120, -0.1207],\n",
            "         [-1.2340,  0.9367, -0.8752,  ..., -0.5987, -1.0845, -0.5472],\n",
            "         ...,\n",
            "         [-1.2340,  0.9367, -0.8752,  ..., -0.5987, -1.0845, -0.5472],\n",
            "         [-1.2340,  0.9367, -0.8752,  ..., -0.5987, -1.0845, -0.5472],\n",
            "         [-0.2018,  0.6884, -0.1749,  ...,  0.0419, -0.3535, -0.0372]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  7 \n",
            "\t\t Data :  torch.Size([7, 43])\n",
            "\t Input Lengths :  torch.Size([7])\n",
            "\t Embeddings :  torch.Size([7, 43, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([285, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([285, 150]) \n",
            "\t\t Batch size :  tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 1])\n",
            "\t Hidden :  torch.Size([1, 7, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 7, 150]) \n",
            "\t\t Data :  tensor([[[-0.2109,  1.0281, -0.0858,  ..., -0.5009, -0.9171, -0.2273],\n",
            "         [-0.2513, -1.0811,  0.7083,  ...,  0.3959,  0.5943, -0.2123],\n",
            "         [-1.3759,  1.2505, -1.2282,  ..., -1.1403, -1.2327, -1.8181],\n",
            "         ...,\n",
            "         [-1.3759,  1.2505, -1.2282,  ..., -1.1403, -1.2327, -1.8181],\n",
            "         [-1.3759,  1.2505, -1.2282,  ..., -1.1403, -1.2327, -1.8181],\n",
            "         [-1.3759,  1.2505, -1.2282,  ..., -1.1403, -1.2327, -1.8181]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 7, 150])\n",
            "\t Hidden :  torch.Size([1, 7, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 7, 150]) \n",
            "\t\t Data :  tensor([[[-0.3954,  0.6957, -0.1131,  ..., -0.0990, -0.8393,  0.1464],\n",
            "         [-0.2256, -0.5097,  0.3453,  ...,  0.1179,  0.3301,  0.2111],\n",
            "         [-1.1792,  1.3090, -1.2849,  ..., -0.5639, -1.0148, -1.0372],\n",
            "         ...,\n",
            "         [-1.1792,  1.3090, -1.2849,  ..., -0.5639, -1.0148, -1.0372],\n",
            "         [-1.1792,  1.3090, -1.2849,  ..., -0.5639, -1.0148, -1.0372],\n",
            "         [-1.1792,  1.3090, -1.2849,  ..., -0.5639, -1.0148, -1.0372]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 26])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 26, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([802, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([802, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6846,  0.6693, -0.9796,  ...,  0.4793, -0.4511, -1.8072],\n",
            "         [-1.1740,  0.2756, -0.6233,  ..., -0.4236, -0.4565, -0.8023],\n",
            "         [-0.2625, -0.1121, -0.0826,  ..., -0.3052,  0.2287,  0.7474],\n",
            "         ...,\n",
            "         [-1.1378,  0.9802, -0.5429,  ..., -2.0112, -1.2215, -0.6312],\n",
            "         [ 0.4723,  0.5222, -0.4710,  ..., -0.8571,  0.2658, -0.0935],\n",
            "         [-0.3617,  1.4367, -0.4721,  ..., -1.0178, -0.1021, -0.7958]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.6404,  0.6290, -0.8059,  ...,  0.3298, -0.3355, -0.8684],\n",
            "         [-0.8258,  0.4180, -0.4851,  ..., -0.0794, -0.3411, -0.2178],\n",
            "         [-0.2348,  0.0859, -0.2142,  ..., -0.1477,  0.0274,  0.5601],\n",
            "         ...,\n",
            "         [-1.0654,  0.8983, -0.5813,  ..., -1.0642, -0.9642, -0.1409],\n",
            "         [ 0.2221,  0.4275, -0.2588,  ..., -0.5377,  0.1513, -0.0544],\n",
            "         [-0.5894,  1.0461, -0.3938,  ..., -0.4779, -0.2971, -0.2422]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 15])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 15, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([476, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([476, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4541,  1.1590, -1.4216,  ..., -1.2652, -1.2068, -0.8245],\n",
            "         [-0.3151,  1.4269, -0.1374,  ..., -0.7396, -0.7155, -1.3938],\n",
            "         [-1.3735,  0.8649, -0.8868,  ..., -1.2073, -1.3140, -1.2656],\n",
            "         ...,\n",
            "         [-1.4871,  0.8761, -0.6152,  ..., -0.7067, -1.0458, -0.9964],\n",
            "         [-0.1095,  0.4234,  0.4139,  ...,  0.0059, -0.2512,  0.3775],\n",
            "         [-0.8742,  0.9358,  0.1029,  ..., -0.5371,  0.1571, -0.6509]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.1427,  1.0356, -1.2246,  ..., -0.6052, -0.7725, -0.1748],\n",
            "         [-0.5252,  1.0278, -0.3792,  ..., -0.3287, -0.5879, -0.5660],\n",
            "         [-1.2590,  0.9571, -0.9263,  ..., -0.6262, -1.1029, -0.5892],\n",
            "         ...,\n",
            "         [-1.1850,  0.7700, -0.5256,  ..., -0.3810, -0.8673, -0.3245],\n",
            "         [-0.2414,  0.3378,  0.1596,  ...,  0.1780, -0.2128,  0.3244],\n",
            "         [-0.6496,  0.6851, -0.0114,  ..., -0.2533,  0.0239, -0.2296]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 19])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 19, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([579, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([579, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "         3])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2722,  0.8216,  0.0988,  ..., -0.2209, -1.1158, -0.0513],\n",
            "         [-0.6482, -0.1644,  0.0300,  ..., -1.1896, -0.1007, -1.3031],\n",
            "         [-0.2722,  0.8216,  0.0988,  ..., -0.2209, -1.1158, -0.0513],\n",
            "         ...,\n",
            "         [-0.8707,  0.1574, -0.2993,  ..., -0.6306, -0.4424, -0.8497],\n",
            "         [-0.5489,  1.6698,  0.1544,  ..., -0.2820, -0.4711, -0.5955],\n",
            "         [-1.0443,  1.2294, -1.7058,  ..., -1.0279, -0.6845, -1.1512]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3812,  0.5717, -0.0301,  ...,  0.1439, -1.0120,  0.4778],\n",
            "         [-0.5712,  0.2845, -0.1727,  ..., -0.7115, -0.0814, -0.4937],\n",
            "         [-0.3812,  0.5717, -0.0301,  ...,  0.1439, -1.0120,  0.4778],\n",
            "         ...,\n",
            "         [-0.7553,  0.3747, -0.4038,  ..., -0.2981, -0.4631, -0.3115],\n",
            "         [-0.5342,  0.8964, -0.0139,  ...,  0.0101, -0.3172, -0.1260],\n",
            "         [-0.8108,  0.8255, -1.3629,  ..., -0.4553, -0.5086, -0.5307]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 24])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 24, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([762, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([762, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 26])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.7496e-02,  1.1583e+00,  6.9746e-02,  ..., -2.3913e-01,\n",
            "          -4.7632e-01, -1.2821e-01],\n",
            "         [-9.1000e-01,  7.1932e-01, -6.9872e-02,  ..., -8.0056e-01,\n",
            "          -9.4575e-01, -2.5828e-01],\n",
            "         [-1.1138e+00,  1.1617e+00, -3.3923e-01,  ..., -8.8171e-01,\n",
            "           1.4778e-01, -2.0230e+00],\n",
            "         ...,\n",
            "         [-1.2915e+00,  7.9229e-01, -9.4308e-01,  ..., -2.3621e-01,\n",
            "          -7.9208e-01, -1.1785e+00],\n",
            "         [-5.6205e-01,  1.6187e-03, -5.5673e-01,  ..., -9.5289e-01,\n",
            "          -4.5979e-01, -8.6346e-01],\n",
            "         [-2.9337e-01,  5.0301e-01, -5.4160e-02,  ..., -1.9107e-01,\n",
            "          -1.3215e+00,  1.8808e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2647,  0.8393, -0.0283,  ...,  0.0696, -0.4287,  0.2144],\n",
            "         [-0.8347,  0.7077, -0.2948,  ..., -0.3906, -0.6730,  0.1104],\n",
            "         [-0.7968,  1.0250, -0.5385,  ..., -0.4742, -0.1001, -1.0606],\n",
            "         ...,\n",
            "         [-1.1261,  0.8589, -0.9807,  ...,  0.0036, -0.6076, -0.6698],\n",
            "         [-0.5359,  0.0496, -0.2837,  ..., -0.4265, -0.4207, -0.2471],\n",
            "         [-0.3838,  0.5546, -0.2504,  ...,  0.0833, -0.8363,  0.2279]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 14])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 14, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([423, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([423, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  7])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7119,  0.4843, -0.0839,  ..., -0.5015, -1.8127, -1.3957],\n",
            "         [-0.7226,  1.2008, -0.7056,  ..., -1.3721, -0.6505, -1.2243],\n",
            "         [-0.1110,  0.4272,  0.4136,  ...,  0.0061, -0.2588,  0.3773],\n",
            "         ...,\n",
            "         [-0.4741,  0.2694, -0.2203,  ..., -0.0621, -1.1335, -0.0830],\n",
            "         [-0.7689,  0.3128, -0.2632,  ..., -0.3611, -0.6115,  0.0143],\n",
            "         [-0.8425, -0.3081, -0.4987,  ..., -0.5160, -0.2704, -0.3525]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7136,  0.6241, -0.3381,  ..., -0.1835, -1.1170, -0.5308],\n",
            "         [-0.6238,  0.8864, -0.6931,  ..., -0.7602, -0.4747, -0.4965],\n",
            "         [-0.2447,  0.3408,  0.1591,  ...,  0.1800, -0.2191,  0.3274],\n",
            "         ...,\n",
            "         [-0.4430,  0.3480, -0.3702,  ...,  0.0959, -0.7830,  0.0894],\n",
            "         [-0.6784,  0.5149, -0.3951,  ..., -0.0698, -0.5223,  0.0627],\n",
            "         [-0.5621,  0.0074, -0.3256,  ..., -0.3589, -0.1858, -0.1890]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 11])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 11, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([247, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([247, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 30, 29, 27, 26, 22, 19, 15, 11,  4])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.5994,  0.3797,  0.0865,  ...,  0.0444, -0.5844, -0.5099],\n",
            "         [ 0.1426, -0.1905,  0.1140,  ...,  0.8030, -0.5947, -0.6251],\n",
            "         [-0.0289,  0.3779,  0.0185,  ..., -0.0961, -0.4396, -0.5591],\n",
            "         ...,\n",
            "         [-0.7908,  0.1603, -0.1525,  ..., -0.5755,  0.0226, -0.8161],\n",
            "         [-0.0995,  0.4325, -0.1703,  ..., -0.0171, -0.1818, -0.3712],\n",
            "         [ 0.4348, -0.0557, -0.1102,  ...,  0.4320, -0.3981, -0.4770]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3743,  0.3073,  0.1252,  ...,  0.0471, -0.3888, -0.1734],\n",
            "         [ 0.0018,  0.0500,  0.0133,  ...,  0.4845, -0.2615, -0.2887],\n",
            "         [-0.2125,  0.3241, -0.0861,  ...,  0.0838, -0.3688, -0.1693],\n",
            "         ...,\n",
            "         [-0.7519,  0.5029, -0.3409,  ..., -0.2523, -0.2168, -0.3489],\n",
            "         [-0.1979,  0.3866, -0.1986,  ...,  0.0957, -0.1055, -0.1107],\n",
            "         [ 0.1505,  0.0074,  0.0190,  ...,  0.2071, -0.2118, -0.2339]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 16])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 16, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([448, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([448, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 26, 21, 12,  9])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.0486,  0.7091, -0.1045,  ..., -0.1520, -1.0967, -0.3276],\n",
            "         [ 0.1354, -0.3881, -0.0737,  ...,  0.2736, -0.3912, -1.0391],\n",
            "         [-0.1869,  0.2239, -0.3086,  ...,  0.0746, -0.6760, -0.4816],\n",
            "         ...,\n",
            "         [-0.4551,  0.1173, -0.5655,  ...,  0.2000, -0.6823, -0.7746],\n",
            "         [-0.9910,  0.6352, -0.5361,  ..., -0.1042, -0.5705, -1.1178],\n",
            "         [-0.4033, -0.1102, -0.5927,  ...,  0.2490, -0.2224, -0.9386]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3438,  0.5054, -0.1335,  ...,  0.1458, -1.0123,  0.1394],\n",
            "         [-0.1612, -0.0388, -0.0218,  ...,  0.2006, -0.2576, -0.4813],\n",
            "         [-0.2978,  0.3177, -0.2175,  ...,  0.1135, -0.3822, -0.1977],\n",
            "         ...,\n",
            "         [-0.5566,  0.3458, -0.5019,  ...,  0.1941, -0.5377, -0.3149],\n",
            "         [-0.7616,  0.6885, -0.3491,  ..., -0.0646, -0.4202, -0.4760],\n",
            "         [-0.4492,  0.1745, -0.4036,  ...,  0.1919, -0.2600, -0.4973]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 21])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 21, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([608, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([608, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 29, 26,\n",
            "        20, 13,  8])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.2445, -0.0682, -0.7972,  ...,  0.4942, -0.7315, -1.1489],\n",
            "         [ 0.0117, -0.4482,  0.0084,  ...,  0.6095, -0.5573, -0.6485],\n",
            "         [-0.7257,  0.8862, -0.4686,  ..., -0.6058, -1.0474, -0.6056],\n",
            "         ...,\n",
            "         [-0.3878,  0.4413, -0.1550,  ..., -0.3222, -1.1815, -0.5889],\n",
            "         [ 0.2576, -0.1778,  0.2755,  ...,  0.4420, -0.6271, -0.5916],\n",
            "         [-0.5178,  0.2840,  0.4774,  ...,  0.0883, -0.4362, -0.5562]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.3565,  0.1952, -0.5709,  ...,  0.3661, -0.4958, -0.6198],\n",
            "         [-0.1480, -0.1392,  0.0224,  ...,  0.3449, -0.3357, -0.3362],\n",
            "         [-0.7769,  0.8078, -0.4876,  ..., -0.0915, -1.0141, -0.0021],\n",
            "         ...,\n",
            "         [-0.5657,  0.3864, -0.1011,  ...,  0.0907, -1.0652,  0.0492],\n",
            "         [ 0.0068,  0.0033,  0.1919,  ...,  0.2566, -0.2951, -0.3247],\n",
            "         [-0.3322,  0.2285,  0.3342,  ...,  0.0687, -0.2312, -0.1842]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 25])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 25, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([749, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([749, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 31, 21, 18,  7])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.7576,  0.8697, -1.0099,  ..., -0.8833, -1.3733, -0.5683],\n",
            "         [-0.8760,  1.2350, -0.3423,  ..., -0.4135, -1.2174, -0.6016],\n",
            "         [ 0.2567, -0.4493,  0.1968,  ...,  0.9598, -0.4455, -0.4789],\n",
            "         ...,\n",
            "         [-0.2621,  0.0077, -0.1986,  ...,  0.2646, -0.5176, -1.1359],\n",
            "         [-0.1886,  0.0036,  0.1470,  ..., -0.3365, -1.3962, -0.2835],\n",
            "         [-0.4450,  1.8185, -0.3306,  ..., -0.8687, -0.8753, -0.7755]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2605,  0.8412, -0.9877,  ..., -0.4387, -0.9115, -0.1493],\n",
            "         [-0.9160,  0.9943, -0.2935,  ...,  0.0354, -1.0852, -0.0158],\n",
            "         [ 0.0737, -0.1705,  0.1062,  ...,  0.5510, -0.1696, -0.2589],\n",
            "         ...,\n",
            "         [-0.3201,  0.2805, -0.3754,  ...,  0.2259, -0.3010, -0.4876],\n",
            "         [-0.3426,  0.0691,  0.0697,  ...,  0.0346, -1.1191,  0.1917],\n",
            "         [-0.5923,  1.4144, -0.4775,  ..., -0.3426, -0.9416, -0.1343]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 29])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 29, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([868, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([868, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 29, 21, 12,  6])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.7612,  0.6676, -0.3623,  ..., -0.0580, -0.7718, -0.2540],\n",
            "         [-1.0002,  0.3503, -0.0379,  ..., -0.2967, -0.7679,  0.2045],\n",
            "         [-0.2117, -0.1896, -0.1138,  ...,  0.2867, -0.4447, -0.5202],\n",
            "         ...,\n",
            "         [-0.5025, -0.2129, -0.1133,  ..., -0.0968, -0.4796, -0.0816],\n",
            "         [ 0.5111,  1.7668, -1.1663,  ..., -0.6817, -0.7236, -0.5706],\n",
            "         [-0.4523, -0.2369,  0.1502,  ..., -0.0406,  0.0347, -0.6135]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-0.4838,  0.5944, -0.2616,  ...,  0.1014, -0.5430, -0.1008],\n",
            "         [-0.7078,  0.3519, -0.1367,  ..., -0.0449, -0.5042,  0.1737],\n",
            "         [-0.3220,  0.0778, -0.1026,  ...,  0.2025, -0.3776, -0.2253],\n",
            "         ...,\n",
            "         [-0.4571, -0.0295, -0.1316,  ..., -0.0267, -0.2863,  0.1638],\n",
            "         [ 0.0267,  1.0008, -0.7957,  ..., -0.3694, -0.5911, -0.1864],\n",
            "         [-0.2183, -0.0447,  0.2023,  ..., -0.0132,  0.0421, -0.3052]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  32 \n",
            "\t\t Data :  torch.Size([32, 40])\n",
            "\t Input Lengths :  torch.Size([32])\n",
            "\t Embeddings :  torch.Size([32, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([1019, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([1019, 150]) \n",
            "\t\t Batch size :  tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
            "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 22, 13,  7,  4,  3,  3,\n",
            "         3,  3,  3,  2])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         [-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         [-0.5912,  2.3265, -4.3206,  ..., -1.4522, -0.7070, -1.4678],\n",
            "         ...,\n",
            "         [-0.3169,  1.4927, -0.0661,  ..., -0.3122, -0.8112, -0.1742],\n",
            "         [-0.3623,  1.2467, -0.3294,  ..., -0.6601, -0.8700, -0.2812],\n",
            "         [ 0.0415,  0.0731,  0.2390,  ..., -0.1201,  0.0982,  0.0343]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 32, 150])\n",
            "\t Hidden :  torch.Size([1, 32, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 32, 150]) \n",
            "\t\t Data :  tensor([[[-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         [-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         [-0.4158,  1.0409, -3.2367,  ..., -0.7373, -0.1565, -0.8428],\n",
            "         ...,\n",
            "         [-0.4259,  0.9859, -0.1261,  ...,  0.1014, -0.7423,  0.3596],\n",
            "         [-0.4761,  0.8583, -0.3227,  ..., -0.1990, -0.8844,  0.1092],\n",
            "         [-0.0509,  0.1463,  0.0960,  ..., -0.0522,  0.0256,  0.0746]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Shapes Insider Encoders :\n",
            "\t Input Length :  13 \n",
            "\t\t Data :  torch.Size([13, 40])\n",
            "\t Input Lengths :  torch.Size([13])\n",
            "\t Embeddings :  torch.Size([13, 40, 300]) \n",
            "\t\t Packed Embedded inout :  torch.Size([520, 300])\n",
            "Shapes of Encoders :\n",
            "\t Output Length :  4 \n",
            "\t\t Data :  torch.Size([520, 150]) \n",
            "\t\t Batch size :  tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
            "        13, 13, 13, 13])\n",
            "\t Hidden :  torch.Size([1, 13, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 13, 150]) \n",
            "\t\t Data :  tensor([[[-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         [-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         [-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         ...,\n",
            "         [-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         [-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160],\n",
            "         [-1.4225,  1.2982, -1.2811,  ..., -1.1788, -1.2601, -1.9160]]],\n",
            "       device='cuda:0')\n",
            "-------------------------------------------\n",
            "Shapes of Decoders :\n",
            "\t Output Length :  1 \n",
            "\t\t Data :  torch.Size([1, 13, 150])\n",
            "\t Hidden :  torch.Size([1, 13, 150])\n",
            "\t Cell Length :  1 \n",
            "\t\t Data Shape :  torch.Size([1, 13, 150]) \n",
            "\t\t Data :  tensor([[[-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         [-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         [-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         ...,\n",
            "         [-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         [-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053],\n",
            "         [-1.2150,  1.3499, -1.3354,  ..., -0.5994, -1.0395, -1.1053]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "\tTrain Loss: 0.509 | Train Acc: 79.34%\n",
            "\t Val. Loss: 0.669 |  Val. Acc: 71.43% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZgzB0ZkHVTI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZfnWo0abRx"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTkHLEipIlM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08f237d8-fbba-4205-f9fe-3188fdd6561d"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVjCuKK_LVEF"
      },
      "source": [
        "## Discussion on Data Augmentation Techniques \n",
        "\n",
        "You might wonder exactly how you can augment text data. After all, you can’t really flip it horizontally as you can an image! :D \n",
        "\n",
        "In contrast to data augmentation in images, augmentation techniques on data is very specific to final product you are building. As its general usage on any type of textual data doesn't provides a significant performance boost, that's why unlike torchvision, torchtext doesn’t offer a augmentation pipeline. Due to powerful models as transformers, augmentation tecnhiques are not so preferred now-a-days. But its better to know about some techniques with text that will provide your model with a little more information for training. \n",
        "\n",
        "### Synonym Replacement\n",
        "\n",
        "First, you could replace words in the sentence with synonyms, like so:\n",
        "\n",
        "    The dog slept on the mat\n",
        "\n",
        "could become\n",
        "\n",
        "    The dog slept on the rug\n",
        "\n",
        "Aside from the dog's insistence that a rug is much softer than a mat, the meaning of the sentence hasn’t changed. But mat and rug will be mapped to different indices in the vocabulary, so the model will learn that the two sentences map to the same label, and hopefully that there’s a connection between those two words, as everything else in the sentences is the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_uEfWJpL6Nq"
      },
      "source": [
        "### Random Insertion\n",
        "A random insertion technique looks at a sentence and then randomly inserts synonyms of existing non-stopwords into the sentence n times. Assuming you have a way of getting a synonym of a word and a way of eliminating stopwords (common words such as and, it, the, etc.), shown, but not implemented, in this function via get_synonyms() and get_stopwords(), an implementation of this would be as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Alm5D7WIvAC"
      },
      "source": [
        "def random_insertion(sentence, n): \n",
        "    words = remove_stopwords(sentence) \n",
        "    for _ in range(n):\n",
        "        new_synonym = get_synonyms(random.choice(words))\n",
        "        sentence.insert(randrange(len(sentence)+1), new_synonym) \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqLWzwJ3Mm8h"
      },
      "source": [
        "## Random Deletion\n",
        "As the name suggests, random deletion deletes words from a sentence. Given a probability parameter p, it will go through the sentence and decide whether to delete a word or not based on that random probability. Consider of it as pixel dropouts while treating images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Dz7JJfMqyC"
      },
      "source": [
        "def random_deletion(words, p=0.5): \n",
        "    if len(words) == 1: # return if single word\n",
        "        return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)] \n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOIbi5WzO5OU"
      },
      "source": [
        "### Random Swap\n",
        "The random swap augmentation takes a sentence and then swaps words within it n times, with each iteration working on the previously swapped sentence. Here we sample two random numbers based on the length of the sentence, and then just keep swapping until we hit n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnkbG15HO3Yj"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "599NpwfMR5Vm"
      },
      "source": [
        "For more on this please go through this [paper](https://arxiv.org/pdf/1901.11196.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5aeKuNCRGip"
      },
      "source": [
        "### Back Translation\n",
        "\n",
        "Another popular approach for augmenting text datasets is back translation. This involves translating a sentence from our target language into one or more other languages and then translating all of them back to the original language. We can use the Python library googletrans for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhNBbYrRXNy"
      },
      "source": [
        "import random\n",
        "import googletrans\n",
        "import googletrans.Translator\n",
        "\n",
        "translator = Translator()\n",
        "sentence = ['']\n",
        "\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "trans_lang = random.choice(available_langs) \n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")\n",
        "\n",
        "translations = translator.translate(sentence, dest=trans_lang) \n",
        "t_text = [t.text for t in translations]\n",
        "print(t_text)\n",
        "\n",
        "translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "en_text = [t.text for t in translations_en_random]\n",
        "print(en_text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}