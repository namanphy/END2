{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jofyc9OC4Qcf"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ahBVnrNc3E0U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crQSAaIz4SkA"
   },
   "source": [
    "# Read and process data. \n",
    "\n",
    "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rgOGxPDP3Wpp"
   },
   "outputs": [],
   "source": [
    "data = open('text.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeXXMLRb4kXb"
   },
   "source": [
    "Process data and calculate indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5TKeiOp4jtl",
    "outputId": "e86fb70a-7f1c-4643-afda-da0c986d0549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corona Virus article has 10245 characters, 79 unique characters\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, X_size = len(data), len(chars)\n",
    "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C53MB135LRY"
   },
   "source": [
    "# Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XsyY2c8JfRGL",
    "outputId": "51ede596-262b-497e-b9f4-39b4fd08d2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(X_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dfj21ORa49Ps"
   },
   "outputs": [],
   "source": [
    "Hidden_Layer_size = 100  # size of the hidden layer\n",
    "Time_steps = 40  # Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 1e-1  # Learning Rate\n",
    "weight_sd = 0.1  # Standard deviation of weights for initialization\n",
    "z_size = Hidden_Layer_size + X_size  # Size of concatenation(H, X) vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdmJf4Du5uhb"
   },
   "source": [
    "# Activation Functions and Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "seGHei_D5FGk"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): # sigmoid function\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y): # derivative of sigmoid function\n",
    "    s = 1 / (1 + np.exp(-y))\n",
    "    ds = s * (1-s)  \n",
    "    return ds\n",
    "\n",
    "def tanh(x): # tanh function\n",
    "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "\n",
    "def dtanh(y): # derivative of tanh\n",
    "    t = (np.exp(y)-np.exp(-y))/(np.exp(y)+np.exp(-y))\n",
    "    dt = 1 - t**2\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftrFxYIMcHU8",
    "outputId": "f37a8902-5e72-417f-96d7-b6f82e452438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0):  0.5\n",
      "dsigmoid(sigmoid(0)):  0.2350037122015945\n",
      "tanh(dsigmoid(sigmoid(0))):  0.2307710272926823\n",
      "dtanh(tanh(dsigmoid(sigmoid(0)))):  0.9485799654066528\n"
     ]
    }
   ],
   "source": [
    "print('sigmoid(0): ', sigmoid(0))\n",
    "print('dsigmoid(sigmoid(0)): ', dsigmoid(sigmoid(0)))\n",
    "print('tanh(dsigmoid(sigmoid(0))): ',  tanh(dsigmoid(sigmoid(0))))\n",
    "print('dtanh(tanh(dsigmoid(sigmoid(0)))): ', dtanh(tanh(dsigmoid(sigmoid(0)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeCvVH1v6Me-"
   },
   "source": [
    "# Quiz Question 1\n",
    "\n",
    "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
    "\n",
    "ANS: 0.5\n",
    "\n",
    "# Quiz Question 2\n",
    "\n",
    "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
    "\n",
    "ANS: \n",
    "\n",
    "# Quiz Question 3\n",
    "\n",
    "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
    "\n",
    "# Quiz Question 4\n",
    "\n",
    "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeSVipDu8iKE"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ICbWNemE6LGV"
   },
   "outputs": [],
   "source": [
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "      self.name = name\n",
    "      self.v = value # parameter value\n",
    "      self.d = np.zeros_like(value) # derivative\n",
    "      self.m = np.zeros_like(value) # momentum for Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j83pZNPE8212"
   },
   "source": [
    "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
    "\n",
    "Biases are initialized to zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swHwLXOI9E7V"
   },
   "source": [
    "# LSTM \n",
    "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
    "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
    "\n",
    "Please note that we are concatenating the old_hidden_vector and new_input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0DBzNY-90s5"
   },
   "source": [
    "# Quiz Question 4\n",
    "\n",
    "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SFuHhqVq6Wge"
   },
   "outputs": [],
   "source": [
    "size_a = Hidden_Layer_size\n",
    "size_b = z_size\n",
    "size_c = X_size\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
    "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
    "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzmfGLZt_xVs"
   },
   "source": [
    "Look at these operations which we'll be writing:\n",
    "\n",
    "**Concatenation of h and x:**\n",
    "\n",
    "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
    "\n",
    "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
    "\n",
    "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
    "\n",
    "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
    "\n",
    "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
    "\n",
    "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
    "\n",
    "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
    "\n",
    "**Logits:**\n",
    "\n",
    "$v_t=W_v\\cdot h_t+b_v$\n",
    "\n",
    "**Softmax:**\n",
    "\n",
    "$\\hat{y}=softmax\\left(v_t\\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-bUkseNnDott"
   },
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p = parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
    "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    \n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = np.multiply(f,C_prev) + np.multiply(i,C_bar)\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = np.multiply(o, tanh(C))\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "#     temp = [np.isnan(x).any() for x in [z, f, i, C_bar, C, o, h, v, y]]\n",
    "#     print(temp)\n",
    "#     if any(temp):\n",
    "#         for x in [z, f, i, C_bar, C, o, h, v, y]:\n",
    "#             print(x.shape)\n",
    "#             print(x)\n",
    "    return z, f, i, C_bar, C, o, h, v, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZrDhZIjFpdI"
   },
   "source": [
    "You must finish the function above before you can attempt the questions below. \n",
    "\n",
    "# Quiz Question 5\n",
    "\n",
    "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?\n",
    "\n",
    "ANS: 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRz2mC-ulLmJ",
    "outputId": "70aacbe3-fe24-4ede-9712-68057719e4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV-YVl_GGiX8"
   },
   "source": [
    "# Quiz Question 6. \n",
    "\n",
    "Assuming you have fixed the forward function, run this command: \n",
    "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
    "\n",
    "Now, find these values:\n",
    "\n",
    "\n",
    "1.   print(z.shape)\n",
    "2.   print(np.sum(z))\n",
    "3.   print(np.sum(f))\n",
    "\n",
    "Copy and paste exact values you get in the logs into the quiz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GvKVWmTDt3H",
    "outputId": "6bd0a586-58ad-4328-d2a0-42e4ef9057a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 1)\n",
      "0.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
    "\n",
    "print(z.shape)\n",
    "print(np.sum(z))\n",
    "print(np.sum(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeSvhkqwILsG"
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zIa1jUZiGPmF"
   },
   "outputs": [],
   "source": [
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters):\n",
    "    \n",
    "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
    "    assert v.shape == (X_size, 1)\n",
    "    assert y.shape == (X_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (Hidden_Layer_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:Hidden_Layer_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tnc7WpRkIU5S"
   },
   "source": [
    "# Forward and Backward Combined Pass\n",
    "\n",
    "Let's first clear the gradients before each backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OJWoC3U1ITf8"
   },
   "outputs": [],
   "source": [
    "def clear_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XN93UnjIgmA"
   },
   "source": [
    "Clip gradients to mitigate exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0LTsublxIfFl"
   },
   "outputs": [],
   "source": [
    "def clip_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7XUpDTWIl_Y"
   },
   "source": [
    "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
    "\n",
    "input, target are list of integers, with character indexes.\n",
    "h_prev is the array of initial h at  h−1  (size H x 1)\n",
    "C_prev is the array of initial C at  C−1  (size H x 1)\n",
    "Returns loss, final  hT  and  CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CQNxjTuZIia_"
   },
   "outputs": [],
   "source": [
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    assert len(inputs) == Time_steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "            \n",
    "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "    # print('------')\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcy5u_vRItkV"
   },
   "source": [
    "# Sample the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "p8SrtJiwIsSm"
   },
   "outputs": [],
   "source": [
    "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiWFaWLNIx_L"
   },
   "source": [
    "# Training (Adagrad)\n",
    "\n",
    "Update the graph and display a sample output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ENQYU-7AIw0t"
   },
   "outputs": [],
   "source": [
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
    "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACXcASJuI73a"
   },
   "source": [
    "# Update Parameters\n",
    "\n",
    "\\begin{align}\n",
    "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
    "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bR08TvcjI4Pf"
   },
   "outputs": [],
   "source": [
    "def update_paramters(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "La9vyJ6RJLFK"
   },
   "source": [
    "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZVDHbMb7JNGT"
   },
   "outputs": [],
   "source": [
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF6vS0VWJqsS"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OQyNSL0iJOxH",
    "outputId": "19c36fd2-2568-4bcd-c2b1-8a8e91cf3f63"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD0CAYAAABtjRZ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5fElEQVR4nO2deWATZf7/35OkSY/0ANpylQIFylUrRQQRuRQoq7goSlfKFhfUFVy/CC4KVBBWWFlWZQ9+oIh3RWsVZdlVQaggyikFWgoCUgqUltK7TdLmnt8fyUxmkmmbQq9pPq9/2kwmyTPJzHs+z+d6GJZlWRAEQRCyRNHWAyAIgiBuHhJxgiAIGUMiThAEIWNIxAmCIGQMiThBEISMUbXmhxmNRuTm5iIiIgJKpbI1P5ogCEKW2Gw2lJaWIi4uDv7+/h7Pt6qI5+bmYvbs2a35kQRBEB2Cbdu2YcSIER7bW1XEIyIi+MF069atNT+aIAhClhQXF2P27Nm8frrTqiLOuVC6deuGqKio1vxogiAIWVOfC5oCmwRBEDKGRJwgCELGkIgTBEHIGBJxgiAIGUMiThAEIWNIxAmCIGSMrES80mBGn2VfY1ducVsPhSAIol0gKxHPLzcAAN78Ia+NR0IQBNE+kJWIh/g7apN0Rksbj4QgCKJ9ICsRVzAMAEBntLbxSAiCINoHshJxbjHQmjqyxAmCIAC5ibhTxU1We9sOhCAIop0gMxFnG9+JIAjCh5CXiLf1AAiCINoZ8hJxUnGCIAgRshJxu0DFd5wsbMOREARBtA9kJeJCS3zf+ZK2GwhBEEQ7QV4iLvCKq5WyGjpBEESLICslFFriNjs5yAmCIBpdY9Nms2HFihXIz8+HUqnEunXroNPpMH/+fPTp0wcAMGvWLNx///3IyMhAeno6VCoVFixYgIkTJzbrYIUibiURJwiCaFzE9+3bBwBIT0/H0aNHsW7dOtx7772YO3cu5s2bx+9XWlqKtLQ0bN++HSaTCcnJyRgzZgzUanWzDVboTiFLnCAIwgsRnzRpEiZMmAAAKCoqQnh4OHJzc5Gfn4/MzEz07t0bqampyMnJQUJCAtRqNdRqNaKjo3Hu3DnEx8c322DFljhVbRIEQTQq4gCgUqmwdOlS7NmzB//+979x48YNzJw5E3FxcXjzzTexadMmDBo0CMHBwfxrgoKCoNfrm3WwwhRDssQJgiCaENhcv349du/ejZUrV+Kee+5BXFwcAGDy5Mk4e/YstFotDAYDv7/BYBCJenMglG3yiRMEQXgh4jt27MCWLVsAAAEBAWAYBs8++yxycnIAAIcPH8bQoUMRHx+PrKwsmEwm6HQ65OXlITY2tlkHS9kpBEEQYhp1p0yZMgXLly/H7NmzYbVakZqaiu7du2PNmjXw8/NDeHg41qxZA61Wi5SUFCQnJ4NlWSxevBgajaZZBytsgGW1kYgTBEE0KuKBgYH417/+5bE9PT3dY1tSUhKSkpKaZ2QSCGWbLHGCIAiZFvsoGMpOIQiCAGQm4lx2ikqpwImrVVj1n9w2HhFBEETbIisR5yxxP4Vjrc0PD19pw9EQBEG0PfIScadX3E8lq2ETBEG0GLJSQ84SVylkNWyCIIgWQ1ZqyLtTlEzbDoQgCKKdIC8R59wp1EucIAgCgMxEnEsNV5ElThAEAUBmIs5VbPqRT5wgCAKA3ETc+ZcscYIgCAfyEnFBsQ9BEAQhOxF3/OWKfQiCIHwdeYo4WeIEQRAAZCbirt4pZIkTBEEAMhNxLrBJljhBEIQDWakh505Rkk+cIAgCgOxEnBaCIAiCECIvEef+kpYTBEEAkJuIk3gTBEGIkJWI23kVJzUnCIIAZCbi5E4hCIIQIy8RJ/UmCIIQITMRd/5t22EQBEG0G+Ql4k75JoucIAjCgbxEnLSbIAhChKxE3E7uFIIgCBGyEnHOjUIWOUEQhAN5iXhbD4AgCKKdIS8Rd5rgT42N8dhGEAThizQq4jabDcuXL8djjz2G2bNn4+rVq7hy5QpmzZqF5ORkrFq1Cna7HQCQkZGBGTNmICkpCfv27Wv2wXJ6HRMRhMWTYkXbCIIgfBFVYztwYpyeno6jR49i3bp1YFkWixYtwqhRo/Dyyy8jMzMTw4YNQ1paGrZv3w6TyYTk5GSMGTMGarW62QbL6bWCYcA4u9HaWRYKUGtagiB8k0ZFfNKkSZgwYQIAoKioCOHh4di/fz9GjhwJABg3bhwOHjwIhUKBhIQEqNVqqNVqREdH49y5c4iPj2+2wXK9UxgG4FqKkyFOEIQv45VPXKVSYenSpVizZg0SExPBsiwYpykcFBQEnU4HvV6P4OBg/jVBQUHQ6/XNOljOdcIA/OfbyZ9CEIQP43Vgc/369di9ezdWrlwJk8nEbzcYDAgJCYFWq4XBYBBtF4p6c8DJNcMwUDhFnDScIAhfplER37FjB7Zs2QIACAgIAMMwiIuLw9GjRwEABw4cwIgRIxAfH4+srCyYTCbodDrk5eUhNja2WQfLSrhTyBInCMKXadQnPmXKFCxfvhyzZ8+G1WpFamoq+vXrh5UrV2LDhg2IiYlBYmIilEolUlJSkJycDJZlsXjxYmg0mmYdrNid4vjfThpOEIQP06iIBwYG4l//+pfH9o8//thjW1JSEpKSkppnZBJwlrhC5E4hFScIwneRVbEPZ3UzjDCw2YYDIgiCaGNkJeJ8YBOMK8WQLHGCIHwYeYk4F9hUgHenkCVOEIQvIzMRd/wVBzZJxQmC8F3kJeLgUgwZKvYhCIKA3ETcqdcKQZ441d0TBOHLyErE+ewUMOQTJwiCgMxE3OVOoYpNgiAIQG4iLpknTiJOEITvIjMRd1riYPgO4qThBEH4MjITccdfhzuFuhgSBEHIS8SdfxUMA4Vz5OROIQjCl5GViPMr+0BYsUkiThCE7yIrEZcObLbhgAiCINoYeYm48y/DCAObpOIEQfgu8hJxluV7pvCBzTYcD0EQRFsjMxEHb4FTsQ9BEITcRBwsb4HzPnF7W46IIAiibZGViNtZCNwp3DayxAmC8F1kJeIOd4pDvanYhyAIQm4iDldgkxaFIAiCkJuIi9wplJ1CEAQhMxFneXcKWeIEQRCyE3FXQNPlEycRJwjCd5GViDuyU8SBTSq7JwjCl5GViLNg+WIf3p1CKk4QhA8jLxEXBDa5vyThBEH4MjITcVbCnUIyThCE7yIvEYdEiiFpOEEQPoyqoSctFgtSU1NRWFgIs9mMBQsWoFu3bpg/fz769OkDAJg1axbuv/9+ZGRkID09HSqVCgsWLMDEiRObfbCO7BTOEndsI0ucIAhfpkER37lzJ8LCwvDaa6+hsrISDz/8MP70pz9h7ty5mDdvHr9faWkp0tLSsH37dphMJiQnJ2PMmDFQq9XNOlg7KwxsUnYKQRBEgyI+depUJCYm8o+VSiVyc3ORn5+PzMxM9O7dG6mpqcjJyUFCQgLUajXUajWio6Nx7tw5xMfHN+tghe4UKvYhCIJoRMSDgoIAAHq9HgsXLsSiRYtgNpsxc+ZMxMXF4c0338SmTZswaNAgBAcHi16n1+ubfbCsRJ44pacQBOHLNBrYvH79OubMmYPp06fjwQcfxOTJkxEXFwcAmDx5Ms6ePQutVguDwcC/xmAwiES9uWAF7hTyiRMEQTQi4mVlZZg3bx5eeOEFPProowCAJ554Ajk5OQCAw4cPY+jQoYiPj0dWVhZMJhN0Oh3y8vIQGxvb7IOVaoBFPnGCIHyZBt0pb731FmpqarB582Zs3rwZALBs2TK8+uqr8PPzQ3h4ONasWQOtVouUlBQkJyeDZVksXrwYGo2m2QcrXtnHsY0scYIgfJkGRXzFihVYsWKFx/b09HSPbUlJSUhKSmq+kUlgF6yxyXUzpAZYBEH4MvIq9hEGNhWubQRBEL6KvERcsLIP+cQJgiDkJuK0UDJBEIQImYm4cGUfaoBFEAQhLxGHywLnApyk4QRB+DKyEnHplX1IxQmC8F1kJeLiik1qRUsQBCEvEQc1wCIIghAiLxEXruyjIEucIAhCZiIOaoBFEAQhQHYizvdOARX7EARByErE7SzrUezDUkNxgiB8GFmJuFCuaXk2giAIuYm41ELJpOIEQfgwMhNxqQZYJOIEQfgu8hJxuPLDlUrHPzayxAmC8GHkJeKsa2UfJUMiThAEISsRF67so3Q6xW3kTiEIwoeRlYizAO9P4UXcRiJOEITvIi8RZ1k+K4V3p5AlThCEDyMzEReU3SsYMAylGBIE4dvIS8ThaoAFOKxxK4k4QRA+jLxEXGCJAw6/OLlTCILwZWQl4habHX5K15CVCoYCmwRB+DSyEnGz1Q6Nn0DEGbLECYLwbWQl4iarHWqhJa5kKLBJEIRPIzsR1/gp+ccU2CQIwteRlYibrXZoVK4hKxQMNcAiCMKnkZWIm6w2kYirFAysFNgkCMKHUTX0pMViQWpqKgoLC2E2m7FgwQL0798fy5YtA8MwGDBgAFatWgWFQoGMjAykp6dDpVJhwYIFmDhxYrMP1mSxQy20xCmwSRCEj9OgiO/cuRNhYWF47bXXUFlZiYcffhiDBg3CokWLMGrUKLz88svIzMzEsGHDkJaWhu3bt8NkMiE5ORljxoyBWq1u1sGarHZoVC6fuIoCmwRB+DgNivjUqVORmJjIP1YqlThz5gxGjhwJABg3bhwOHjwIhUKBhIQEqNVqqNVqREdH49y5c4iPj2+2gbIsC7NN7BOnwCZBEL5Ogz7xoKAgaLVa6PV6LFy4EIsWLXKursPwz+t0Ouj1egQHB4tep9frm3WgJqsdAMTuFApsEgTh4zQa2Lx+/TrmzJmD6dOn48EHH4RC4XqJwWBASEgItFotDAaDaLtQ1JsDTsTdA5u0KARBEL5MgyJeVlaGefPm4YUXXsCjjz4KABgyZAiOHj0KADhw4ABGjBiB+Ph4ZGVlwWQyQafTIS8vD7Gxsc06UDMn4oI8cQVDIk4QhG/ToE/8rbfeQk1NDTZv3ozNmzcDAF566SWsXbsWGzZsQExMDBITE6FUKpGSkoLk5GSwLIvFixdDo9E060BNVhsAQCOo2FQpScQJgvBtGhTxFStWYMWKFR7bP/74Y49tSUlJSEpKar6RucG7U/zEKYYU2CQIwpeRTbGPWcInrqTAJkEQPo5sRNwV2BT0TqHAJkEQPo58RNzi8Imr3fLEScQJgvBlZCPiWVcrAXi6U0jECYLwZWQj4n/fdR4AuVMIgiCEyEbEtRpHIo1gnWRaY5MgCJ9HNiL+8ZOjMLJPZ/QND+K3OSzxNhwUQRBEG9Ngnnh7YlivMGTMHy3a5ghskooTBOG7yMYSl4J84gRB+DqyF3HScIIgfBnZi7iV3CkEQfgwshZxBcOANJwgCF9G1iKuIkucIAgfR9YirqAUQ4IgfBxZi7iKuhgSBOHjyFrElQoGVjLFCYLwYWQt4gqGUgwJgvBtZC3iKiUFNgmC8G1kLeKUYth+KNObUFBR29bDaHNOXq3EmaLqth4G4UPIpneKFCrqYthuGPnXvbCzwOW/PdDWQ2lTHt58CAB9D0TrIW9L3Nk7hSUhb3MoNkEQbYOsRVzpbC5OAkIQvsWXJ65h6j8PtPUw2gXydqcoHSJutduhVCgb2ZsgiI7C8xnZAACWZcEIV4rxQWRtiYcE+AEAqmotyC8zwOhcTJkgCN+AWlHLXMR7hPoDAM4X6zDx9f1YuSO3jUdEEERrYiURl7c7pXtoAABgznvHAAC7zhTjQokeGx9LgL9aAQYMIoI1bTlEgiBaELLEZS7iPcL8RY91RiuyC6qw9cdLSDtyBQCQ/fIUBKiVUKtkPekgCEICssRl7k4JdfrE3fH3cx3W7a98h6fTjrfWkAiCaEXIEpe5Jc4wDHp1DkDnQDUMZhsulugBAP5+4kyVfedL22J4BEG0MCTiMrfEAeDHF+/Fjj+NwYTYCH7bxu8vtuGICF/BarNj+qaDOHDBYSRQ0VnrQyLupYhnZ2cjJSUFAHDmzBmMHTsWKSkpSElJwTfffAMAyMjIwIwZM5CUlIR9+/a13IglYJiGA5jkD2897D50UZXpzcguqMKc946huNpI/tk2gBrgeeFO2bp1K3bu3ImAAEcmyNmzZzF37lzMmzeP36e0tBRpaWnYvn07TCYTkpOTMWbMGKjV6pYbuRuDu4fU+1yIv6y9Rm0Oy7LYcaoQD9zWo9EbotXOQq3wjeILFi7RvmtdJn55ZWobjsY3IUvcC0s8OjoaGzdu5B/n5uZi//79mD17NlJTU6HX65GTk4OEhASo1WoEBwcjOjoa586da9GBu3Nnn871PhfsLx0AJbxjV24xFn+Wjf+3r3E3lS9dVO7eEwtZha0OzX68EPHExESoVC5LNj4+Hi+++CK2bduGXr16YdOmTdDr9QgODub3CQoKgl6vb5kR10OAWomHhvWQfM5P2fKWodVmx58zsnHhhk7yeaPFJpuK0h8ulEJntPCPK2sd/5fUGBt9bUef3loEK0lZbWIBcX9MtDy+ZDTUR5OdxZMnT0ZcXBz//9mzZ6HVamEwGPh9DAaDSNRbi38+liB6/MHcOzGqb2fUmm9OPKvrLCjVmbza91KZAdtPXMMz205IPj9o5S6M+dv3NzWO1qSgohaPv3cMy7af5rdxbgNvWlR0ZA3/9vR1DHjpW/zqvFGb3ZYGpD7irQ/dOG9CxJ944gnk5OQAAA4fPoyhQ4ciPj4eWVlZMJlM0Ol0yMvLQ2xsbLMPtqkEqlXoH6lF3U2K+Oh1mbjzr3u92pdzAzdkbZcbzDc1jtakstYxxisVrptyU5IuOrIlvvtMMQDgdKFDrC1uIp7y7rFWH1NHpaCiFmZr4+eSHCxxo8Xm1bHcLE0W8dWrV+PVV19FSkoKTpw4gWeeeQYRERFISUlBcnIyHn/8cSxevBgaTduXu3cP9UegWulhiR+4UIoagbugPppiwdeZHT+S0dL2IlaqMyH1q9MwWZt+8zKYHK8J8PO+K6TwQmqriyq/zODVb3ozmKw2PP/ZKRRVO9xJdhbY8kMevjtzo97XULqh97zz4yVkXangH+uMFoz9+z6s2HG6gVc5aCujocZogcFk9Wrfpz46jtgV36JE17g78mbwKm0jKioKGRkZAIChQ4ciPT3dY5+kpCQkJSU17+hugawVk9BFq0GAWoU6iw12OwuGAfafL8XcD37G2AHhSHtiVLN9Xq3Z8YOaJCzx1k67++vXZ7HjVBHuiumC394uHSeoj+o6hyXuXjDlQNqfIvITt5GIT3x9PwZ1C8auReOa/b0vlRrw5clC/rGdZbHu24YD91Y72yqxmPoo05tQXWdBvwhtm43BW9Z+/QsA12pInCGx34siPXsb3SzjV38HrUaF3L8kNrrvj7+WAQBOXq1C4tBuzT6WDptA3UXrmAkEqh1iZLTa8EXWNcz94GcAwOG8cuw9ewNvfHce+WWGet/HW+qc4m2UsH5bykKsD8stCCkXxBRa4tyFUp9PXCjibTm9PVcsHVS+VbgbNIc3VnZbT/Pf+O48/vhR+2834e6SEm7zJgbTlj5xvZeWOEdLuVQ6nIjvWzIB78+9k3/MiXi53ozPfi7gt1vtLJ786Dg2fn8RE1/fj8tlBuzKLcaV8psTdM7vbpE4qThhvNn3/eNHx5FX2nC2T3WtBZ8cveqw+p1D+OeeC+iz7GuRoCzbnoNhr3xX7/twPvEAtUvETY24iIQXUluIl5QQNMThvHLM2HzQ64uQswxdn9f4MbZ16lupzoTquqaJTHPQ1AwsndFzjHVNeI+2vlk2BRJxL+kbHoSJAyP5x5xFOfbv+3D8SmW9rztZUIlnPzmBDw9d8XiusRMl6a3DDZb6c8J4M/z4aym+O3sDa/93tsH93vnpElK/Oo2d2UV8Nskl5wxD+PnpPxegqoGbSkmNZzYOd2HWZxi1tTulqcIxa+sRnLhahWuVtV7t7+779GZmZbsJC/FUQRU2eZGL7w01RivMNxETuRW+OnkNg1buwuUmzGx1Et9lU37Ptr5ZNgX3bKbmosOJuDsKL5du+jrnOqx2FnqT50nVWIDw2OUKnL1ewz92n25X3YSI5xZW47Ofr/LWYpDGM3xRrjfh8+MFoud3Zhd5ZJMUV3sXUMkuqMIHhy4DEF9InIuoPv+jxYvAps3O4i//PYPCqjqvxuIt1bUW3L3O+9RN4W/T2AyDw+AW4C7XN/573kzA7aFNB/Ha7vNNfp0UOqPVqxlDxs8FOJxXzj9mWRZ9ln2N13Z7V6xnsdnBsiy+OnkN/zlVBAD4RXAteDNOd7hZLVOv2eCivVviQuubLPGb5De3dcPKaUMwLjYCAyJdQR73wiAuiHK92ogxf/teFC3nMk7K9SZsO3pFJARSVsPFEj2ulBvw6je/YGPmr5KWb9rhyxj16l4PwT94sQyVBjOmbfwJS7efxqr/nAEABEu0Dvi/T0/ihS9yUFBRy5/MOdeqPUR82safkFsozmGW8uteKnO5bLhjtttZXK8y8u8tZTlZRZa49Il68mol3j94GX/OOCX5vDewLIvUr04j51oVv+1QXhl0TfBNCqfq3k7b3S3xMn3jtQO3YiFam8Fi0xktXll+L27PwaytR/jH3Lm6eX9eg6+z2ux47O3DeGjTQew7X4LFn2Xz11BTYjJ7f/HM8GmKO6W9W+LCY7mZbDFv6PBNRQLVKjxxT188cU9fAMCNGiN0Ris+OXoVADBpcFewLIvMcyUAXJHkNwUnMfdDPJ+RjR8ulGJU387oHxmMI5fK8eOvnhH0yf8Qr8I9a2Q0/7/VZodKqcBKpzibrHY+E8RgsmL2O0cxUtBCgBMolcLzfstZtWabnQ++lelNuCGRynS6sBpxPUP5x8LP5bBYHReEWqXgb04bv7/IZ2acKarBvA9+xtAeofjg0GU+m8DihU+c23oz1gi3GG6V0++/42Qhzjr7lDT1Ehb6wb2dthvMtybiP/1ahqhOAegTHuTV5xmtdmiVt2Zf6YxW2OwsbHYWSgUDg8mKr3OuY+aIqAYXFi5xFrcFqT2loaCiFk9+eBxpT45EQUUtjlxyGDp7fykR7edt6t0v12vwz72/emxvijvF1gYphuebEEAX1qiQJd5MdA3xR/9ILcICHf1U+kdq0bNTgMd+3NJvgOuk4oKLZ687fsQln2dj076GLRYAOCHwxaf/XIAKQdEPN538/HgB0p2B1/MSpftSFjBnTNeZbaKc9pNXqxodE3dMb+7Pw4mrlSjRGbHLWcwyuFswjM4Tbt958QX68+VK3uUy6+0jqDFavPKJc7IhfPo/pwpx6GJZg+PUm6zou/wbfHAwnxdg4bE2NcNMGKT0VixqTU13pwh94r9/9ygmvL7fuwFCOk1Vii+yrkkKCsuy/HfFCce3ucV4cXuOKBNLyjK84WytIAxsc7x/8DLO39Bh56ki1AjcIJxBxPHvzF9R7bTo3z+Yjz7LvpYMPgutVLXgptVclvh/ThU2yT/vDWarHYn/PND4jk6EmU0k4s2MypnDa2dZREq0sRVaX9zdlMvCWPjpSfznVCGKvPTvXhZkvKzYkYsNe1x+T+5ie+GLHKxxBi+DJC4goe+w0mBGndnGBzB1RitqTTZEBGvQOUi6c2SZW/sAo8Xhy1y/6xxmbD6Ex7YcwffO2UjnIDUvJFJuHI7Dl8qx63SxKDulqtaMpz46LvpusguqUOwUB+El91z6KSS/c7Te7JLkrUfwutNHvPq/ZyWzSZo6RTWILHHvLir3z/XOEne8d1MzZwDwN9DGWPJ5tqSg1Jpt/IyIE44Kg2PMwmOpEWSv7DtfgrF//x4FzmCv1Dko7NrI3dju7NPJY7/r1Ua89p3Dp879ftz3brTY+N9MGJMQ5tRzhXPFNUZkF1Th6KVyTN7wA748cc1DCOud+bEsnks/hWkbf5J8viF0Rgvv0vrjR8fx7k/5oueagtDgMFFgs3lROqeUNjsr2YtcKEImqw21ZivKDa6Ld9Fnp+CtO87kduIdEgSS9BKBnUC3IOaovp1FGREJa/Zg1tYjvBWqN1lRa7FBq1Hhz1Ok2x24C0+dxSYSsUsCiyXY34+3Ut1F3H0mbrHbRd37Dlwow56zN5D6lavabvqmg3j2k5OOBxKm88+XKzy2VddacCivnLf6Acd03p2m5uoK9xdafCeuVkpa5izL8tYpR5k3lrjz5Kh0a7WgN1mxeucZ0WzMHW9mCA3dHIQ3fJPN8V6cr1t4/NV1rnNq5Y5cFFTUIafAETsJFLhTDCYrdEYL/9MxDMNbmA/WU0zG3dg5S5kTsyEv78KkDT84t7nGonT2rSjXmzzOndSvTuPXEj2ez8jGG3vEgd/6RJy75oTHe/paNQ7lNTzzA4DbVn+HP7zvqif54YLLZVojcb02hPC3JEu8mYnt5mjQNbh7CCKD/T2evy7I6Kg127D7TDEsNhaDnK+rbxrfkOXKcanUJZg6k8WjolPpppQhAX78hcmJ8amCKn4MBpMVdWYrAvyU6OJmiT87sT9iIoJQpjeLgpl1Zht0Epk4gGONUqPFjrxSPZRuvng/N1/tS1/lIkOQf8+JS841hxi4X2TcQ2HwTkoUpZpJnSlyZT1w35lUdkNDCG+a3AVWXG3EjM2HsGJHrsf+O04V4tvc4iZ9BuCKE7gf26GLZfjg0GU8l36y3tcKLVRh3cK54hrsyr0OoGG/s9BaPHW1ChdL9HytAmdB7z5TjHd+vMTvx4nuVeeNUvi7jV6XidtWu2oLGLhEuVuI57UDuG72XEYTJ9h2FiiocBhIwqwf7vv68LBniq8w3/1ymUE0NquNxaZ9Fz3qO6T6JT34/35C8tajDfZS4kT/p4tlKKkxQmey4qrgvWvqxNdMY4VfIkucRLx5mTgwEt8+NxaPDO+J7mGOEzFc6xJALiMDcDQ2WvxZNnqE+uObhWOx7cn6y/UjtGKrXpgRI8VLX+Xi/z4VX9DueeXB/iqcK9bhuzPFoswMjqXbc3C92ohAtRKdg8SfHxKgQrhWg1K9SZStUGex1SuA/n5KFNcYcd8bP+C/2UWi56SsiXSBiHP+4gqDGc9nnBJZe4BrSl7j5h5yJ7cREb9UZsD16jpJSzy7oAp9ln3t4S8+ebUSbwuEa+uBS7j3jf18T4vjEjOCrAZqCxqCExrh7A1wWaZcAF0KLqXzfzlFGP/afvzk3PeRzYcw/+MTqDVbG5yBCL/bP6ZlYdKGH/g0V85N+HRaluh349w/hy85Zokit4vz/TjBMlnt/PsIY0dCuHoD7njdC6ZKaox45b+O4P4jw6NgtNrAsqzkAi5C4bTZxbOQ69VGvLb7PMa/tp/f9umxq/g8qwD1sUciIwYANu+/iPWCdgpcXcm1yjr+M91rBBpL46ylwGbLMrh7CBiGwcCuwdiScgfuv607/5xUelZCdCcoFAzieoR6PPfNwrH43//dg34C0X5l+lB0rcdS4cgvM+Dr09dF20rc/Nec5b5iRy5yCx1CFuKvEl1UZ4pqEKBWevjEwwLUiNBqUFhZhx8vuITDaLFJunKA+vqmeIdQtL48UYhj+eWi5znDRZg7X2EwY9/5Ehy95Nq3sNLlzuJWEzorEPZJG37A6HXfe/go0w5f5rsNfpsr/l6XfJ6NY/kuoS6qNuJSqYEv15eaJfirpL8LtUT2yMw7ovD46N6O97Bzaamu49xz9oYoD/zjI1d4y1oIN0Pgfq98pyXIWa5HL1WIRPZaZS12ZhehVGfClXKDpN+WMwzqa+rmbp1y7y+0NC28IDtiMAoGHq7IWSN7YXxsBJ8hxc8W3TJ8ntl2gp+ldNGqwbJA5i8l+HemZ7aK8Fo8XVglag9dqncZW5zBsPzL03j1G8889+6hjmtRyi1nsdnx913nkXbENRPgZoNWO8u7V2vcqmAbSuM8frkCaUcuu/YlEW85GIZB4tBuvNXQM0zauujVORAAEBrohzXTh2LXorH4/V2O9MEhPUIQ1zMUv7/LcRH/99l7MGd0H3RxWvcapxA15G6ZNDgSLyQO9Nj+1NgYAA5x37DnAgBH8Ms9HzdIrfJwp0R3CUS4Vo3Cqjo8Keil8fnxAnwlaOokxL+RJdh6dwms9zn3zA33HPkr5bVY/uVpkbuqstaMue//jN+9LchXFlhf0Z0D0TVEw3cRFOJ+I1r5nzPQOr/jmjorWJbFDxdKYbez9WYycNlDNufF2v+lb/kiqjK9Cf5+CnwgaOUAALf38ryRB6qVmDSkKwCHWO44WYhFn53in3/qo+Oi7JAVO3Ix/+MTOHqpXBSz4NwpVc5mZJxzjTsvF6afxNYDrmDbnPeOYeGnJ/Hkhz+LLHch3O9QnxtG6NpIiA5DdZ0FHx66LPLdczdevcmKWrMNgWoVQgLE53OIvx+6hmg8Kn9rTTaRBS0sjuPO2Sc/Ot6oz/lGjQnJ77jOE+H5Vt5IwJm7OUrFI7ILqjy2CWd+Z4tqkHWl0uMGyQnzsfwKjzjFsi9P4+BFh2ES4q8iEW8NjM4Tef6EfpLPDxNcuCmj+2BQtxCsmR6HvFfv57ePj43AuTVTcVuUY9/eTuHnrNuGBHDemL6SN5AH4rtjslMcOMxWu8eCFYFqJUIDxEvR9Q0PQrjWM3C741SRKGgoeh+3wOqQ7iHYOMu14IawrYE7l9xSupZ9KW4nqjdZ8emxq9gvSF28XO6yjC6V6lFpMIvEv0+XQN7iYxhxc66qOk+rk7Mqq2rN+F/OdTz+3jFsO3a13mZJnMvEZLXzS9B9d9Yx5S7TmzG4ewgGdBUvcqKVqKBlGIYP0M1+56hIwOtDrVTgd28fweytR/ltXPaG0DUFuCxNndGK7Seu8ftzM7VsZxxixymxCwxw/S7ubg0puHNw1U5xhe015+zofznXUVxTh0C10qNlcUSwBpHB/ijRmbDk82x+u8FsFd1AhDOCpi6fyPnUAXHA/vH3j0m65mx2FizL8jeICoMZVptdlNnkXmXaNUTDz3oBYMG2E3jkzUMeFcfPfnICBRW1SNpyGBnHxS4czvIf0bsTuocGUNl9a8AVQYQHqTFhYAQAh0977/PjsPf58Zga113yNUq3hYGF7giuwIa7ADsF1r94dEiAH6IkctYBSAqxOwFqJRQKRuSHjwzW8B0dvaWvW1GKzc7iwdt7YOYdUQCAfhGu56VmDt5w4YYj5z40wA+HBRkDf0zLQsKaPSJ/do+wAP5702pU6Bfp+nyplgLc4htXKmpxvdpx0V0q1Xt0I+T4tcQxljK9Cd84XVtccLlMb0K4VoMw581xWK8wAMDwaM/UOoaRLsqa2kD7US5GIKwNMFrs2HP2Bu+TrTCYYTA17AcXIpUCyVmB9X0HQoRxDOHvwAU9Hd9TMYI0Ko/Coa4h/ogMcZxvX2S5bjTlejN/E3AnQN2wDDXU0lcYOC6oqMMjbx3y2Kdf6jfYlVssiFOY8adPTiB+9Xe8u6jC4DpmtVKBfhFaye+xqEp8vh3KK+ezl7jip0+PXUW53gQ7y2JE7074YsHdCNIoyRJvDZbfPwhP3tMXk4Z0xRszb8ec0b3x3/+7B/0jg9G/kQBlfcRHhYkeR3Wq3xIP8fer93mhG2ZkX+lFobmOjXueH89vYxiGD9j6+ynwx3ExjY6Zy8Dh4Py7nL89tmsw7h0UiXUzbvPY11u4Jc76hgeJgkMXnYJaLEjr6xriz392sEaFmHDXb+Fu+QNAhfPCzi2s5t/bZmdRZ7Fh7IBwbEi6vd5xcTOA6zVG/PRrGc4V69AlSI1AtRJ+SgZxPUOw9/nxWCAxW2PA8PUHQpb+ZlC9nycVGPvz59l46qPj8FMyCAv0Q2FVnUfbhPqor06AY8uBS/iXoEpy6VTPsf15iuvG/MIXOfz/7q4xqYVDuob4S9ZdvPK/s/XmbAf4ec5qDi27FyN6O26UDfVEd69/EGZ+CRFmGFUYTNh95gZMVjt+cRbuCZMJIkPE9RbBglkXZxSIxuAU+5/zK3C5zIDlX57GwvSTMFpcVdFqlaLFyu5JxAWEazVYMW0I/JQKdNFq8Mr0uFsK8gGOadn88f3w1TN3Y92M2/DytCH8cy9OHYitc0bwj0MCVJIXAODy5z0zoR+2pozAzDui8NeH4/DZH+/i94nu4rJQf3hhAvY6xTw8mOutrsLC+wY0OuZebjcSzpe8eHIs3pkzAqNiuuC9P9yJWSOj0aOe+EFjFFUboVYqMNDpppByT8Q4Lf77BkfyF1UXrYbfDjgszLEDwkWBRi64arLa+UCi2WqH0WJHQnQnzBgexe/LuQ6E7qqxA8KRXVCF37/rcHEM7RkKhmEwZ3Qf3DeoK/pHaqFyC2wG+Ckxd0wfqBSeIt43PAhvzh7u7VfDW4wJvTqhU6Aae87eEMUL6iNcq8bkwV0b3e8fex1xldT7B/EzTiHDeoVhpeA8rY8gjee1ERmsQYREym5DCH9Pjh5hAXx8SZgs8OG8kaL9dCarV33HObdbsEaFvBKX0L/7Uz7ue2O/KAupW4i/aMYsbFchNZvgthXXGHk/+pXyWtSZbbx+aFRkicsWhmGw7DeDkBDdCbNGRiNArcShZffixxcn4pkJ/TF5SFfsWTwOS6cOQligGgoJEQBcwpoQ3QmhgX54bebtmD2qN0bFdOF7szwyvCe/f+8uQfzsgQscKRVMg0HLvz4ch31LJkChYLBkSixSnBcR50v293MF7jikRPyHFyY0mFrJ+bcH9whBXM8Q/r3dmXZbd1x69X4M6haCzs6LqmdYAGLcLLMJAyOx6rcu0SmsrPMQJ84VEOhWicgJSM+wAHyzcCx+fHGiKONiZJ/O+P0ox/e7ctoQTBwkHQ/Y++fx6NU5UBRo7RkWgHhnbKSpLi3AkQbq7i5yj5nEdnV8Fw/c1h37X5iI6AZiLu5oNX713oSF38GMhJ6S+3AFQUeW38dviwzRoGuI67VvzKx/1sPh7r7jmDgoEolDu+LlaUOQtWISTr08GX0kjs+b1gsXnTO/PuFBoiKv7SeuIa/UgNOF1YiJCEJUpwCkPjAYnQJdfvqE6DD+/6sSmS1CYd+Z7UgWsNpYGC02+Ps5rjeHJU4i3mHoERbAZ7oAwICuwaLp+cZZCXjvDw4Lnbsg5t3TFx/OG4lJgz1F5JXpQ3F69RRRlZ0QLs3xxcSBIgty9YNDRBZX8sho/oJ69t4B+N2dvQA03O5TKq+3d5cgkUtHyItTB/I+9WFRoRjc3SHiUlWKwpsa504KDfBDgtMvzdEj1B/JI6Px1FhHk7OiaiNujwoTzVK4Kll3FwAXg+gW6o8hPULQq3MgHhVY6j3C/BtsGOUOd4N5f+6dOLjsXux89h7nsTQteAcALz0wGO8+PgJ/mug6N+aPF7vD7u4XDsAhulqNyqvl2Dhh0fqrJH8/wPW7JkSH4Q2B++nTp+7C2AGOz+SC6N1C/XGH0/URqFaJbgCP3BHlkZGldjMk3AvIOEID/LAlZQS6hviji1aDsEC1ZF56sMQszh0us0mYVRTjdvOICQ/CT0vvxfDoTggLdLkgBznPUY7beobyN2fAkbKo1TjqMXY711212OwwWmz8+aZWKVossNnhuxjKEa6UeduTo3hrWqlgMD7Wc+oLOC6C+i4EwGHlch0HASB5VDQ+OXoV99/WHZEh/uge6g+z1e4hVpyLo6He2AzDYOF9AxCuVeNlZ2dGjt2Lxnn09nhmQn8E+/uhXG/G/bd15y+QcbHhKKio41eSB8CnZwKuFLjQQD/06hyIPYvH8d0iu4cFgGEY/oYAAE+Pj5FMKeQuqqwVk2Bngc9+djRvElYe3t0/HIsnxeIfey/wF7MU88b0xXsHHal+WucNtFuov+i75uAyFbzl3Jqp/OzkrpgufKO139/VG4/e0Qt5pXqcKqjCyL6d8cGhy3zAlbPMpZgzujf6R2rx4aHLyCs1IFgiMMnBxWYeTugJhmHwyZOjsONUIe6K6YwSXRR+/LVMFF/5aN5IPiCqcebWc2LuntbIuRW2pNyBoT0cv9k/fzcMhVV1jfZTd78BAI5ZkFLBYMTavZKv6R+pxcUSPYI1Kvzh7r74+IjjN+8UpAYEMRWhC6VTkOMGFahWeYj9sF5hmDAwAk986EjZzTxXgshgDdY8FIen07IAuILrXCMxjVLRYu4UEvF2zJj+4S3yvmumx2Hu3X0Q6RQuYZGTEC7furGqtOcnx6LSYPYQ8YHdgsEwjunuW78fzk8nU+7qzbtqAGDXorGI7hwIi41FpcHMd/wTui7u6R+O13af58eqFVh3XBqncCYi/D9cq+azGPydFxXn3uA6WLoXZXH+3oZmIS8/OATL7x+E4mojQhuxtIP9/XD5bw/gfzlF6B7qj3K9GUarHQsF1bpThnTlUxuF7iWFgkGvzgEY1M1RnBagViKuZyjvq839SyLfsKp3F2nXBOC4gXYL9UfmLyXIKzV4TO/fmHk7L179I7U4lnofL8R39w/H3c7zcfqwnnjgtu6iWV2QRiVauOTb58byr312Yn/8+/uLWDChH749fR0vTh2EE1cqRYsGP5TQExab/aYWxeB+u2CNyqO3/C+vTMWar8/iYokew3t3Qv9IrSN2MKSrRzVuJ0Ewk7t5B/gpMbBbMEbHdOGrWSOCNR6Lzfj7KSVTb7nfMVCjbHLHTW8hEfdBlArGI+9ZCs4Sn+RFsIw7p919zpnPj8f5Yp1keibHoG4uCzo0wA9v/X44zDYWIYL84dt7hYksXGEglLv4OOEVBhePpt4Hf5UStzvXFQ10c6dMiI3E46N7i/yewjFxlmJ9+CkVItdYY0yLdzWMMlvteHZif/zuzl44cqkcjwyPwj/2XpBMX/zxxXvrfU/hd6FUMEiIDsOgbsH49Jg4b5lz6Tw3aQAO55Xzx7wpeTjyy/R45I4o0f6RDVQbuwd23RHOip6fMhAzhkehd5dAPhtGynBoaDYpZP+SCbCxLO574wfR9swl4zHyr5kAgKfHxaBUb0KA2iGuuYXVePxuh+Hw80uTwDAMXt99HhduuJbD6y9wRXEppQFqJfyUCnw4byRiV3wLwCHiEwZG4NE7ovg0ys2zh0vOEjgRnz++H357u3Rs4VYhESfqxd9PicPL70WXoMaDckEaFXqGBWD5/eKUtZgIrUcgsjEaEnz+85yWtjDQxVmCQh8sZ6VxTb3c+2R3ClLjL9PjPN7/ngHh+GbhWAzufnMplN6gVimwxJlnz90IhOl9N8tXz4yB0WLzEHFOUIZHd8KFv/6G3/5AfOPf963i7YIYt/JekcH+iAkPwqUyAx69I4o3VCYP6SrKPuJcSIsnx2LO6N4Y+apD+O8QtNXlZnKcsAsFOkKrAcMwmDemLy/i3Kzon78bhqpaMzLPleDHX8v4+ENUp8AG04tvBRJxokHqa3Dkjp9SgYPL6rcWmxuFgsEX80eL8vc5f3dIgKdrI8BPKcrb9YYhjVjh7RmNSoGJAyOQMro3QgP8cKrAuzzztuaDuXfW2/bCG15+cAiWbs/xSjCVCgaRIf4Y1isMpwqqRL7v2K5avPZoPBLjPAu1uKCmVIrlQ85MnoP1BNJbAhJxQraM6CMueuIq+4Z09xTfAD8lKmFplYuqPcAwDN6f68qpvqO3dIFYe2NCAy0d3Fk5bQgGuxWbTRgYiaOpk5r0mR89MRI6o1UU5GUYBjNH9JLcn3Mz1ZcNBrhmPbdaZ+INJOJEh6F/ZDD+PSsB90rkcnMBzYZKuAl5wa2be6uE+PuJ4i/18fETo/jAL+AZ/xHC1WO0xtlGIk50KH5bz0oz9w6MxKXSfFFWC0E0hXsGiLPFGprVcRZ4UxZ9vlnojCZ8gmW/GYTkUdFe+/gJojEUCgYMA/xpQn+P57iAprfrpd4KJOKET6BSKpqcJUMQjZG/zrOwCwDGDojA1h/zcbtbA7yWwKvEzOzsbKSkpAAArly5glmzZiE5ORmrVq2C3VnNl5GRgRkzZiApKQn79u1ruRETBEG0c8bFRiBn9RSM7telxT+rURHfunUrVqxYAZPJ0Rlu3bp1WLRoET755BOwLIvMzEyUlpYiLS0N6enpePfdd7FhwwaYzY2vCE4QBNFR8SZY2hw0KuLR0dHYuHEj//jMmTMYOdKRujRu3DgcOnQIOTk5SEhIgFqtRnBwMKKjo3HunOcadwRBEETz0qiIJyYmQqVyuc5ZluXzKYOCgqDT6aDX6xEc7MrXDAoKgl6vb4HhEgRBEEKa3IpWIVh+ymAwICQkBFqtFgaDQbRdKOoEQRBEy9BkER8yZAiOHnWseHLgwAGMGDEC8fHxyMrKgslkgk6nQ15eHmJjY5t9sARBEISYJqcYLl26FCtXrsSGDRsQExODxMREKJVKpKSkIDk5GSzLYvHixdBomr6SCUEQBNE0GJZtqS63nly7dg333XcfMjMzERUV1fgLCIIgfJzGdLNVi31sNkcJanFxcSN7EgRBEIBLLzn9dKdVRby0tBQAMHv27Nb8WIIgCNlTWlqK3r17e2xvVXeK0WhEbm4uIiIioFT6RktQgiCIW8Fms6G0tBRxcXHw9/dcbalVRZwgCIJoXpqcYkgQBEG0H9p9F0O73Y7Vq1fj/PnzUKvVWLt2raRfSM5kZ2fj9ddfR1paGq5cuYJly5aBYRgMGDAAq1atgkKhQEZGBtLT06FSqbBgwQJMnDixrYd901gsFqSmpqKwsBBmsxkLFixA//79O/Rx22w2rFixAvn5+VAqlVi3bh1Ylu3QxwwA5eXlmDFjBt577z2oVKoOf7wA8NBDD/HFjlFRUZg/f37LHjfbztm9eze7dOlSlmVZ9uTJk+z8+fPbeETNy9tvv81OmzaNnTlzJsuyLPv000+zR44cYVmWZVeuXMl+9913bElJCTtt2jTWZDKxNTU1/P9y5YsvvmDXrl3LsizLVlRUsOPHj+/wx71nzx522bJlLMuy7JEjR9j58+d3+GM2m83sM888w06ZMoW9ePFihz9elmVZo9HITp8+XbStpY+73btTsrKyMHbsWADAsGHDkJub28Yjal58scHY1KlT8dxzz/GPlUplhz/uSZMmYc2aNQCAoqIihIeHd/hjXr9+PR577DFERjqWy+voxwsA586dQ11dHebNm4c5c+bg1KlTLX7c7V7E9Xo9tFpXM3+lUgmr1dqGI2pefLHBWFBQELRaLfR6PRYuXIhFixb5xHGrVCosXboUa9asQWJiYoc+5i+//BKdO3fmDTDAN85tf39/PPHEE3j33Xfxl7/8BUuWLGnx4273Iu7eXMtut4tEr6PhKw3Grl+/jjlz5mD69Ol48MEHfea4169fj927d2PlypV8j36g4x3z9u3bcejQIaSkpOCXX37B0qVLUVFRwT/f0Y6Xo2/fvvjtb38LhmHQt29fhIWFoby8nH++JY673Yv48OHDceDAAQDAqVOnOnxjLV9oMFZWVoZ58+bhhRdewKOPPgqg4x/3jh07sGXLFgBAQEAAGIZBXFxchz3mbdu24eOPP0ZaWhoGDx6M9evXY9y4cR32eDm++OIL/O1vfwMA3LhxA3q9HmPGjGnR4273eeJcdsqFCxfAsixeffVV9OvXr62H1axcu3YNzz//PDIyMpCfn4+VK1fCYrEgJiYGa9euhVKpREZGBj777DOwLIunn34aiYmJbT3sm2bt2rX49ttvERMTw2976aWXsHbt2g573LW1tVi+fDnKyspgtVrx1FNPoV+/fh3+twaAlJQUrF69GgqFosMfr9lsxvLly1FUVASGYbBkyRJ06tSpRY+73Ys4QRAEUT/t3p1CEARB1A+JOEEQhIwhEScIgpAxJOIEQRAyhkScIAhCxpCIEwRByBgScYIgCBlDIk4QBCFj/j82A9I5cTfziAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " rooonooeueoooooo oooaoo  ooo nonoohon iaoe  ooponhohhpr ousuooooohthheoh \n",
      "o,msoohohouooooooo  ot ooooooou  oe a osooofoovoaoooodhooootun h oooooooooooooeuo euooohonsohhofreorouo ooo   ooef h ooooooo t \n",
      "----\n",
      "iter 500, loss 156.510816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naman\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\naman\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fc1abb91559c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m   \u001b[1;31m# Print every hundred steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[0mupdate_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_h_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_C_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[0mupdate_paramters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-7ac1ac7424b4>\u001b[0m in \u001b[0;36mupdate_status\u001b[1;34m(inputs, h_prev, C_prev)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Get predictions for 200 letters with current model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msample_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-7c294fc2fd1b>\u001b[0m in \u001b[0;36msample\u001b[1;34m(h_prev, C_prev, first_char_idx, sentence_length)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "iter = 50000\n",
    "while iter > 0:\n",
    "  # Reset\n",
    "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
    "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
    "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
    "      pointer = 0\n",
    "\n",
    "\n",
    "  inputs = ([char_to_idx[ch] \n",
    "              for ch in data[pointer: pointer + Time_steps]])\n",
    "  targets = ([char_to_idx[ch] \n",
    "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
    "\n",
    "  loss, g_h_prev, g_C_prev = forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "#   print(loss, g_h_prev, g_C_prev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "  # Print every hundred steps\n",
    "  if iteration % 100 == 0:\n",
    "      update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "  update_paramters()\n",
    "\n",
    "  plot_iter = np.append(plot_iter, [iteration])\n",
    "  plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "  pointer += Time_steps\n",
    "  iteration += 1\n",
    "  iter = iter -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00p4MuYiPsV-"
   },
   "outputs": [],
   "source": [
    "plot_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AKpa1BGOItQ"
   },
   "source": [
    "# Quiz Question 7. \n",
    "\n",
    "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GikHlOV8a1ln"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_and_QnA_A4P2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_and_QnA_A4P2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namanphy/END2/blob/main/S4/LSTM_and_QnA_A4P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5f7fc9-08c4-446b-985d-7f04997dce78"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsyY2c8JfRGL",
        "outputId": "a0d2c2a3-ca50-459e-fe92-fc90c6f85490"
      },
      "source": [
        "print(X_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100  # size of the hidden layer\n",
        "Time_steps = 40  # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1  # Learning Rate\n",
        "weight_sd = 0.1  # Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size  # Size of concatenation(H, X) vector"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "    s = 1 / (1 + np.exp(-y))\n",
        "    ds = s * (1-s)  \n",
        "    return ds\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "    t = (np.exp(y)-np.exp(-y))/(np.exp(y)+np.exp(-y))\n",
        "    dt = 1 - t**2\n",
        "    return dt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "## Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "\n",
        "## Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "ANS: \n",
        "\n",
        "## Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "## Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftrFxYIMcHU8",
        "outputId": "31987dbc-a617-4471-803f-48c65690167a"
      },
      "source": [
        "print('sigmoid(0): ', sigmoid(0))\n",
        "print('dsigmoid(sigmoid(0)): ', dsigmoid(sigmoid(0)))\n",
        "print('tanh(dsigmoid(sigmoid(0))): ',  tanh(dsigmoid(sigmoid(0))))\n",
        "print('dtanh(tanh(dsigmoid(sigmoid(0)))): ', dtanh(tanh(dsigmoid(sigmoid(0)))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sigmoid(0):  0.5\n",
            "dsigmoid(sigmoid(0)):  0.2350037122015945\n",
            "tanh(dsigmoid(sigmoid(0))):  0.2307710272926823\n",
            "dtanh(tanh(dsigmoid(sigmoid(0)))):  0.9485799654066528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Params and forward function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YdLX4wtnBdX"
      },
      "source": [
        "## Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size\n",
        "size_b = z_size\n",
        "size_c = X_size\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    \n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    # temp = [np.isnan(x).any() for x in [z, f, i, C_bar, C, o, h, v, y]]\n",
        "    # print(temp)\n",
        "    # if any(temp):\n",
        "    #     for x in [z, f, i, C_bar, C, o, h, v, y]:\n",
        "    #         print(x.shape)\n",
        "    #         print(x)\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "## Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?\n",
        "\n",
        "ANS: 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRz2mC-ulLmJ",
        "outputId": "cebfcab0-8601-4d21-c3d7-1ccc3d5779af"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "## Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c8e5c2-cc12-4be8-c388-29da0e572bae"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "    # print('------')\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "e2ee9365-6c2f-423a-b9e6-f5864e012d45"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "#   print(loss, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 40 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " nctiom tarenavs hod avfr Mg0ngesnols c ha, 9i' C Ohom (ry s ndnoigteifi iothrat\n",
            " v sno uot t  kn1fclhr wCKncgycea (aore AaepiaIhin  onth hl ig ter u.\n",
            "r aere dieiguheesattd alue nIoml rs:fl r 2,bd cfon \n",
            "----\n",
            "iter 49960, loss 113.005046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GikHlOV8a1ln",
        "outputId": "04b06fe4-055e-4f2d-e8d6-d144407ee461"
      },
      "source": [
        "print('loss :', 113.005046)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss : 113.005046\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
>>>>>>> 386e60bcd696d662bcfea13b4eb37caf1558a7b3
