{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namanphy/END2/blob/main/S9/Assignment_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2djL8imtQiQ4",
        "outputId": "f36d3f6d-dacb-49d3-b813-6cc5e823fc5d"
      },
      "source": [
        "! git clone https://github.com/namanphy/END2.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'END2'...\n",
            "remote: Enumerating objects: 628, done.\u001b[K\n",
            "remote: Counting objects: 100% (628/628), done.\u001b[K\n",
            "remote: Compressing objects: 100% (461/461), done.\u001b[K\n",
            "remote: Total 628 (delta 316), reused 404 (delta 157), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (628/628), 14.45 MiB | 19.32 MiB/s, done.\n",
            "Resolving deltas: 100% (316/316), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-vFcGgCQjwe",
        "outputId": "80f06dd9-2ef9-43f8-d93a-f3527f469d4b"
      },
      "source": [
        "cd /content/END2/S9"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/END2/S9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFv_Q2NLSGoh"
      },
      "source": [
        "## Making Datatset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4eAjHGbFON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "241877bb-fdaf-4625-b32b-6cd9cff2810f"
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "df = pd.read_csv(\"tweets_clean.csv\")\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "      <th>tweets_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "      <td>- his connection to supporters of Critical Ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "      <td>Obama has approved more targeted assassinatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                       tweets_clean\n",
              "0           0  ...  Obama has called the GOP budget social Darwini...\n",
              "1           1  ...  In his teen years, Obama has been known to use...\n",
              "2           2  ...  IPA Congratulates President Barack Obama for L...\n",
              "3           3  ...   - his connection to supporters of Critical Ra...\n",
              "4           4  ...   Obama has approved more targeted assassinatio...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE-ylf6C6BJD",
        "outputId": "8e0cf6ff-6755-4716-8999-0a77808c6c08"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxhrQox6Ju3",
        "outputId": "5530f8fd-ac1f-4b1e-e6d4-4df09b6ef9f2"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIyapAa6Pjr"
      },
      "source": [
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kqZx2hG6e4Q",
        "outputId": "5c66d653-8c13-42ba-d80e-07438e5c462b"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f30e4c47450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('tweet', Tweet), ('label', Label)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmCFTgk797i"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lj9XCy38OqE"
      },
      "source": [
        "twitterDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIA3n0l8m2x"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[85, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91fhtSKS8y3T",
        "outputId": "f9b92241-3aa2-4036-e85b-b0919f84ecb8"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCDhbBKJ81ZK",
        "outputId": "a0556ed7-c577-46c8-a8f6-3ee057315f16"
      },
      "source": [
        "vars(train.examples[11])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'tweet': ['@sweetbay',\n",
              "  'That',\n",
              "  'was',\n",
              "  'Paul',\n",
              "  'Ryan',\n",
              "  \"'s\",\n",
              "  'budget',\n",
              "  '.',\n",
              "  'How',\n",
              "  'did',\n",
              "  'Obama',\n",
              "  \"'s\",\n",
              "  'budget',\n",
              "  'do',\n",
              "  '?',\n",
              "  'Getting',\n",
              "  'educated',\n",
              "  'on',\n",
              "  'the',\n",
              "  'facts',\n",
              "  'is',\n",
              "  'the',\n",
              "  'first',\n",
              "  'step',\n",
              "  'in',\n",
              "  'losing',\n",
              "  'that',\n",
              "  'liberalism',\n",
              "  '!']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_K23gxx84-K"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPG8VrE9MKq",
        "outputId": "48b62e24-b1a8-4fa2-c213-db18d383488f"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBmMQQcX9SZk",
        "outputId": "c294b17c-8996-431a-e2b3-82de0913b2ec"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJyulXA9sEr"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kgqqK75FLEV",
        "outputId": "0224f346-b287-4842-9942-cb1ac7c8cd80"
      },
      "source": [
        "next(iter(train_iterator)).label\n",
        "#len(train.examples[11].tweet)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvyfX7pAR_Pu"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh2Z6jqIN6W2"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfZX3pvoICy2"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers,                            \n",
        "                           batch_first=True)\n",
        "        \n",
        "  def forward(self, text, text_lengths):\n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "            \n",
        "        return (packed_output, (hidden, cell))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whd8POb9JIOX"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        " def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, device):\n",
        "        \n",
        "        super().__init__() \n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers,                            \n",
        "                           batch_first=True)\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        " def forward(self, packed_input, hidden, cell):\n",
        "\n",
        "        packed_input = nn.utils.rnn.PackedSequence(torch.zeros(packed_input.data.shape[0],packed_input.data.shape[1]), packed_input.batch_sizes, packed_input.sorted_indices, packed_input.unsorted_indices)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_input.to(self.device), (hidden,cell))\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMOsJcZ2KVqx"
      },
      "source": [
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, device):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = Encoder(vocab_size, embedding_dim, hidden_dim, n_layers)\n",
        "        self.decoder = Decoder(hidden_dim, hidden_dim, output_dim, n_layers, device)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        packed_output, (hidden, cell) = self.encoder(text, text_lengths)\n",
        "        output = self.decoder(packed_output, hidden, cell)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNWimMMAKya"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd84tbJ8MLNX"
      },
      "source": [
        "model=model.to(device)\n",
        "for batch in train_iterator:\n",
        "  tweet = batch.tweet[0]\n",
        "  length = batch.tweet[1]\n",
        "  model(tweet, length)\n",
        "  break"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRextCcAASGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3269352-b247-41e5-bac9-4c9247a118ec"
      },
      "source": [
        "print(model)\n",
        " \n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(4651, 300)\n",
            "    (lstm): LSTM(300, 100, batch_first=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (lstm): LSTM(100, 100, batch_first=True)\n",
            "    (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "The model has 1,637,203 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        " \n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = (correct.sum() / len(correct)) * 100\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emu83iPbtFCf"
      },
      "source": [
        "def evaluate_metrics(function):\n",
        "  from functools import wraps\n",
        "  @wraps(function)\n",
        "  def inner(model, iterator, criterion, optimizer = None):\n",
        "    labels, preds = [], []\n",
        "    pred = function(model, iterator, criterion, optimizer)\n",
        "    for i,j in enumerate(pred):\n",
        "      if i % 2 == 0:\n",
        "        preds.append(j)\n",
        "      else:\n",
        "        labels.append(j.tolist()) \n",
        "    predictions = torch.cat(preds, dim=0).argmax(dim=1).tolist()\n",
        "    labels = sum(labels, [])\n",
        "    positive = {'True Positive' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 1)[0]].count(1), 'False Neutral' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 1)[0]].count(2), 'False Negative' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 1)[0]].count(0)}\n",
        "    neutral = {'False Positive' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 2)[0]].count(1), 'True Neutral' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 2)[0]].count(2),  'False Negative' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 2)[0]].count(0)}\n",
        "    negative = {'False Positive' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 0)[0]].count(1), 'False Neutral' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 0)[0]].count(2), 'True Negative' : [predictions[i] for i in np.where(np.array(labels, dtype=object) == 0)[0]].count(0)}\n",
        "    \n",
        "    precision = {'positive' : positive['True Positive'] / (positive['True Positive'] + neutral['False Positive'] + negative['False Positive'] + 1e-15), 'neutral' : neutral['True Neutral'] / (positive['False Neutral'] + neutral['True Neutral'] + negative['False Neutral'] + 1e-15), 'negative' : negative['True Negative'] / (positive['False Negative'] + neutral['False Negative'] + negative['True Negative'] + 1e-15)}\n",
        "    recall = {'positive' : positive['True Positive'] / (positive['True Positive'] + positive['False Neutral'] + positive['False Negative'] + 1e-15), 'neutral' : neutral['True Neutral'] / (neutral['False Positive'] + neutral['True Neutral'] + neutral['False Negative'] + 1e-15), 'negative' : negative['True Negative'] / (negative['False Positive'] + negative['False Neutral'] + negative['True Negative'] + 1e-15)} \n",
        "    f1_score = {'positive' : 2 * precision['positive'] * recall['positive'] / (precision['positive'] + recall['positive'] + 1e-15), 'neutral' : 2 * precision['neutral'] * recall['neutral'] / (precision['neutral'] + recall['neutral'] + 1e-15), 'negative' : 2 * precision['negative'] * recall['negative'] / (precision['negative'] + recall['negative'] + 1e-15)}\n",
        "    return precision, recall, f1_score\n",
        "  return inner"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "@evaluate_metrics\n",
        "def train(model, iterator, criterion, optimizer):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweet  \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)  \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step() \n",
        " \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item() \n",
        "        epoch_acc += acc.item()  \n",
        " \n",
        "        yield predictions.cpu().detach()\n",
        "        yield batch.label.cpu().detach()    \n",
        "    \n",
        "    print(\"Loss = {:.2f}\".format(epoch_loss / len(iterator))) \n",
        "    print(\"Accuracy = {:.2f}% \\n \".format(epoch_acc / len(iterator)))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "@evaluate_metrics\n",
        "def evaluate(model, iterator, criterion, optimizer=None):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweet\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label) \n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()  \n",
        "\n",
        "            yield predictions.cpu().detach()\n",
        "            yield batch.label.cpu().detach()\n",
        "\n",
        "    print(\"Loss : {:.2f}\".format(epoch_loss / len(iterator)))\n",
        "    print(\"Accuracy = {:.2f}% \\n \".format(epoch_acc / len(iterator))) "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7UPwN0KAvVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9fe657-2b6e-4db8-8bb4-373cf8b60574"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        " \n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(\"\\n\\033[1mEpoch : {} \\033[0m\".format(epoch + 1))\n",
        "    print(\" \")\n",
        "    # train the model\n",
        "    print(\"\\033[4mTrain Dataset\\033[0m\\n \")\n",
        "    recall, precision, f1_score = train(model, train_iterator, criterion, optimizer)\n",
        "    print (\"{:<10} {:<10} {:<10} {:<10}\".format('-','Positive','Neutral','Negative'))\n",
        "    print (\"{:<10} {:<10.2f} {:<10.2f} {:<10.2f}\".format('Recall', recall['positive'], recall['neutral'], recall['negative']))\n",
        "    print (\"{:<10} {:<10.2f} {:<10.2f} {:<10.2f}\".format('Precision', precision['positive'], precision['neutral'], precision['negative']))\n",
        "    print (\"{:<10} {:<10.2f} {:<10.2f} {:<10.2f} \\n\".format('F1 Score', f1_score['positive'], f1_score['neutral'], f1_score['negative']))\n",
        "\n",
        "\n",
        "    # evaluate the model\n",
        "    print(\"\\033[4mValidation Dataset\\033[0m\\n \")\n",
        "    recall, precision, f1_score = evaluate(model, train_iterator, criterion)\n",
        "    print (\"{:<10} {:<10} {:<10} {:<10}\".format('-','Positive','Neutral','Negative'))\n",
        "    print (\"{:<10} {:<10.2f} {:<10.2f} {:<10.2f}\".format('Recall', recall['positive'], recall['neutral'], recall['negative']))\n",
        "    print (\"{:<10} {:<10.2f} {:<10.2f} {:<10.2f}\".format('Precision', precision['positive'], precision['neutral'], precision['negative']))\n",
        "    print (\"{:<10} {:<10.2f} {:<10.2f} {:<10.2f}\".format('F1 Score', f1_score['positive'], f1_score['neutral'], f1_score['negative']))\n",
        "    print(\"-----------------------------------------\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mEpoch : 1 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 1.09\n",
            "Accuracy = 54.02% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.28       0.00       0.71      \n",
            "Precision  0.41       0.00       0.65      \n",
            "F1 Score   0.33       0.00       0.68       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 1.07\n",
            "Accuracy = 69.04% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 2 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 1.04\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.94\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 3 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.88\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.87\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 4 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 5 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 6 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 7 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 8 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 9 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.12% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     0.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.00       0.00       0.81      \n",
            "-----------------------------------------\n",
            "\n",
            "\u001b[1mEpoch : 10 \u001b[0m\n",
            " \n",
            "\u001b[4mTrain Dataset\u001b[0m\n",
            " \n",
            "Loss = 0.86\n",
            "Accuracy = 69.21% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     1.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.01       0.00       0.82       \n",
            "\n",
            "\u001b[4mValidation Dataset\u001b[0m\n",
            " \n",
            "Loss : 0.86\n",
            "Accuracy = 69.21% \n",
            " \n",
            "-          Positive   Neutral    Negative  \n",
            "Recall     1.00       0.00       0.69      \n",
            "Precision  0.00       0.00       1.00      \n",
            "F1 Score   0.01       0.00       0.82      \n",
            "-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        "#inference \n",
        " \n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        " \n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        " \n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1mmb9YiHWOv"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXPNMxEJXiqr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}